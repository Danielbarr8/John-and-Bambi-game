{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM61khh49RHy2nVWC+pota5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danielbarr8/John-and-Bambi-game/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define constants\n",
        "MAX_HEALTH = 100\n",
        "MAX_ENERGY = 100\n",
        "MAX_LEVEL = 10\n",
        "MAX_EXPERIENCE = 100\n",
        "\n",
        "# Define classes\n",
        "class Character:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.health = MAX_HEALTH\n",
        "        self.energy = MAX_ENERGY\n",
        "        self.level = 1\n",
        "        self.experience = 0\n",
        "\n",
        "    def attack(self, other):\n",
        "        damage = random.randint(1, 10)\n",
        "        other.health -= damage\n",
        "        print(f\"{self.name} attacked {other.name} and dealt {damage} damage.\")\n",
        "    \n",
        "    def rest(self):\n",
        "        self.energy = min(self.energy + 20, MAX_ENERGY)\n",
        "        print(f\"{self.name} rested and gained 20 energy.\")\n",
        "    \n",
        "    def level_up(self):\n",
        "        if self.level < MAX_LEVEL and self.experience >= MAX_EXPERIENCE:\n",
        "            self.level += 1\n",
        "            self.experience = 0\n",
        "            print(f\"{self.name} leveled up to level {self.level}!\")\n",
        "        elif self.level == MAX_LEVEL:\n",
        "            print(f\"{self.name} has reached the maximum level!\")\n",
        "        else:\n",
        "            print(f\"{self.name} needs more experience to level up.\")\n",
        "\n",
        "class Man(Character):\n",
        "    def __init__(self, name):\n",
        "        super().__init__(name)\n",
        "\n",
        "class Deer(Character):\n",
        "    def __init__(self, name):\n",
        "        super().__init__(name)\n",
        "\n",
        "# Define functions\n",
        "def explore_area():\n",
        "    # Simulate exploring an area and encountering enemies or finding items\n",
        "    print(\"You are exploring the area...\")\n",
        "    encounter = random.randint(1, 5)\n",
        "    if encounter == 1:\n",
        "        enemy = Deer(\"Wild Deer\")\n",
        "        print(f\"You encountered {enemy.name}!\")\n",
        "        return enemy\n",
        "    elif encounter == 2:\n",
        "        enemy = Man(\"Bandit\")\n",
        "        print(f\"You encountered {enemy.name}!\")\n",
        "        return enemy\n",
        "    else:\n",
        "        print(\"You didn't encounter any enemies.\")\n",
        "\n",
        "def battle(man, deer):\n",
        "    # Simulate a battle between a man and a deer\n",
        "    while man.health > 0 and deer.health > 0:\n",
        "        action = input(\"What do you want to do? (attack, rest) \")\n",
        "        if action == \"attack\":\n",
        "            man.attack(deer)\n",
        "            deer.attack(man)\n",
        "        elif action == \"rest\":\n",
        "            man.rest()\n",
        "            deer.attack(man)\n",
        "        else:\n",
        "            print(\"Invalid action, try again.\")\n",
        "    if man.health <= 0:\n",
        "        print(\"You lost the battle!\")\n",
        "    elif deer.health <= 0:\n",
        "        print(\"You won the battle!\")\n",
        "        man.experience += random.randint(10, 20)\n",
        "        man.level_up()\n",
        "\n",
        "# Main game loop\n",
        "man = Man(\"John\")\n",
        "deer = Deer(\"Bambi\")\n",
        "print(f\"Welcome to 'The Quest for the Lost City', {man.name} and {deer.name}!\")\n",
        "while True:\n",
        "    action = input(\"What do you want to do? (explore, quit) \")\n",
        "    if action == \"explore\":\n",
        "        enemy = explore_area()\n",
        "        if enemy:\n",
        "            battle(man, enemy)\n",
        "    elif action == \"quit\":\n",
        "        print(\"Thanks for playing!\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid action, try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE_FFTO7PBkD",
        "outputId": "f07f3794-ca49-4ed5-efb9-38ab392c6d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to 'The Quest for the Lost City', John and Bambi!\n",
            "What do you want to do? (explore, quit) quit\n",
            "Thanks for playing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_size, input_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self, grid_size, agent_position, goal_position, obstacle_positions):\n",
        "        self.grid_size = grid_size\n",
        "        self.agent_position = torch.tensor(agent_position, dtype=torch.int)\n",
        "        self.goal_position = torch.tensor(goal_position, dtype=torch.int)\n",
        "        self.obstacle_positions = [torch.tensor(pos, dtype=torch.int) for pos in obstacle_positions]\n",
        "        self.autoencoder = Autoencoder(grid_size * grid_size, 32)\n",
        "\n",
        "    def is_valid_move(self, new_position):\n",
        "        if (new_position < 0).any() or (new_position >= self.grid_size).any():\n",
        "            return False\n",
        "        for obstacle in self.obstacle_positions:\n",
        "            if torch.all(new_position == obstacle):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def move_agent(self, direction):\n",
        "        new_position = self.agent_position.clone()\n",
        "        if direction == \"up\":\n",
        "            new_position[0] -= 1\n",
        "        elif direction == \"down\":\n",
        "            new_position[0] += 1\n",
        "        elif direction == \"left\":\n",
        "            new_position[1] -= 1\n",
        "        elif direction == \"right\":\n",
        "            new_position[1] += 1\n",
        "        else:\n",
        "            raise ValueError(\"Invalid direction\")\n",
        "\n",
        "        if self.is_valid_move(new_position):\n",
        "            self.agent_position = new_position\n",
        "\n",
        "    def is_won(self):\n",
        "        return torch.all(self.agent_position == self.goal_position)\n",
        "\n",
        "    def __str__(self):\n",
        "        grid = np.full((self.grid_size, self.grid_size), 0)\n",
        "        grid[tuple(self.goal_position)] = 2\n",
        "        for obstacle in self.obstacle_positions:\n",
        "            grid[tuple(obstacle)] = 1\n",
        "        grid[tuple(self.agent_position)] = 3\n",
        "        grid_flat = grid.flatten()\n",
        "        grid_tensor = torch.tensor(grid_flat, dtype=torch.float32)\n",
        "        encoded = self.autoencoder.encoder(grid_tensor)\n",
        "        decoded = self.autoencoder.decoder(encoded).detach().numpy().reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        char_grid = np.full((self.grid_size, self.grid_size), \".\")\n",
        "        char_grid[tuple(self.goal_position)] = \"G\"\n",
        "        for obstacle in self.obstacle_positions:\n",
        "            char_grid[tuple(obstacle)] = \"#\"\n",
        "        char_grid[tuple(self.agent_position)] = \"A\"\n",
        "\n",
        "        return \"\\n\".join([\" \".join(row) for row in char_grid]) + \"\\n\\nDecoded grid state:\\n\" + \"\\n\".join([\" \".join(map(lambda x: '{:0.1f}'.format(x), row)) for row in decoded])\n",
        "\n",
        "def main():\n",
        "    grid_size = 5\n",
        "    agent_position = [0, 0]\n",
        "    goal_position = [4, 4]\n",
        "    obstacle_positions = [[1, 1], [2, 2], [3, 3]]\n",
        "    game = GridWorld(grid_size, agent_position, goal_position, obstacle_positions)\n",
        "\n",
        "    print(\"Initial state:\")\n",
        "    print(game)\n",
        "\n",
        "    move_sequence = [\"right\", \"right\", \"down\", \"down\", \"right\", \"down\", \"down\", \"right\"]\n",
        "    for move in move_sequence:\n",
        "        game.move_agent(move)\n",
        "        print(f\"Move: {move}\")\n",
        "        print(game)\n",
        "\n",
        "    if game.is_won():\n",
        "        print(\"Agent reached the goal!\")\n",
        "    else:\n",
        "        print(\"Agent did not reach the goal.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVv4AEhYtqMQ",
        "outputId": "87a00469-e145-4802-a4a7-50994bafef6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial state:\n",
            "A . . . .\n",
            ". # . . .\n",
            ". . # . .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.0 0.0 0.1 0.1\n",
            "0.1 0.1 0.2 0.0 0.0\n",
            "0.0 0.0 0.5 0.1 0.0\n",
            "0.0 0.1 0.0 0.0 0.0\n",
            "0.1 0.0 0.0 0.0 0.1\n",
            "Move: right\n",
            ". A . . .\n",
            ". # . . .\n",
            ". . # . .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.0 0.0 0.0 0.0\n",
            "0.0 0.1 0.2 0.0 0.3\n",
            "0.0 0.0 0.4 0.0 0.0\n",
            "0.0 0.2 0.0 0.0 0.0\n",
            "0.2 0.3 0.0 0.0 0.3\n",
            "Move: right\n",
            ". . A . .\n",
            ". # . . .\n",
            ". . # . .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.0 0.3 0.0 0.1\n",
            "0.0 0.0 0.1 0.0 0.1\n",
            "0.0 0.0 0.4 0.2 0.0\n",
            "0.0 0.0 0.0 0.1 0.0\n",
            "0.0 0.3 0.0 0.0 0.0\n",
            "Move: down\n",
            ". . . . .\n",
            ". # A . .\n",
            ". . # . .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.4 0.2 0.1 0.0\n",
            "0.0 0.0 0.3 0.0 0.1\n",
            "0.0 0.0 0.2 0.0 0.0\n",
            "0.0 0.0 0.0 0.0 0.2\n",
            "0.1 0.2 0.1 0.3 0.1\n",
            "Move: down\n",
            ". . . . .\n",
            ". # A . .\n",
            ". . # . .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.4 0.2 0.1 0.0\n",
            "0.0 0.0 0.3 0.0 0.1\n",
            "0.0 0.0 0.2 0.0 0.0\n",
            "0.0 0.0 0.0 0.0 0.2\n",
            "0.1 0.2 0.1 0.3 0.1\n",
            "Move: right\n",
            ". . . . .\n",
            ". # . A .\n",
            ". . # . .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.1 0.1 0.0 0.0\n",
            "0.0 0.0 0.2 0.0 0.1\n",
            "0.0 0.0 0.2 0.0 0.0\n",
            "0.1 0.3 0.0 0.0 0.2\n",
            "0.2 0.1 0.0 0.1 0.0\n",
            "Move: down\n",
            ". . . . .\n",
            ". # . . .\n",
            ". . # A .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.4 0.2 0.0 0.0\n",
            "0.1 0.0 0.4 0.0 0.2\n",
            "0.0 0.0 0.2 0.0 0.0\n",
            "0.0 0.0 0.0 0.0 0.0\n",
            "0.0 0.4 0.0 0.2 0.0\n",
            "Move: down\n",
            ". . . . .\n",
            ". # . . .\n",
            ". . # A .\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.4 0.2 0.0 0.0\n",
            "0.1 0.0 0.4 0.0 0.2\n",
            "0.0 0.0 0.2 0.0 0.0\n",
            "0.0 0.0 0.0 0.0 0.0\n",
            "0.0 0.4 0.0 0.2 0.0\n",
            "Move: right\n",
            ". . . . .\n",
            ". # . . .\n",
            ". . # . A\n",
            ". . . # .\n",
            ". . . . G\n",
            "\n",
            "Decoded grid state:\n",
            "0.0 0.2 0.2 0.0 0.0\n",
            "0.0 0.0 0.3 0.0 0.0\n",
            "0.0 0.0 0.0 0.0 0.0\n",
            "0.0 0.0 0.1 0.0 0.1\n",
            "0.0 0.3 0.0 0.2 0.0\n",
            "Agent did not reach the goal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def generate_art(width, height, num_circles, min_radius, max_radius, characters):\n",
        "    canvas = [[' ' for _ in range(width)] for _ in range(height)]\n",
        "\n",
        "    for _ in range(num_circles):\n",
        "        radius = random.randint(min_radius, max_radius)\n",
        "        center_x = random.randint(radius, width - radius)\n",
        "        center_y = random.randint(radius, height - radius)\n",
        "        character = random.choice(characters)\n",
        "\n",
        "        for y in range(height):\n",
        "            for x in range(width):\n",
        "                distance = math.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
        "                if distance <= radius:\n",
        "                    canvas[y][x] = character\n",
        "\n",
        "    return canvas\n",
        "\n",
        "def print_art(canvas):\n",
        "    for row in canvas:\n",
        "        print(''.join(row))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    width, height = 80, 40\n",
        "    num_circles = 15\n",
        "    min_radius, max_radius = 3, 10\n",
        "    characters = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890!@#$%^&*()\")\n",
        "\n",
        "    art = generate_art(width, height, num_circles, min_radius, max_radius, characters)\n",
        "    print_art(art)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4YQ4Oz1XASx",
        "outputId": "cbe9c5a2-4c69-4da7-ecac-cf44802e24cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                \n",
            "                                                                                \n",
            "                                                                                \n",
            "                                                    M                           \n",
            "                 L                              MMMMMMMMM                       \n",
            "              LLLLLLL                         MMMMMMMMMMMMM         &           \n",
            "             LLLLLLLLL                       MMMMMMMMMMMMMMM      &&&&&         \n",
            "             L4LLLLLLL                      MMMMMMMMMMMMM7MMM     &&&&&         \n",
            "       Z   4444444LLLL      B               MMMMMMMMMM7777777    &&&&&&&        \n",
            "    ZZZZZ44444444444LLL BBBBBBBBB          MMMMMMMMMM777777777    &&&&&         \n",
            "   ZZZZZ4444444444444L BBBBBBBBBBB 4       MMMMMMMMM77777777777   &&&&&         \n",
            "  ZZZFFF4444444444444LBBBBBBBBBBBBB44444   MMMMMMMM7777777777777    &           \n",
            " ZZZFFF444444444444444BBBBBBBBBBBBBB44444  MMMMMMMM7777777777777                \n",
            " ZZFFFF444444444444444BBBBBBBBBBBBBBB44444MMMMMMMMM7777777777777                \n",
            " ZZFFFF444444444444444BBBBBBBBBBBBBBB444444MMMMMMM777777777777777               \n",
            "ZZZFFF44444444444444444BBBBBBBBBBBBBB444444MMMMMMMM7777777777777                \n",
            " ZFFFFF444444444444444BBBBBBBBBBBBBBB444444MMMMMMMM7777777777777                \n",
            " ZZFFFF444444444444444BBBBBBBBBBBBBBBB44444MMMMMMMM7777777777777                \n",
            " ZZFFFF444444444444444BBBBBBBBBBBBBBB4444444MMMMMMMM77777777777                 \n",
            "  ZFFFFF4444444444444BBBBBBBBBBBBBBBB4444444MMMMMMMMM777777777                  \n",
            "   ZFFFF4444444444444BBBBBBBBBBBBBBBB4444444 MMMMMMMMM7777777CCC                \n",
            "    ZFFFF44444444444BBBBBBBBBBBBBBBBB4444444  MMMMMMMMMMM7MCCCCCCC              \n",
            "       ZFCC4444444YYYBBBBBBBBBBBBBBB44444444    MMMMMMMMMCCCCCCCCCC             \n",
            "        CCCCCC4YYYYYYYBBBBBBBBBBBBB444444444        M CCCCCCCCCCCCC             \n",
            "        CCCCCCCYYYYYYYYBBBBBBBBBBB444444444      NNNNCCCCCCCCCCCCCCC            \n",
            "         CCCCCCYYYYYYYYYBBBBBBBBBY44444444      NNNNNCCCCCCCCCCCCCCC5           \n",
            "          CCCCCYYYYYYYYYYYYYBYYYYY4444444      NNNNNNCCCCCCCCCCCCCCC5           \n",
            "           CCCCCYYYYYYYYYYYYYYYYY4444444      NNNNNNCCCCCCCCCCCCCCCCC5          \n",
            "            CCCCYYYYYYYYYYYYYYYYY  4          NNNNNNNCCCCCCCCCCCCCCC55          \n",
            "                CYYYYYYYYYYYYYYY              NNNNNNNCCCCCCCCCCCCCCC55          \n",
            "                  YYYYYYYYYYYYYK             NNNNNNNNCCCCCCCCCCCCCCC555         \n",
            "                    YYYYYYYYYKKKK             NNNNNNNNCCCCCCCCCCCCC555          \n",
            "                        Y  KKKKK              NNNNNNNNCCCCCCCCCCCCC555          \n",
            "                           KKKKK              NNNNNNNNNCCCCCCCCCCC5555          \n",
            "                             K                 NNNNNNNNN5CCCCCCC55555           \n",
            "                                                NNNNNNNN5555C55555555           \n",
            "                                                 NNNNNNN 55555555555            \n",
            "                                                    N      5555555              \n",
            "                                                              5                 \n",
            "                                                                                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install torch torchvision higher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vg0baOZHh5",
        "outputId": "11a6a10c-cda5-42aa-fee7-f68c6bf94eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Collecting higher\n",
            "  Downloading higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Installing collected packages: higher\n",
            "Successfully installed higher-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import higher\n",
        "\n",
        "# Define the autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28 * 28),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# MAML training\n",
        "def metalearning_train(model, dataloader, device, num_tasks, inner_lr, meta_lr, num_inner_updates):\n",
        "    model.train()\n",
        "    meta_optimizer = optim.Adam(model.parameters(), lr=meta_lr)\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        meta_loss = 0\n",
        "        for task_idx in range(num_tasks):\n",
        "            task_data = data[task_idx]\n",
        "            with higher.innerloop_ctx(model, meta_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
        "                for inner_update in range(num_inner_updates):\n",
        "                    task_output = fmodel(task_data.view(-1, 28 * 28))\n",
        "                    inner_loss = nn.MSELoss()(task_output, task_data.view(-1, 28 * 28))\n",
        "                    diffopt.step(inner_loss)\n",
        "\n",
        "                task_output = fmodel(task_data.view(-1, 28 * 28))\n",
        "                task_loss = nn.MSELoss()(task_output, task_data.view(-1, 28 * 28))\n",
        "                meta_loss += task_loss\n",
        "\n",
        "        meta_loss /= num_tasks\n",
        "        meta_optimizer.zero_grad()\n",
        "        meta_loss.backward()\n",
        "        meta_optimizer.step()\n",
        "\n",
        "        print(f\"Batch {batch_idx + 1}, Meta-loss: {meta_loss.item()}\")\n",
        "\n",
        "def main():\n",
        "    # Settings\n",
        "    num_tasks = 5\n",
        "    num_inner_updates = 3\n",
        "    inner_lr = 0.01\n",
        "    meta_lr = 0.001\n",
        "    epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    # Device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load the MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    dataset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=num_tasks * batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize the autoencoder\n",
        "    model = Autoencoder().to(device)\n",
        "\n",
        "    # Train the autoencoder with metalearning\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}\")\n",
        "        metalearning_train(model, dataloader, device, num_tasks, inner_lr, meta_lr, num_inner_updates)\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), \"unique_autoencoder_maml.pth\")\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgqPsR5Xa7sd",
        "outputId": "57d48d6f-0079-4760-fe37-f8a623a65871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Batch 1, Meta-loss: 1.2369827032089233\n",
            "Batch 2, Meta-loss: 1.243680715560913\n",
            "Batch 3, Meta-loss: 1.1987953186035156\n",
            "Batch 4, Meta-loss: 1.25210440158844\n",
            "Batch 5, Meta-loss: 1.1311174631118774\n",
            "Batch 6, Meta-loss: 1.1240041255950928\n",
            "Batch 7, Meta-loss: 1.0991218090057373\n",
            "Batch 8, Meta-loss: 1.0175820589065552\n",
            "Batch 9, Meta-loss: 0.8384190797805786\n",
            "Batch 10, Meta-loss: 0.9640092849731445\n",
            "Batch 11, Meta-loss: 0.9548549652099609\n",
            "Batch 12, Meta-loss: 0.7846535444259644\n",
            "Batch 13, Meta-loss: 0.7048062682151794\n",
            "Batch 14, Meta-loss: 0.7518845796585083\n",
            "Batch 15, Meta-loss: 0.8422155380249023\n",
            "Batch 16, Meta-loss: 0.9181683659553528\n",
            "Batch 17, Meta-loss: 0.674493670463562\n",
            "Batch 18, Meta-loss: 0.5793286561965942\n",
            "Batch 19, Meta-loss: 0.790092408657074\n",
            "Batch 20, Meta-loss: 0.7578265070915222\n",
            "Batch 21, Meta-loss: 0.7156494855880737\n",
            "Batch 22, Meta-loss: 0.7788786292076111\n",
            "Batch 23, Meta-loss: 0.7090259790420532\n",
            "Batch 24, Meta-loss: 0.6594291925430298\n",
            "Batch 25, Meta-loss: 0.5872047543525696\n",
            "Batch 26, Meta-loss: 0.48648232221603394\n",
            "Batch 27, Meta-loss: 0.5569982528686523\n",
            "Batch 28, Meta-loss: 0.6911414861679077\n",
            "Batch 29, Meta-loss: 0.5100864171981812\n",
            "Batch 30, Meta-loss: 0.515067994594574\n",
            "Batch 31, Meta-loss: 0.5059126615524292\n",
            "Batch 32, Meta-loss: 0.5095250010490417\n",
            "Batch 33, Meta-loss: 0.4392480254173279\n",
            "Batch 34, Meta-loss: 0.5327011942863464\n",
            "Batch 35, Meta-loss: 0.5224921107292175\n",
            "Batch 36, Meta-loss: 0.47599872946739197\n",
            "Batch 37, Meta-loss: 0.5559477806091309\n",
            "Batch 38, Meta-loss: 0.4402177929878235\n",
            "Batch 39, Meta-loss: 0.5856969952583313\n",
            "Batch 40, Meta-loss: 0.5144705772399902\n",
            "Batch 41, Meta-loss: 0.5202878713607788\n",
            "Batch 42, Meta-loss: 0.5379157066345215\n",
            "Batch 43, Meta-loss: 0.5232736468315125\n",
            "Batch 44, Meta-loss: 0.5606511831283569\n",
            "Batch 45, Meta-loss: 0.6923350095748901\n",
            "Batch 46, Meta-loss: 0.5384417772293091\n",
            "Batch 47, Meta-loss: 0.5400699377059937\n",
            "Batch 48, Meta-loss: 0.6793724298477173\n",
            "Batch 49, Meta-loss: 0.6034468412399292\n",
            "Batch 50, Meta-loss: 0.6245036125183105\n",
            "Batch 51, Meta-loss: 0.8252876996994019\n",
            "Batch 52, Meta-loss: 0.5352911353111267\n",
            "Batch 53, Meta-loss: 0.49860912561416626\n",
            "Batch 54, Meta-loss: 0.589118480682373\n",
            "Batch 55, Meta-loss: 0.680052638053894\n",
            "Batch 56, Meta-loss: 0.6060574054718018\n",
            "Batch 57, Meta-loss: 0.6229432821273804\n",
            "Batch 58, Meta-loss: 0.790108859539032\n",
            "Batch 59, Meta-loss: 0.7271844744682312\n",
            "Batch 60, Meta-loss: 0.6837276220321655\n",
            "Batch 61, Meta-loss: 0.8561803698539734\n",
            "Batch 62, Meta-loss: 0.6277886629104614\n",
            "Batch 63, Meta-loss: 0.5648633241653442\n",
            "Batch 64, Meta-loss: 0.6436436772346497\n",
            "Batch 65, Meta-loss: 0.6990729570388794\n",
            "Batch 66, Meta-loss: 0.6380942463874817\n",
            "Batch 67, Meta-loss: 0.7035754323005676\n",
            "Batch 68, Meta-loss: 0.7610967755317688\n",
            "Batch 69, Meta-loss: 0.8062217831611633\n",
            "Batch 70, Meta-loss: 0.6845015287399292\n",
            "Batch 71, Meta-loss: 0.6552190780639648\n",
            "Batch 72, Meta-loss: 0.6301187872886658\n",
            "Batch 73, Meta-loss: 0.8063400983810425\n",
            "Batch 74, Meta-loss: 0.7985199689865112\n",
            "Batch 75, Meta-loss: 0.6399996280670166\n",
            "Batch 76, Meta-loss: 0.6814588904380798\n",
            "Batch 77, Meta-loss: 0.7290719151496887\n",
            "Batch 78, Meta-loss: 0.6176427006721497\n",
            "Batch 79, Meta-loss: 0.731275737285614\n",
            "Batch 80, Meta-loss: 0.6931778788566589\n",
            "Batch 81, Meta-loss: 0.8290188908576965\n",
            "Batch 82, Meta-loss: 0.5908035635948181\n",
            "Batch 83, Meta-loss: 0.6951239109039307\n",
            "Batch 84, Meta-loss: 0.662863552570343\n",
            "Batch 85, Meta-loss: 0.7563204169273376\n",
            "Batch 86, Meta-loss: 0.6048089265823364\n",
            "Batch 87, Meta-loss: 0.7220136523246765\n",
            "Batch 88, Meta-loss: 0.7101874351501465\n",
            "Batch 89, Meta-loss: 0.5682176351547241\n",
            "Batch 90, Meta-loss: 0.6984320878982544\n",
            "Batch 91, Meta-loss: 0.7278788685798645\n",
            "Batch 92, Meta-loss: 0.6140745878219604\n",
            "Batch 93, Meta-loss: 0.5965617299079895\n",
            "Batch 94, Meta-loss: 0.8837620615959167\n",
            "Batch 95, Meta-loss: 0.777057409286499\n",
            "Batch 96, Meta-loss: 0.7120469808578491\n",
            "Batch 97, Meta-loss: 0.739926278591156\n",
            "Batch 98, Meta-loss: 0.6252952814102173\n",
            "Batch 99, Meta-loss: 0.5887441039085388\n",
            "Batch 100, Meta-loss: 0.7286874651908875\n",
            "Batch 101, Meta-loss: 0.6681273579597473\n",
            "Batch 102, Meta-loss: 0.7125095129013062\n",
            "Batch 103, Meta-loss: 0.6744071841239929\n",
            "Batch 104, Meta-loss: 0.6609369516372681\n",
            "Batch 105, Meta-loss: 0.8470295667648315\n",
            "Batch 106, Meta-loss: 0.7531946301460266\n",
            "Batch 107, Meta-loss: 0.6748902201652527\n",
            "Batch 108, Meta-loss: 0.8485277891159058\n",
            "Batch 109, Meta-loss: 0.6810457110404968\n",
            "Batch 110, Meta-loss: 0.7814542055130005\n",
            "Batch 111, Meta-loss: 0.7288936972618103\n",
            "Batch 112, Meta-loss: 0.7004231214523315\n",
            "Batch 113, Meta-loss: 0.5923571586608887\n",
            "Batch 114, Meta-loss: 0.7177168130874634\n",
            "Batch 115, Meta-loss: 0.7448345422744751\n",
            "Batch 116, Meta-loss: 0.8535057306289673\n",
            "Batch 117, Meta-loss: 0.7130330801010132\n",
            "Batch 118, Meta-loss: 0.6453965306282043\n",
            "Batch 119, Meta-loss: 0.732182502746582\n",
            "Batch 120, Meta-loss: 0.7729557752609253\n",
            "Batch 121, Meta-loss: 0.746979296207428\n",
            "Batch 122, Meta-loss: 0.7537658214569092\n",
            "Batch 123, Meta-loss: 0.6900664567947388\n",
            "Batch 124, Meta-loss: 0.8129483461380005\n",
            "Batch 125, Meta-loss: 0.5651135444641113\n",
            "Batch 126, Meta-loss: 0.7299116849899292\n",
            "Batch 127, Meta-loss: 0.7759782075881958\n",
            "Batch 128, Meta-loss: 0.6717888712882996\n",
            "Batch 129, Meta-loss: 0.7673723697662354\n",
            "Batch 130, Meta-loss: 0.8396902084350586\n",
            "Batch 131, Meta-loss: 0.7646560072898865\n",
            "Batch 132, Meta-loss: 0.7177979350090027\n",
            "Batch 133, Meta-loss: 0.7096061110496521\n",
            "Batch 134, Meta-loss: 0.7796427607536316\n",
            "Batch 135, Meta-loss: 0.7580556869506836\n",
            "Batch 136, Meta-loss: 0.756402313709259\n",
            "Batch 137, Meta-loss: 0.6958441734313965\n",
            "Batch 138, Meta-loss: 0.7672585248947144\n",
            "Batch 139, Meta-loss: 0.7617882490158081\n",
            "Batch 140, Meta-loss: 0.8173090815544128\n",
            "Batch 141, Meta-loss: 0.8100179433822632\n",
            "Batch 142, Meta-loss: 0.7622169256210327\n",
            "Batch 143, Meta-loss: 0.7326828837394714\n",
            "Batch 144, Meta-loss: 0.7100752592086792\n",
            "Batch 145, Meta-loss: 0.6053929924964905\n",
            "Batch 146, Meta-loss: 0.7856519818305969\n",
            "Batch 147, Meta-loss: 0.6843315362930298\n",
            "Batch 148, Meta-loss: 0.7840720415115356\n",
            "Batch 149, Meta-loss: 0.6600353717803955\n",
            "Batch 150, Meta-loss: 0.7871307134628296\n",
            "Batch 151, Meta-loss: 0.7893064022064209\n",
            "Batch 152, Meta-loss: 0.7785274386405945\n",
            "Batch 153, Meta-loss: 0.7494280934333801\n",
            "Batch 154, Meta-loss: 0.6822587251663208\n",
            "Batch 155, Meta-loss: 0.6645612120628357\n",
            "Batch 156, Meta-loss: 0.6733115911483765\n",
            "Batch 157, Meta-loss: 0.7631075382232666\n",
            "Batch 158, Meta-loss: 0.6678930521011353\n",
            "Batch 159, Meta-loss: 0.7635049819946289\n",
            "Batch 160, Meta-loss: 0.7620939016342163\n",
            "Batch 161, Meta-loss: 0.8489066958427429\n",
            "Batch 162, Meta-loss: 0.8695002794265747\n",
            "Batch 163, Meta-loss: 0.7233180999755859\n",
            "Batch 164, Meta-loss: 0.7905158400535583\n",
            "Batch 165, Meta-loss: 0.7665541768074036\n",
            "Batch 166, Meta-loss: 0.7003532648086548\n",
            "Batch 167, Meta-loss: 0.9294554591178894\n",
            "Batch 168, Meta-loss: 0.8583287000656128\n",
            "Batch 169, Meta-loss: 0.7277018427848816\n",
            "Batch 170, Meta-loss: 0.8569628596305847\n",
            "Batch 171, Meta-loss: 0.8247489929199219\n",
            "Batch 172, Meta-loss: 0.7204700112342834\n",
            "Batch 173, Meta-loss: 0.7915001511573792\n",
            "Batch 174, Meta-loss: 0.6936548352241516\n",
            "Batch 175, Meta-loss: 0.8492259979248047\n",
            "Batch 176, Meta-loss: 0.7919265031814575\n",
            "Batch 177, Meta-loss: 0.9016238451004028\n",
            "Batch 178, Meta-loss: 0.8492165803909302\n",
            "Batch 179, Meta-loss: 0.8615306615829468\n",
            "Batch 180, Meta-loss: 0.8575833439826965\n",
            "Batch 181, Meta-loss: 0.9186334609985352\n",
            "Batch 182, Meta-loss: 0.8270825147628784\n",
            "Batch 183, Meta-loss: 0.8161706924438477\n",
            "Batch 184, Meta-loss: 0.801944375038147\n",
            "Batch 185, Meta-loss: 0.8743162155151367\n",
            "Batch 186, Meta-loss: 0.747584342956543\n",
            "Batch 187, Meta-loss: 0.7939500212669373\n",
            "Batch 188, Meta-loss: 0.7027447819709778\n",
            "Batch 189, Meta-loss: 0.8676085472106934\n",
            "Batch 190, Meta-loss: 0.6213538646697998\n",
            "Batch 191, Meta-loss: 0.846540629863739\n",
            "Batch 192, Meta-loss: 0.6773225665092468\n",
            "Batch 193, Meta-loss: 0.6971489191055298\n",
            "Batch 194, Meta-loss: 1.0281130075454712\n",
            "Batch 195, Meta-loss: 0.8108816146850586\n",
            "Batch 196, Meta-loss: 0.8209825754165649\n",
            "Batch 197, Meta-loss: 0.7952491641044617\n",
            "Batch 198, Meta-loss: 0.8730977773666382\n",
            "Batch 199, Meta-loss: 0.8112452626228333\n",
            "Batch 200, Meta-loss: 0.6819015741348267\n",
            "Batch 201, Meta-loss: 0.7678026556968689\n",
            "Batch 202, Meta-loss: 0.7657475471496582\n",
            "Batch 203, Meta-loss: 0.7149261236190796\n",
            "Batch 204, Meta-loss: 0.7190491557121277\n",
            "Batch 205, Meta-loss: 0.7996402978897095\n",
            "Batch 206, Meta-loss: 0.9439199566841125\n",
            "Batch 207, Meta-loss: 0.8853451013565063\n",
            "Batch 208, Meta-loss: 0.7607671618461609\n",
            "Batch 209, Meta-loss: 0.8371356129646301\n",
            "Batch 210, Meta-loss: 0.8314569592475891\n",
            "Batch 211, Meta-loss: 0.7547268271446228\n",
            "Batch 212, Meta-loss: 0.7428810000419617\n",
            "Batch 213, Meta-loss: 0.8119586110115051\n",
            "Batch 214, Meta-loss: 0.78925621509552\n",
            "Batch 215, Meta-loss: 0.9204721450805664\n",
            "Batch 216, Meta-loss: 0.6836153268814087\n",
            "Batch 217, Meta-loss: 0.7686909437179565\n",
            "Batch 218, Meta-loss: 0.7954930067062378\n",
            "Batch 219, Meta-loss: 1.0084575414657593\n",
            "Batch 220, Meta-loss: 0.8909223675727844\n",
            "Batch 221, Meta-loss: 0.7744127511978149\n",
            "Batch 222, Meta-loss: 0.7512878775596619\n",
            "Batch 223, Meta-loss: 0.8013126254081726\n",
            "Batch 224, Meta-loss: 0.7466002702713013\n",
            "Batch 225, Meta-loss: 0.840926468372345\n",
            "Batch 226, Meta-loss: 0.8231925964355469\n",
            "Batch 227, Meta-loss: 0.8297848701477051\n",
            "Batch 228, Meta-loss: 0.808349609375\n",
            "Batch 229, Meta-loss: 0.7348383665084839\n",
            "Batch 230, Meta-loss: 0.8408640623092651\n",
            "Batch 231, Meta-loss: 0.7773635983467102\n",
            "Batch 232, Meta-loss: 0.807660698890686\n",
            "Batch 233, Meta-loss: 0.870955765247345\n",
            "Batch 234, Meta-loss: 0.8291302919387817\n",
            "Batch 235, Meta-loss: 0.7365285754203796\n",
            "Batch 236, Meta-loss: 0.7782389521598816\n",
            "Batch 237, Meta-loss: 0.7520251870155334\n",
            "Batch 238, Meta-loss: 0.7232249975204468\n",
            "Batch 239, Meta-loss: 0.7710872888565063\n",
            "Batch 240, Meta-loss: 0.7862585783004761\n",
            "Batch 241, Meta-loss: 0.8532315492630005\n",
            "Batch 242, Meta-loss: 0.6993957161903381\n",
            "Batch 243, Meta-loss: 0.8076211810112\n",
            "Batch 244, Meta-loss: 0.6744030714035034\n",
            "Batch 245, Meta-loss: 0.7025821805000305\n",
            "Batch 246, Meta-loss: 0.860365092754364\n",
            "Batch 247, Meta-loss: 0.7355654239654541\n",
            "Batch 248, Meta-loss: 0.7712619304656982\n",
            "Batch 249, Meta-loss: 1.0032631158828735\n",
            "Batch 250, Meta-loss: 0.8257196545600891\n",
            "Batch 251, Meta-loss: 0.7938464879989624\n",
            "Batch 252, Meta-loss: 0.9964932203292847\n",
            "Batch 253, Meta-loss: 0.7921792268753052\n",
            "Batch 254, Meta-loss: 0.8723837733268738\n",
            "Batch 255, Meta-loss: 0.7554677724838257\n",
            "Batch 256, Meta-loss: 1.0615848302841187\n",
            "Batch 257, Meta-loss: 0.7741081714630127\n",
            "Batch 258, Meta-loss: 0.7688955068588257\n",
            "Batch 259, Meta-loss: 0.7383082509040833\n",
            "Batch 260, Meta-loss: 0.8783273696899414\n",
            "Batch 261, Meta-loss: 0.8043602108955383\n",
            "Batch 262, Meta-loss: 0.8779582977294922\n",
            "Batch 263, Meta-loss: 0.7862787842750549\n",
            "Batch 264, Meta-loss: 0.7815605998039246\n",
            "Batch 265, Meta-loss: 0.8166142702102661\n",
            "Batch 266, Meta-loss: 0.7864569425582886\n",
            "Batch 267, Meta-loss: 0.8296386003494263\n",
            "Batch 268, Meta-loss: 0.851416289806366\n",
            "Batch 269, Meta-loss: 0.8670989871025085\n",
            "Batch 270, Meta-loss: 0.8745778799057007\n",
            "Batch 271, Meta-loss: 0.7688736915588379\n",
            "Batch 272, Meta-loss: 0.9969934225082397\n",
            "Batch 273, Meta-loss: 0.8432940244674683\n",
            "Batch 274, Meta-loss: 0.9726186990737915\n",
            "Batch 275, Meta-loss: 0.7233514785766602\n",
            "Batch 276, Meta-loss: 0.8406442403793335\n",
            "Batch 277, Meta-loss: 0.9312601089477539\n",
            "Batch 278, Meta-loss: 0.8847516775131226\n",
            "Batch 279, Meta-loss: 0.7241523861885071\n",
            "Batch 280, Meta-loss: 0.7167574763298035\n",
            "Batch 281, Meta-loss: 1.0195673704147339\n",
            "Batch 282, Meta-loss: 0.7965711355209351\n",
            "Batch 283, Meta-loss: 0.8384890556335449\n",
            "Batch 284, Meta-loss: 0.9264445304870605\n",
            "Batch 285, Meta-loss: 0.8781023025512695\n",
            "Batch 286, Meta-loss: 0.8142304420471191\n",
            "Batch 287, Meta-loss: 0.7550708651542664\n",
            "Batch 288, Meta-loss: 0.7816017866134644\n",
            "Batch 289, Meta-loss: 0.6955640912055969\n",
            "Batch 290, Meta-loss: 1.0126093626022339\n",
            "Batch 291, Meta-loss: 0.8836286664009094\n",
            "Batch 292, Meta-loss: 0.8068341016769409\n",
            "Batch 293, Meta-loss: 0.8722370862960815\n",
            "Batch 294, Meta-loss: 0.8356660008430481\n",
            "Batch 295, Meta-loss: 0.7283608317375183\n",
            "Batch 296, Meta-loss: 0.8422819375991821\n",
            "Batch 297, Meta-loss: 0.9631394147872925\n",
            "Batch 298, Meta-loss: 0.8335806727409363\n",
            "Batch 299, Meta-loss: 0.7699903249740601\n",
            "Batch 300, Meta-loss: 0.8167277574539185\n",
            "Batch 301, Meta-loss: 0.771229088306427\n",
            "Batch 302, Meta-loss: 0.7893264889717102\n",
            "Batch 303, Meta-loss: 0.8831484913825989\n",
            "Batch 304, Meta-loss: 0.8470643162727356\n",
            "Batch 305, Meta-loss: 0.7936539649963379\n",
            "Batch 306, Meta-loss: 0.8919343948364258\n",
            "Batch 307, Meta-loss: 0.7711694836616516\n",
            "Batch 308, Meta-loss: 0.8588973879814148\n",
            "Batch 309, Meta-loss: 0.897413432598114\n",
            "Batch 310, Meta-loss: 0.769645094871521\n",
            "Batch 311, Meta-loss: 0.8758467435836792\n",
            "Batch 312, Meta-loss: 0.8075920939445496\n",
            "Batch 313, Meta-loss: 0.6842644214630127\n",
            "Batch 314, Meta-loss: 0.9495781064033508\n",
            "Batch 315, Meta-loss: 0.7982991337776184\n",
            "Batch 316, Meta-loss: 0.9619124531745911\n",
            "Batch 317, Meta-loss: 0.6828979253768921\n",
            "Batch 318, Meta-loss: 0.8445267677307129\n",
            "Batch 319, Meta-loss: 0.8798404932022095\n",
            "Batch 320, Meta-loss: 0.8176589012145996\n",
            "Batch 321, Meta-loss: 0.8449451327323914\n",
            "Batch 322, Meta-loss: 0.8142827749252319\n",
            "Batch 323, Meta-loss: 0.6817032098770142\n",
            "Batch 324, Meta-loss: 0.7594417929649353\n",
            "Batch 325, Meta-loss: 0.9107950925827026\n",
            "Batch 326, Meta-loss: 0.8271074295043945\n",
            "Batch 327, Meta-loss: 0.6648610234260559\n",
            "Batch 328, Meta-loss: 0.8114417791366577\n",
            "Batch 329, Meta-loss: 0.8168762922286987\n",
            "Batch 330, Meta-loss: 0.8520110845565796\n",
            "Batch 331, Meta-loss: 0.8523107767105103\n",
            "Batch 332, Meta-loss: 0.7864309549331665\n",
            "Batch 333, Meta-loss: 0.7741586565971375\n",
            "Batch 334, Meta-loss: 0.911935031414032\n",
            "Batch 335, Meta-loss: 0.8190237879753113\n",
            "Batch 336, Meta-loss: 1.0908499956130981\n",
            "Batch 337, Meta-loss: 0.8278241157531738\n",
            "Batch 338, Meta-loss: 0.8330016136169434\n",
            "Batch 339, Meta-loss: 0.9331226348876953\n",
            "Batch 340, Meta-loss: 0.8242387771606445\n",
            "Batch 341, Meta-loss: 0.8118446469306946\n",
            "Batch 342, Meta-loss: 0.7603380084037781\n",
            "Batch 343, Meta-loss: 0.7598276734352112\n",
            "Batch 344, Meta-loss: 0.8285185098648071\n",
            "Batch 345, Meta-loss: 0.9172136187553406\n",
            "Batch 346, Meta-loss: 0.9010825157165527\n",
            "Batch 347, Meta-loss: 0.8057911992073059\n",
            "Batch 348, Meta-loss: 0.7165442705154419\n",
            "Batch 349, Meta-loss: 0.7641623616218567\n",
            "Batch 350, Meta-loss: 0.7458242177963257\n",
            "Batch 351, Meta-loss: 0.8906654119491577\n",
            "Batch 352, Meta-loss: 1.0170913934707642\n",
            "Batch 353, Meta-loss: 0.6642917394638062\n",
            "Batch 354, Meta-loss: 0.8159157633781433\n",
            "Batch 355, Meta-loss: 0.8586869239807129\n",
            "Batch 356, Meta-loss: 1.0841209888458252\n",
            "Batch 357, Meta-loss: 0.8096941113471985\n",
            "Batch 358, Meta-loss: 0.8144901990890503\n",
            "Batch 359, Meta-loss: 0.7663680911064148\n",
            "Batch 360, Meta-loss: 0.933310329914093\n",
            "Batch 361, Meta-loss: 0.7866131663322449\n",
            "Batch 362, Meta-loss: 0.7756801843643188\n",
            "Batch 363, Meta-loss: 0.7804262042045593\n",
            "Batch 364, Meta-loss: 0.8086150288581848\n",
            "Batch 365, Meta-loss: 0.9372750520706177\n",
            "Batch 366, Meta-loss: 0.7514274716377258\n",
            "Batch 367, Meta-loss: 0.7773350477218628\n",
            "Batch 368, Meta-loss: 0.8031597137451172\n",
            "Batch 369, Meta-loss: 0.8557621836662292\n",
            "Batch 370, Meta-loss: 0.7957416772842407\n",
            "Batch 371, Meta-loss: 1.0500562191009521\n",
            "Batch 372, Meta-loss: 0.860012412071228\n",
            "Batch 373, Meta-loss: 0.8523880839347839\n",
            "Batch 374, Meta-loss: 0.8192285299301147\n",
            "Batch 375, Meta-loss: 0.8111759424209595\n",
            "Epoch 2\n",
            "Batch 1, Meta-loss: 0.8276429176330566\n",
            "Batch 2, Meta-loss: 0.8752027750015259\n",
            "Batch 3, Meta-loss: 0.8283001184463501\n",
            "Batch 4, Meta-loss: 0.763411819934845\n",
            "Batch 5, Meta-loss: 0.9289838671684265\n",
            "Batch 6, Meta-loss: 0.9360696077346802\n",
            "Batch 7, Meta-loss: 0.9837095141410828\n",
            "Batch 8, Meta-loss: 0.800906777381897\n",
            "Batch 9, Meta-loss: 0.7034397125244141\n",
            "Batch 10, Meta-loss: 0.788577675819397\n",
            "Batch 11, Meta-loss: 0.7937605977058411\n",
            "Batch 12, Meta-loss: 0.7250713109970093\n",
            "Batch 13, Meta-loss: 0.8244954943656921\n",
            "Batch 14, Meta-loss: 0.8793718218803406\n",
            "Batch 15, Meta-loss: 0.6957401037216187\n",
            "Batch 16, Meta-loss: 0.767368495464325\n",
            "Batch 17, Meta-loss: 0.6990900635719299\n",
            "Batch 18, Meta-loss: 0.7114427089691162\n",
            "Batch 19, Meta-loss: 0.6833091378211975\n",
            "Batch 20, Meta-loss: 0.7179046869277954\n",
            "Batch 21, Meta-loss: 0.566535234451294\n",
            "Batch 22, Meta-loss: 0.7071452140808105\n",
            "Batch 23, Meta-loss: 0.7103407979011536\n",
            "Batch 24, Meta-loss: 0.8102736473083496\n",
            "Batch 25, Meta-loss: 0.6111208200454712\n",
            "Batch 26, Meta-loss: 0.6376959085464478\n",
            "Batch 27, Meta-loss: 0.594913125038147\n",
            "Batch 28, Meta-loss: 0.7771920561790466\n",
            "Batch 29, Meta-loss: 0.5727831125259399\n",
            "Batch 30, Meta-loss: 0.8140566945075989\n",
            "Batch 31, Meta-loss: 0.635120153427124\n",
            "Batch 32, Meta-loss: 0.8125385046005249\n",
            "Batch 33, Meta-loss: 0.6382699012756348\n",
            "Batch 34, Meta-loss: 0.6857028007507324\n",
            "Batch 35, Meta-loss: 0.5961945056915283\n",
            "Batch 36, Meta-loss: 0.665603756904602\n",
            "Batch 37, Meta-loss: 0.6553550958633423\n",
            "Batch 38, Meta-loss: 0.9648111462593079\n",
            "Batch 39, Meta-loss: 0.84393709897995\n",
            "Batch 40, Meta-loss: 0.6122795343399048\n",
            "Batch 41, Meta-loss: 0.6875501275062561\n",
            "Batch 42, Meta-loss: 0.8400806188583374\n",
            "Batch 43, Meta-loss: 0.544437050819397\n",
            "Batch 44, Meta-loss: 0.7990373373031616\n",
            "Batch 45, Meta-loss: 0.7434903979301453\n",
            "Batch 46, Meta-loss: 0.697773814201355\n",
            "Batch 47, Meta-loss: 0.6286276578903198\n",
            "Batch 48, Meta-loss: 0.5851610898971558\n",
            "Batch 49, Meta-loss: 0.7365584969520569\n",
            "Batch 50, Meta-loss: 0.6828233003616333\n",
            "Batch 51, Meta-loss: 0.6136656999588013\n",
            "Batch 52, Meta-loss: 0.8861885070800781\n",
            "Batch 53, Meta-loss: 0.7965507507324219\n",
            "Batch 54, Meta-loss: 0.6675604581832886\n",
            "Batch 55, Meta-loss: 0.7965684533119202\n",
            "Batch 56, Meta-loss: 0.7534512877464294\n",
            "Batch 57, Meta-loss: 0.8588258028030396\n",
            "Batch 58, Meta-loss: 0.8442408442497253\n",
            "Batch 59, Meta-loss: 0.6392468214035034\n",
            "Batch 60, Meta-loss: 0.8277755975723267\n",
            "Batch 61, Meta-loss: 0.7352110147476196\n",
            "Batch 62, Meta-loss: 0.6661459803581238\n",
            "Batch 63, Meta-loss: 0.6636967062950134\n",
            "Batch 64, Meta-loss: 0.7056112885475159\n",
            "Batch 65, Meta-loss: 0.679853081703186\n",
            "Batch 66, Meta-loss: 0.6795211434364319\n",
            "Batch 67, Meta-loss: 0.8135645985603333\n",
            "Batch 68, Meta-loss: 0.8666787147521973\n",
            "Batch 69, Meta-loss: 0.6803784370422363\n",
            "Batch 70, Meta-loss: 0.6695059537887573\n",
            "Batch 71, Meta-loss: 0.8117392659187317\n",
            "Batch 72, Meta-loss: 0.6697210073471069\n",
            "Batch 73, Meta-loss: 0.6367380023002625\n",
            "Batch 74, Meta-loss: 0.610049307346344\n",
            "Batch 75, Meta-loss: 0.7445681691169739\n",
            "Batch 76, Meta-loss: 0.8220803141593933\n",
            "Batch 77, Meta-loss: 0.6505026817321777\n",
            "Batch 78, Meta-loss: 0.7940505743026733\n",
            "Batch 79, Meta-loss: 0.7349914312362671\n",
            "Batch 80, Meta-loss: 0.6239210963249207\n",
            "Batch 81, Meta-loss: 0.778581440448761\n",
            "Batch 82, Meta-loss: 0.688334584236145\n",
            "Batch 83, Meta-loss: 0.7395208477973938\n",
            "Batch 84, Meta-loss: 0.7230677008628845\n",
            "Batch 85, Meta-loss: 0.8014324307441711\n",
            "Batch 86, Meta-loss: 0.7770166397094727\n",
            "Batch 87, Meta-loss: 0.7126592397689819\n",
            "Batch 88, Meta-loss: 0.6824443340301514\n",
            "Batch 89, Meta-loss: 0.7147573232650757\n",
            "Batch 90, Meta-loss: 0.7235449552536011\n",
            "Batch 91, Meta-loss: 0.7958463430404663\n",
            "Batch 92, Meta-loss: 0.7955706715583801\n",
            "Batch 93, Meta-loss: 0.7265101671218872\n",
            "Batch 94, Meta-loss: 0.6259538531303406\n",
            "Batch 95, Meta-loss: 0.6843814253807068\n",
            "Batch 96, Meta-loss: 0.6777207255363464\n",
            "Batch 97, Meta-loss: 0.8289971351623535\n",
            "Batch 98, Meta-loss: 0.629690945148468\n",
            "Batch 99, Meta-loss: 0.7463047504425049\n",
            "Batch 100, Meta-loss: 0.6659015417098999\n",
            "Batch 101, Meta-loss: 0.7619712352752686\n",
            "Batch 102, Meta-loss: 0.6869949102401733\n",
            "Batch 103, Meta-loss: 0.7396937012672424\n",
            "Batch 104, Meta-loss: 0.7132168412208557\n",
            "Batch 105, Meta-loss: 0.7501926422119141\n",
            "Batch 106, Meta-loss: 0.7394068837165833\n",
            "Batch 107, Meta-loss: 0.6769994497299194\n",
            "Batch 108, Meta-loss: 0.6859043836593628\n",
            "Batch 109, Meta-loss: 0.8053838610649109\n",
            "Batch 110, Meta-loss: 0.7440735101699829\n",
            "Batch 111, Meta-loss: 0.6911357641220093\n",
            "Batch 112, Meta-loss: 0.7942461371421814\n",
            "Batch 113, Meta-loss: 0.8186393976211548\n",
            "Batch 114, Meta-loss: 0.7445176839828491\n",
            "Batch 115, Meta-loss: 0.7902434468269348\n",
            "Batch 116, Meta-loss: 0.9735499620437622\n",
            "Batch 117, Meta-loss: 0.9034895896911621\n",
            "Batch 118, Meta-loss: 0.8245798349380493\n",
            "Batch 119, Meta-loss: 0.6379686594009399\n",
            "Batch 120, Meta-loss: 0.7062833309173584\n",
            "Batch 121, Meta-loss: 0.8335277438163757\n",
            "Batch 122, Meta-loss: 0.7442346811294556\n",
            "Batch 123, Meta-loss: 0.8366901278495789\n",
            "Batch 124, Meta-loss: 0.7200166583061218\n",
            "Batch 125, Meta-loss: 0.7510482668876648\n",
            "Batch 126, Meta-loss: 0.8781000971794128\n",
            "Batch 127, Meta-loss: 0.773966372013092\n",
            "Batch 128, Meta-loss: 0.7849127650260925\n",
            "Batch 129, Meta-loss: 0.8226505517959595\n",
            "Batch 130, Meta-loss: 0.888886570930481\n",
            "Batch 131, Meta-loss: 0.8644645810127258\n",
            "Batch 132, Meta-loss: 0.6886376142501831\n",
            "Batch 133, Meta-loss: 0.7720074653625488\n",
            "Batch 134, Meta-loss: 0.7605117559432983\n",
            "Batch 135, Meta-loss: 0.7129358649253845\n",
            "Batch 136, Meta-loss: 0.7976528406143188\n",
            "Batch 137, Meta-loss: 0.6147664785385132\n",
            "Batch 138, Meta-loss: 0.8815945386886597\n",
            "Batch 139, Meta-loss: 0.7395428419113159\n",
            "Batch 140, Meta-loss: 0.7656745910644531\n",
            "Batch 141, Meta-loss: 0.7472215294837952\n",
            "Batch 142, Meta-loss: 0.731343686580658\n",
            "Batch 143, Meta-loss: 0.6822787523269653\n",
            "Batch 144, Meta-loss: 0.6923831701278687\n",
            "Batch 145, Meta-loss: 0.8848320841789246\n",
            "Batch 146, Meta-loss: 0.749971866607666\n",
            "Batch 147, Meta-loss: 0.6936299204826355\n",
            "Batch 148, Meta-loss: 0.6673784852027893\n",
            "Batch 149, Meta-loss: 0.7398274540901184\n",
            "Batch 150, Meta-loss: 0.6702492833137512\n",
            "Batch 151, Meta-loss: 0.7918344736099243\n",
            "Batch 152, Meta-loss: 0.8086034059524536\n",
            "Batch 153, Meta-loss: 0.6819541454315186\n",
            "Batch 154, Meta-loss: 0.7710614204406738\n",
            "Batch 155, Meta-loss: 0.7362140417098999\n",
            "Batch 156, Meta-loss: 0.8642920255661011\n",
            "Batch 157, Meta-loss: 0.8509451150894165\n",
            "Batch 158, Meta-loss: 0.8670212626457214\n",
            "Batch 159, Meta-loss: 0.7798399925231934\n",
            "Batch 160, Meta-loss: 0.7583826184272766\n",
            "Batch 161, Meta-loss: 0.8764750361442566\n",
            "Batch 162, Meta-loss: 0.7578880190849304\n",
            "Batch 163, Meta-loss: 0.8936408758163452\n",
            "Batch 164, Meta-loss: 0.864844024181366\n",
            "Batch 165, Meta-loss: 0.7977220416069031\n",
            "Batch 166, Meta-loss: 0.7790719270706177\n",
            "Batch 167, Meta-loss: 0.7089124917984009\n",
            "Batch 168, Meta-loss: 0.8077369928359985\n",
            "Batch 169, Meta-loss: 0.7882057428359985\n",
            "Batch 170, Meta-loss: 0.7129408121109009\n",
            "Batch 171, Meta-loss: 0.7383459806442261\n",
            "Batch 172, Meta-loss: 0.907483696937561\n",
            "Batch 173, Meta-loss: 0.7922724485397339\n",
            "Batch 174, Meta-loss: 0.8414818048477173\n",
            "Batch 175, Meta-loss: 0.8005542755126953\n",
            "Batch 176, Meta-loss: 0.7770109176635742\n",
            "Batch 177, Meta-loss: 0.6931103467941284\n",
            "Batch 178, Meta-loss: 0.7520209550857544\n",
            "Batch 179, Meta-loss: 0.8051910400390625\n",
            "Batch 180, Meta-loss: 0.7222486138343811\n",
            "Batch 181, Meta-loss: 0.8323748707771301\n",
            "Batch 182, Meta-loss: 0.7039468288421631\n",
            "Batch 183, Meta-loss: 0.7569884657859802\n",
            "Batch 184, Meta-loss: 0.8911474943161011\n",
            "Batch 185, Meta-loss: 0.8478554487228394\n",
            "Batch 186, Meta-loss: 0.8843231201171875\n",
            "Batch 187, Meta-loss: 0.6605581045150757\n",
            "Batch 188, Meta-loss: 0.8951325416564941\n",
            "Batch 189, Meta-loss: 0.7247970700263977\n",
            "Batch 190, Meta-loss: 0.7766501903533936\n",
            "Batch 191, Meta-loss: 0.7361053228378296\n",
            "Batch 192, Meta-loss: 0.8901829719543457\n",
            "Batch 193, Meta-loss: 0.746788501739502\n",
            "Batch 194, Meta-loss: 0.89696204662323\n",
            "Batch 195, Meta-loss: 0.8532005548477173\n",
            "Batch 196, Meta-loss: 0.739512026309967\n",
            "Batch 197, Meta-loss: 0.7223609685897827\n",
            "Batch 198, Meta-loss: 0.6890022158622742\n",
            "Batch 199, Meta-loss: 0.6957520842552185\n",
            "Batch 200, Meta-loss: 0.8045897483825684\n",
            "Batch 201, Meta-loss: 0.8491314053535461\n",
            "Batch 202, Meta-loss: 0.8025676012039185\n",
            "Batch 203, Meta-loss: 0.908551812171936\n",
            "Batch 204, Meta-loss: 0.8835964202880859\n",
            "Batch 205, Meta-loss: 0.922032356262207\n",
            "Batch 206, Meta-loss: 0.7115365266799927\n",
            "Batch 207, Meta-loss: 0.6949718594551086\n",
            "Batch 208, Meta-loss: 0.7722862362861633\n",
            "Batch 209, Meta-loss: 0.7860283851623535\n",
            "Batch 210, Meta-loss: 0.6746784448623657\n",
            "Batch 211, Meta-loss: 0.7051559686660767\n",
            "Batch 212, Meta-loss: 0.8450163006782532\n",
            "Batch 213, Meta-loss: 0.8121789693832397\n",
            "Batch 214, Meta-loss: 0.752941906452179\n",
            "Batch 215, Meta-loss: 0.8970573544502258\n",
            "Batch 216, Meta-loss: 0.8023365139961243\n",
            "Batch 217, Meta-loss: 0.9708458185195923\n",
            "Batch 218, Meta-loss: 0.6641466021537781\n",
            "Batch 219, Meta-loss: 0.8178087472915649\n",
            "Batch 220, Meta-loss: 0.6861323118209839\n",
            "Batch 221, Meta-loss: 0.8850784301757812\n",
            "Batch 222, Meta-loss: 0.9062906503677368\n",
            "Batch 223, Meta-loss: 0.6927462816238403\n",
            "Batch 224, Meta-loss: 0.8213230967521667\n",
            "Batch 225, Meta-loss: 0.6248507499694824\n",
            "Batch 226, Meta-loss: 0.7349967360496521\n",
            "Batch 227, Meta-loss: 0.8960361480712891\n",
            "Batch 228, Meta-loss: 0.7316139936447144\n",
            "Batch 229, Meta-loss: 0.7778940796852112\n",
            "Batch 230, Meta-loss: 0.8201307058334351\n",
            "Batch 231, Meta-loss: 0.7613056898117065\n",
            "Batch 232, Meta-loss: 0.8568035960197449\n",
            "Batch 233, Meta-loss: 0.8075876235961914\n",
            "Batch 234, Meta-loss: 0.7978633046150208\n",
            "Batch 235, Meta-loss: 0.7048468589782715\n",
            "Batch 236, Meta-loss: 0.8408838510513306\n",
            "Batch 237, Meta-loss: 0.6642332077026367\n",
            "Batch 238, Meta-loss: 0.811837375164032\n",
            "Batch 239, Meta-loss: 0.6690301895141602\n",
            "Batch 240, Meta-loss: 0.8477040529251099\n",
            "Batch 241, Meta-loss: 0.7632254362106323\n",
            "Batch 242, Meta-loss: 0.7414563894271851\n",
            "Batch 243, Meta-loss: 0.7382501363754272\n",
            "Batch 244, Meta-loss: 0.8102919459342957\n",
            "Batch 245, Meta-loss: 0.8853555917739868\n",
            "Batch 246, Meta-loss: 0.8040847778320312\n",
            "Batch 247, Meta-loss: 0.8620896339416504\n",
            "Batch 248, Meta-loss: 0.7026674151420593\n",
            "Batch 249, Meta-loss: 0.9018467664718628\n",
            "Batch 250, Meta-loss: 0.7733825445175171\n",
            "Batch 251, Meta-loss: 0.7729402184486389\n",
            "Batch 252, Meta-loss: 0.8563653230667114\n",
            "Batch 253, Meta-loss: 0.7133095860481262\n",
            "Batch 254, Meta-loss: 0.593384861946106\n",
            "Batch 255, Meta-loss: 0.7558013200759888\n",
            "Batch 256, Meta-loss: 0.7888416051864624\n",
            "Batch 257, Meta-loss: 0.8536920547485352\n",
            "Batch 258, Meta-loss: 0.8040684461593628\n",
            "Batch 259, Meta-loss: 0.8443930745124817\n",
            "Batch 260, Meta-loss: 0.8159966468811035\n",
            "Batch 261, Meta-loss: 0.8389639854431152\n",
            "Batch 262, Meta-loss: 0.8390178680419922\n",
            "Batch 263, Meta-loss: 0.7077624201774597\n",
            "Batch 264, Meta-loss: 0.7569313049316406\n",
            "Batch 265, Meta-loss: 0.8090457916259766\n",
            "Batch 266, Meta-loss: 0.8439393043518066\n",
            "Batch 267, Meta-loss: 0.8748807907104492\n",
            "Batch 268, Meta-loss: 0.8088468313217163\n",
            "Batch 269, Meta-loss: 0.7934123277664185\n",
            "Batch 270, Meta-loss: 0.8387691378593445\n",
            "Batch 271, Meta-loss: 0.7663478851318359\n",
            "Batch 272, Meta-loss: 0.8410714268684387\n",
            "Batch 273, Meta-loss: 0.822870135307312\n",
            "Batch 274, Meta-loss: 0.8515399098396301\n",
            "Batch 275, Meta-loss: 0.9020293951034546\n",
            "Batch 276, Meta-loss: 0.8383238911628723\n",
            "Batch 277, Meta-loss: 0.842939555644989\n",
            "Batch 278, Meta-loss: 0.8069078326225281\n",
            "Batch 279, Meta-loss: 0.7526675462722778\n",
            "Batch 280, Meta-loss: 0.6547319293022156\n",
            "Batch 281, Meta-loss: 0.7756232023239136\n",
            "Batch 282, Meta-loss: 0.7180196642875671\n",
            "Batch 283, Meta-loss: 0.7247259020805359\n",
            "Batch 284, Meta-loss: 0.7640503644943237\n",
            "Batch 285, Meta-loss: 0.8144105672836304\n",
            "Batch 286, Meta-loss: 0.8429023027420044\n",
            "Batch 287, Meta-loss: 0.743556022644043\n",
            "Batch 288, Meta-loss: 0.8206735849380493\n",
            "Batch 289, Meta-loss: 0.7232101559638977\n",
            "Batch 290, Meta-loss: 0.7869822978973389\n",
            "Batch 291, Meta-loss: 0.735584557056427\n",
            "Batch 292, Meta-loss: 0.8160241842269897\n",
            "Batch 293, Meta-loss: 0.842820942401886\n",
            "Batch 294, Meta-loss: 0.9308532476425171\n",
            "Batch 295, Meta-loss: 0.7553867697715759\n",
            "Batch 296, Meta-loss: 0.879930317401886\n",
            "Batch 297, Meta-loss: 0.8286887407302856\n",
            "Batch 298, Meta-loss: 0.7692359685897827\n",
            "Batch 299, Meta-loss: 1.0073922872543335\n",
            "Batch 300, Meta-loss: 0.9496880769729614\n",
            "Batch 301, Meta-loss: 0.651639997959137\n",
            "Batch 302, Meta-loss: 0.8055536150932312\n",
            "Batch 303, Meta-loss: 0.7675943374633789\n",
            "Batch 304, Meta-loss: 0.7478376626968384\n",
            "Batch 305, Meta-loss: 0.8111166954040527\n",
            "Batch 306, Meta-loss: 0.815285861492157\n",
            "Batch 307, Meta-loss: 0.7918621301651001\n",
            "Batch 308, Meta-loss: 0.817191481590271\n",
            "Batch 309, Meta-loss: 0.7751761078834534\n",
            "Batch 310, Meta-loss: 0.928918719291687\n",
            "Batch 311, Meta-loss: 0.7630997896194458\n",
            "Batch 312, Meta-loss: 0.9911338686943054\n",
            "Batch 313, Meta-loss: 0.8302141427993774\n",
            "Batch 314, Meta-loss: 0.7990483641624451\n",
            "Batch 315, Meta-loss: 0.672632098197937\n",
            "Batch 316, Meta-loss: 0.8359394073486328\n",
            "Batch 317, Meta-loss: 0.7206249833106995\n",
            "Batch 318, Meta-loss: 0.9407879114151001\n",
            "Batch 319, Meta-loss: 0.7884594202041626\n",
            "Batch 320, Meta-loss: 0.8353704214096069\n",
            "Batch 321, Meta-loss: 0.8398609161376953\n",
            "Batch 322, Meta-loss: 0.9307258725166321\n",
            "Batch 323, Meta-loss: 0.6798160076141357\n",
            "Batch 324, Meta-loss: 0.7635356187820435\n",
            "Batch 325, Meta-loss: 0.7645676136016846\n",
            "Batch 326, Meta-loss: 0.8341574668884277\n",
            "Batch 327, Meta-loss: 0.8816201090812683\n",
            "Batch 328, Meta-loss: 0.8068893551826477\n",
            "Batch 329, Meta-loss: 0.8847402334213257\n",
            "Batch 330, Meta-loss: 0.785886287689209\n",
            "Batch 331, Meta-loss: 0.7671759128570557\n",
            "Batch 332, Meta-loss: 0.8016262054443359\n",
            "Batch 333, Meta-loss: 0.8498170971870422\n",
            "Batch 334, Meta-loss: 0.6599796414375305\n",
            "Batch 335, Meta-loss: 0.9783627390861511\n",
            "Batch 336, Meta-loss: 0.7681938409805298\n",
            "Batch 337, Meta-loss: 0.8311079144477844\n",
            "Batch 338, Meta-loss: 0.7959011197090149\n",
            "Batch 339, Meta-loss: 0.7599161267280579\n",
            "Batch 340, Meta-loss: 0.8683925867080688\n",
            "Batch 341, Meta-loss: 0.8793012499809265\n",
            "Batch 342, Meta-loss: 0.7213509678840637\n",
            "Batch 343, Meta-loss: 0.986293613910675\n",
            "Batch 344, Meta-loss: 0.7896267771720886\n",
            "Batch 345, Meta-loss: 0.7234223484992981\n",
            "Batch 346, Meta-loss: 0.7618985176086426\n",
            "Batch 347, Meta-loss: 0.7427223920822144\n",
            "Batch 348, Meta-loss: 0.9886897206306458\n",
            "Batch 349, Meta-loss: 0.7774942517280579\n",
            "Batch 350, Meta-loss: 0.8426469564437866\n",
            "Batch 351, Meta-loss: 0.7423982620239258\n",
            "Batch 352, Meta-loss: 0.6715652346611023\n",
            "Batch 353, Meta-loss: 0.687603771686554\n",
            "Batch 354, Meta-loss: 0.8373397588729858\n",
            "Batch 355, Meta-loss: 0.9280251264572144\n",
            "Batch 356, Meta-loss: 0.9151204824447632\n",
            "Batch 357, Meta-loss: 0.6968569755554199\n",
            "Batch 358, Meta-loss: 0.7791200876235962\n",
            "Batch 359, Meta-loss: 0.7967492341995239\n",
            "Batch 360, Meta-loss: 0.7018407583236694\n",
            "Batch 361, Meta-loss: 0.9364681243896484\n",
            "Batch 362, Meta-loss: 0.7252968549728394\n",
            "Batch 363, Meta-loss: 0.7498499751091003\n",
            "Batch 364, Meta-loss: 0.683249831199646\n",
            "Batch 365, Meta-loss: 0.9021013379096985\n",
            "Batch 366, Meta-loss: 0.6766317486763\n",
            "Batch 367, Meta-loss: 0.8366957902908325\n",
            "Batch 368, Meta-loss: 0.715533971786499\n",
            "Batch 369, Meta-loss: 0.794724702835083\n",
            "Batch 370, Meta-loss: 0.7802683711051941\n",
            "Batch 371, Meta-loss: 0.9805509448051453\n",
            "Batch 372, Meta-loss: 0.7460709810256958\n",
            "Batch 373, Meta-loss: 0.7487988471984863\n",
            "Batch 374, Meta-loss: 0.865537166595459\n",
            "Batch 375, Meta-loss: 0.7965878248214722\n",
            "Epoch 3\n",
            "Batch 1, Meta-loss: 0.8042057752609253\n",
            "Batch 2, Meta-loss: 0.8252924084663391\n",
            "Batch 3, Meta-loss: 0.8909632563591003\n",
            "Batch 4, Meta-loss: 0.710166335105896\n",
            "Batch 5, Meta-loss: 0.8676353693008423\n",
            "Batch 6, Meta-loss: 0.7054728269577026\n",
            "Batch 7, Meta-loss: 0.7643486261367798\n",
            "Batch 8, Meta-loss: 0.7818154096603394\n",
            "Batch 9, Meta-loss: 0.9313812255859375\n",
            "Batch 10, Meta-loss: 0.7185744047164917\n",
            "Batch 11, Meta-loss: 0.8282710909843445\n",
            "Batch 12, Meta-loss: 0.7255361080169678\n",
            "Batch 13, Meta-loss: 0.6219462752342224\n",
            "Batch 14, Meta-loss: 0.8889816999435425\n",
            "Batch 15, Meta-loss: 0.7015824913978577\n",
            "Batch 16, Meta-loss: 0.7176820635795593\n",
            "Batch 17, Meta-loss: 0.7610831260681152\n",
            "Batch 18, Meta-loss: 0.8321805000305176\n",
            "Batch 19, Meta-loss: 0.7320743799209595\n",
            "Batch 20, Meta-loss: 0.7077022790908813\n",
            "Batch 21, Meta-loss: 0.7399708032608032\n",
            "Batch 22, Meta-loss: 0.6915543675422668\n",
            "Batch 23, Meta-loss: 0.6432622671127319\n",
            "Batch 24, Meta-loss: 0.8070680499076843\n",
            "Batch 25, Meta-loss: 0.7899557948112488\n",
            "Batch 26, Meta-loss: 0.6748641729354858\n",
            "Batch 27, Meta-loss: 0.7274340987205505\n",
            "Batch 28, Meta-loss: 0.7009154558181763\n",
            "Batch 29, Meta-loss: 0.7098342776298523\n",
            "Batch 30, Meta-loss: 0.6669420003890991\n",
            "Batch 31, Meta-loss: 0.720305323600769\n",
            "Batch 32, Meta-loss: 0.6991807818412781\n",
            "Batch 33, Meta-loss: 0.7302069067955017\n",
            "Batch 34, Meta-loss: 0.5551828145980835\n",
            "Batch 35, Meta-loss: 0.7073537111282349\n",
            "Batch 36, Meta-loss: 0.5713793635368347\n",
            "Batch 37, Meta-loss: 0.6076003313064575\n",
            "Batch 38, Meta-loss: 0.6574527621269226\n",
            "Batch 39, Meta-loss: 0.7239452004432678\n",
            "Batch 40, Meta-loss: 0.7189866900444031\n",
            "Batch 41, Meta-loss: 0.6987496614456177\n",
            "Batch 42, Meta-loss: 0.6791509389877319\n",
            "Batch 43, Meta-loss: 0.6383666396141052\n",
            "Batch 44, Meta-loss: 0.8192459344863892\n",
            "Batch 45, Meta-loss: 0.6267968416213989\n",
            "Batch 46, Meta-loss: 0.8188444375991821\n",
            "Batch 47, Meta-loss: 0.8006080389022827\n",
            "Batch 48, Meta-loss: 0.6806830167770386\n",
            "Batch 49, Meta-loss: 0.7798574566841125\n",
            "Batch 50, Meta-loss: 0.6493170857429504\n",
            "Batch 51, Meta-loss: 0.7086326479911804\n",
            "Batch 52, Meta-loss: 0.8164060711860657\n",
            "Batch 53, Meta-loss: 0.7347760200500488\n",
            "Batch 54, Meta-loss: 0.7531881332397461\n",
            "Batch 55, Meta-loss: 0.7106630206108093\n",
            "Batch 56, Meta-loss: 0.686806857585907\n",
            "Batch 57, Meta-loss: 0.6428800821304321\n",
            "Batch 58, Meta-loss: 0.9102071523666382\n",
            "Batch 59, Meta-loss: 0.5963925123214722\n",
            "Batch 60, Meta-loss: 0.649118185043335\n",
            "Batch 61, Meta-loss: 0.5969089269638062\n",
            "Batch 62, Meta-loss: 0.6573322415351868\n",
            "Batch 63, Meta-loss: 0.8807425498962402\n",
            "Batch 64, Meta-loss: 0.7949464917182922\n",
            "Batch 65, Meta-loss: 0.8152621388435364\n",
            "Batch 66, Meta-loss: 0.7416307926177979\n",
            "Batch 67, Meta-loss: 0.6689468622207642\n",
            "Batch 68, Meta-loss: 0.7026553750038147\n",
            "Batch 69, Meta-loss: 0.7006024122238159\n",
            "Batch 70, Meta-loss: 0.6492310762405396\n",
            "Batch 71, Meta-loss: 0.8984001278877258\n",
            "Batch 72, Meta-loss: 0.871616542339325\n",
            "Batch 73, Meta-loss: 0.7830144762992859\n",
            "Batch 74, Meta-loss: 0.6774977445602417\n",
            "Batch 75, Meta-loss: 0.9309598207473755\n",
            "Batch 76, Meta-loss: 0.6096066236495972\n",
            "Batch 77, Meta-loss: 0.8524090051651001\n",
            "Batch 78, Meta-loss: 0.7827752828598022\n",
            "Batch 79, Meta-loss: 0.791103720664978\n",
            "Batch 80, Meta-loss: 0.8426206707954407\n",
            "Batch 81, Meta-loss: 0.7102813720703125\n",
            "Batch 82, Meta-loss: 0.7452724575996399\n",
            "Batch 83, Meta-loss: 0.7938329577445984\n",
            "Batch 84, Meta-loss: 0.7576480507850647\n",
            "Batch 85, Meta-loss: 0.7309237718582153\n",
            "Batch 86, Meta-loss: 0.6299923658370972\n",
            "Batch 87, Meta-loss: 0.7626285552978516\n",
            "Batch 88, Meta-loss: 0.8407928347587585\n",
            "Batch 89, Meta-loss: 0.5642213821411133\n",
            "Batch 90, Meta-loss: 0.8105977773666382\n",
            "Batch 91, Meta-loss: 0.9163364171981812\n",
            "Batch 92, Meta-loss: 0.804474949836731\n",
            "Batch 93, Meta-loss: 0.7205964922904968\n",
            "Batch 94, Meta-loss: 0.7380623817443848\n",
            "Batch 95, Meta-loss: 0.7007726430892944\n",
            "Batch 96, Meta-loss: 0.7890013456344604\n",
            "Batch 97, Meta-loss: 0.8133037686347961\n",
            "Batch 98, Meta-loss: 0.6636924743652344\n",
            "Batch 99, Meta-loss: 0.7386326789855957\n",
            "Batch 100, Meta-loss: 0.7714735269546509\n",
            "Batch 101, Meta-loss: 0.7448340654373169\n",
            "Batch 102, Meta-loss: 0.8650035858154297\n",
            "Batch 103, Meta-loss: 0.8253339529037476\n",
            "Batch 104, Meta-loss: 0.7058992981910706\n",
            "Batch 105, Meta-loss: 0.7828143239021301\n",
            "Batch 106, Meta-loss: 0.709522008895874\n",
            "Batch 107, Meta-loss: 0.6776440739631653\n",
            "Batch 108, Meta-loss: 0.7384442090988159\n",
            "Batch 109, Meta-loss: 0.8038881421089172\n",
            "Batch 110, Meta-loss: 0.7850813865661621\n",
            "Batch 111, Meta-loss: 0.7966895699501038\n",
            "Batch 112, Meta-loss: 0.6168922185897827\n",
            "Batch 113, Meta-loss: 0.8125526309013367\n",
            "Batch 114, Meta-loss: 0.7640211582183838\n",
            "Batch 115, Meta-loss: 1.0246163606643677\n",
            "Batch 116, Meta-loss: 0.7221559882164001\n",
            "Batch 117, Meta-loss: 0.7037535905838013\n",
            "Batch 118, Meta-loss: 0.6504114866256714\n",
            "Batch 119, Meta-loss: 0.7769061326980591\n",
            "Batch 120, Meta-loss: 0.7570316195487976\n",
            "Batch 121, Meta-loss: 0.6994510889053345\n",
            "Batch 122, Meta-loss: 0.7802428007125854\n",
            "Batch 123, Meta-loss: 0.8223227262496948\n",
            "Batch 124, Meta-loss: 0.8156723976135254\n",
            "Batch 125, Meta-loss: 0.7659648656845093\n",
            "Batch 126, Meta-loss: 0.8833667635917664\n",
            "Batch 127, Meta-loss: 0.8276796340942383\n",
            "Batch 128, Meta-loss: 0.788239061832428\n",
            "Batch 129, Meta-loss: 0.6308321356773376\n",
            "Batch 130, Meta-loss: 0.9186693429946899\n",
            "Batch 131, Meta-loss: 0.8165820837020874\n",
            "Batch 132, Meta-loss: 0.8800475001335144\n",
            "Batch 133, Meta-loss: 0.6554720401763916\n",
            "Batch 134, Meta-loss: 0.7281979322433472\n",
            "Batch 135, Meta-loss: 0.8155668377876282\n",
            "Batch 136, Meta-loss: 0.6609915494918823\n",
            "Batch 137, Meta-loss: 0.8416431546211243\n",
            "Batch 138, Meta-loss: 0.7492806315422058\n",
            "Batch 139, Meta-loss: 0.6664000153541565\n",
            "Batch 140, Meta-loss: 0.7772015929222107\n",
            "Batch 141, Meta-loss: 0.6931201219558716\n",
            "Batch 142, Meta-loss: 0.709160566329956\n",
            "Batch 143, Meta-loss: 0.7965380549430847\n",
            "Batch 144, Meta-loss: 1.0279064178466797\n",
            "Batch 145, Meta-loss: 0.9363471865653992\n",
            "Batch 146, Meta-loss: 0.7611440420150757\n",
            "Batch 147, Meta-loss: 0.7597306370735168\n",
            "Batch 148, Meta-loss: 0.851898193359375\n",
            "Batch 149, Meta-loss: 0.8312056660652161\n",
            "Batch 150, Meta-loss: 0.70124351978302\n",
            "Batch 151, Meta-loss: 0.7233161926269531\n",
            "Batch 152, Meta-loss: 0.8175870776176453\n",
            "Batch 153, Meta-loss: 0.904607892036438\n",
            "Batch 154, Meta-loss: 0.8954825401306152\n",
            "Batch 155, Meta-loss: 1.0383988618850708\n",
            "Batch 156, Meta-loss: 0.7224331498146057\n",
            "Batch 157, Meta-loss: 0.8150439262390137\n",
            "Batch 158, Meta-loss: 0.7093651294708252\n",
            "Batch 159, Meta-loss: 0.7908289432525635\n",
            "Batch 160, Meta-loss: 0.7453910112380981\n",
            "Batch 161, Meta-loss: 0.7378994226455688\n",
            "Batch 162, Meta-loss: 0.827112078666687\n",
            "Batch 163, Meta-loss: 0.6468514204025269\n",
            "Batch 164, Meta-loss: 0.7185821533203125\n",
            "Batch 165, Meta-loss: 0.7728055715560913\n",
            "Batch 166, Meta-loss: 0.8206359148025513\n",
            "Batch 167, Meta-loss: 0.8683420419692993\n",
            "Batch 168, Meta-loss: 0.6806870102882385\n",
            "Batch 169, Meta-loss: 0.7351468801498413\n",
            "Batch 170, Meta-loss: 0.8045889735221863\n",
            "Batch 171, Meta-loss: 0.7241131067276001\n",
            "Batch 172, Meta-loss: 0.7874099016189575\n",
            "Batch 173, Meta-loss: 0.7845748662948608\n",
            "Batch 174, Meta-loss: 0.7623214721679688\n",
            "Batch 175, Meta-loss: 0.729293704032898\n",
            "Batch 176, Meta-loss: 0.7295516133308411\n",
            "Batch 177, Meta-loss: 0.5840854644775391\n",
            "Batch 178, Meta-loss: 0.9643403887748718\n",
            "Batch 179, Meta-loss: 0.8492582440376282\n",
            "Batch 180, Meta-loss: 0.7293545007705688\n",
            "Batch 181, Meta-loss: 0.676537275314331\n",
            "Batch 182, Meta-loss: 0.9642473459243774\n",
            "Batch 183, Meta-loss: 0.8445021510124207\n",
            "Batch 184, Meta-loss: 0.7651633024215698\n",
            "Batch 185, Meta-loss: 0.7191765308380127\n",
            "Batch 186, Meta-loss: 0.8391337394714355\n",
            "Batch 187, Meta-loss: 0.848318874835968\n",
            "Batch 188, Meta-loss: 0.8330113291740417\n",
            "Batch 189, Meta-loss: 0.7585760354995728\n",
            "Batch 190, Meta-loss: 0.8183306455612183\n",
            "Batch 191, Meta-loss: 0.945205569267273\n",
            "Batch 192, Meta-loss: 0.8655754923820496\n",
            "Batch 193, Meta-loss: 0.8287526965141296\n",
            "Batch 194, Meta-loss: 0.8367652893066406\n",
            "Batch 195, Meta-loss: 0.6929730772972107\n",
            "Batch 196, Meta-loss: 0.7900053262710571\n",
            "Batch 197, Meta-loss: 0.8238110542297363\n",
            "Batch 198, Meta-loss: 1.0135893821716309\n",
            "Batch 199, Meta-loss: 0.7022494077682495\n",
            "Batch 200, Meta-loss: 0.7232427000999451\n",
            "Batch 201, Meta-loss: 0.8315857648849487\n",
            "Batch 202, Meta-loss: 0.7190621495246887\n",
            "Batch 203, Meta-loss: 0.8047358393669128\n",
            "Batch 204, Meta-loss: 0.6772769689559937\n",
            "Batch 205, Meta-loss: 0.7759361267089844\n",
            "Batch 206, Meta-loss: 0.7122088670730591\n",
            "Batch 207, Meta-loss: 0.757083535194397\n",
            "Batch 208, Meta-loss: 0.8309733271598816\n",
            "Batch 209, Meta-loss: 0.7302541136741638\n",
            "Batch 210, Meta-loss: 0.788111686706543\n",
            "Batch 211, Meta-loss: 0.8043612241744995\n",
            "Batch 212, Meta-loss: 0.761665940284729\n",
            "Batch 213, Meta-loss: 0.703278660774231\n",
            "Batch 214, Meta-loss: 0.8360737562179565\n",
            "Batch 215, Meta-loss: 0.7281630039215088\n",
            "Batch 216, Meta-loss: 0.8228979110717773\n",
            "Batch 217, Meta-loss: 0.8176285028457642\n",
            "Batch 218, Meta-loss: 0.6955922842025757\n",
            "Batch 219, Meta-loss: 0.6952341794967651\n",
            "Batch 220, Meta-loss: 0.803942084312439\n",
            "Batch 221, Meta-loss: 0.8594067692756653\n",
            "Batch 222, Meta-loss: 0.755639374256134\n",
            "Batch 223, Meta-loss: 0.77637779712677\n",
            "Batch 224, Meta-loss: 0.7577005624771118\n",
            "Batch 225, Meta-loss: 0.745520293712616\n",
            "Batch 226, Meta-loss: 0.7195636630058289\n",
            "Batch 227, Meta-loss: 0.7483517527580261\n",
            "Batch 228, Meta-loss: 0.8803472518920898\n",
            "Batch 229, Meta-loss: 0.7168930172920227\n",
            "Batch 230, Meta-loss: 0.6647576093673706\n",
            "Batch 231, Meta-loss: 0.8657581210136414\n",
            "Batch 232, Meta-loss: 0.8389631509780884\n",
            "Batch 233, Meta-loss: 0.8371168375015259\n",
            "Batch 234, Meta-loss: 0.6492260694503784\n",
            "Batch 235, Meta-loss: 0.7835595607757568\n",
            "Batch 236, Meta-loss: 0.8553701639175415\n",
            "Batch 237, Meta-loss: 0.6769835352897644\n",
            "Batch 238, Meta-loss: 0.7128432989120483\n",
            "Batch 239, Meta-loss: 0.7243518829345703\n",
            "Batch 240, Meta-loss: 0.6810548305511475\n",
            "Batch 241, Meta-loss: 0.7560141682624817\n",
            "Batch 242, Meta-loss: 0.8537890315055847\n",
            "Batch 243, Meta-loss: 0.7482633590698242\n",
            "Batch 244, Meta-loss: 0.7231220602989197\n",
            "Batch 245, Meta-loss: 0.7764474749565125\n",
            "Batch 246, Meta-loss: 0.8187359571456909\n",
            "Batch 247, Meta-loss: 0.6943134069442749\n",
            "Batch 248, Meta-loss: 0.7088608741760254\n",
            "Batch 249, Meta-loss: 0.7059099078178406\n",
            "Batch 250, Meta-loss: 0.8068979978561401\n",
            "Batch 251, Meta-loss: 0.7130976915359497\n",
            "Batch 252, Meta-loss: 0.7450224161148071\n",
            "Batch 253, Meta-loss: 0.9863113164901733\n",
            "Batch 254, Meta-loss: 0.7879859805107117\n",
            "Batch 255, Meta-loss: 0.989163875579834\n",
            "Batch 256, Meta-loss: 0.7887653112411499\n",
            "Batch 257, Meta-loss: 0.7263622879981995\n",
            "Batch 258, Meta-loss: 0.8040415048599243\n",
            "Batch 259, Meta-loss: 0.6741324663162231\n",
            "Batch 260, Meta-loss: 0.7814990282058716\n",
            "Batch 261, Meta-loss: 0.7039097547531128\n",
            "Batch 262, Meta-loss: 0.840314507484436\n",
            "Batch 263, Meta-loss: 0.7873741388320923\n",
            "Batch 264, Meta-loss: 0.893614649772644\n",
            "Batch 265, Meta-loss: 0.8151830434799194\n",
            "Batch 266, Meta-loss: 0.8005583882331848\n",
            "Batch 267, Meta-loss: 0.7498093843460083\n",
            "Batch 268, Meta-loss: 0.8991750478744507\n",
            "Batch 269, Meta-loss: 0.8929036855697632\n",
            "Batch 270, Meta-loss: 0.7868277430534363\n",
            "Batch 271, Meta-loss: 0.7836689352989197\n",
            "Batch 272, Meta-loss: 0.7908467054367065\n",
            "Batch 273, Meta-loss: 0.8865752220153809\n",
            "Batch 274, Meta-loss: 0.7859426736831665\n",
            "Batch 275, Meta-loss: 0.7019402384757996\n",
            "Batch 276, Meta-loss: 0.6855229735374451\n",
            "Batch 277, Meta-loss: 0.9159337282180786\n",
            "Batch 278, Meta-loss: 0.8337124586105347\n",
            "Batch 279, Meta-loss: 0.6363996267318726\n",
            "Batch 280, Meta-loss: 0.8785613775253296\n",
            "Batch 281, Meta-loss: 0.7831982374191284\n",
            "Batch 282, Meta-loss: 0.7959707379341125\n",
            "Batch 283, Meta-loss: 0.8323750495910645\n",
            "Batch 284, Meta-loss: 0.7844986915588379\n",
            "Batch 285, Meta-loss: 0.8437690734863281\n",
            "Batch 286, Meta-loss: 0.7763456106185913\n",
            "Batch 287, Meta-loss: 0.7306857109069824\n",
            "Batch 288, Meta-loss: 0.8905754089355469\n",
            "Batch 289, Meta-loss: 0.7728322148323059\n",
            "Batch 290, Meta-loss: 0.6906282901763916\n",
            "Batch 291, Meta-loss: 0.8438947796821594\n",
            "Batch 292, Meta-loss: 0.8581964373588562\n",
            "Batch 293, Meta-loss: 0.8292876482009888\n",
            "Batch 294, Meta-loss: 0.9101923704147339\n",
            "Batch 295, Meta-loss: 0.7754946947097778\n",
            "Batch 296, Meta-loss: 0.7175325155258179\n",
            "Batch 297, Meta-loss: 0.913031280040741\n",
            "Batch 298, Meta-loss: 0.8525893092155457\n",
            "Batch 299, Meta-loss: 0.920534610748291\n",
            "Batch 300, Meta-loss: 0.9318584203720093\n",
            "Batch 301, Meta-loss: 0.6735613942146301\n",
            "Batch 302, Meta-loss: 0.7173349261283875\n",
            "Batch 303, Meta-loss: 0.8057893514633179\n",
            "Batch 304, Meta-loss: 0.9370294809341431\n",
            "Batch 305, Meta-loss: 0.8438330888748169\n",
            "Batch 306, Meta-loss: 0.7857798337936401\n",
            "Batch 307, Meta-loss: 0.7861794829368591\n",
            "Batch 308, Meta-loss: 0.7283246517181396\n",
            "Batch 309, Meta-loss: 0.6722046136856079\n",
            "Batch 310, Meta-loss: 0.782520055770874\n",
            "Batch 311, Meta-loss: 0.7689865231513977\n",
            "Batch 312, Meta-loss: 0.7978827357292175\n",
            "Batch 313, Meta-loss: 0.8377130627632141\n",
            "Batch 314, Meta-loss: 0.8549332618713379\n",
            "Batch 315, Meta-loss: 0.8663827776908875\n",
            "Batch 316, Meta-loss: 0.8154403567314148\n",
            "Batch 317, Meta-loss: 0.8342753648757935\n",
            "Batch 318, Meta-loss: 0.9725023508071899\n",
            "Batch 319, Meta-loss: 0.7289474606513977\n",
            "Batch 320, Meta-loss: 0.8197494745254517\n",
            "Batch 321, Meta-loss: 0.8223322033882141\n",
            "Batch 322, Meta-loss: 0.844512939453125\n",
            "Batch 323, Meta-loss: 0.8556601405143738\n",
            "Batch 324, Meta-loss: 0.8340104818344116\n",
            "Batch 325, Meta-loss: 0.7880526781082153\n",
            "Batch 326, Meta-loss: 0.7428750991821289\n",
            "Batch 327, Meta-loss: 0.8660575151443481\n",
            "Batch 328, Meta-loss: 0.8119572401046753\n",
            "Batch 329, Meta-loss: 0.9847244024276733\n",
            "Batch 330, Meta-loss: 0.8771133422851562\n",
            "Batch 331, Meta-loss: 0.8893786668777466\n",
            "Batch 332, Meta-loss: 0.7359949946403503\n",
            "Batch 333, Meta-loss: 0.8030044436454773\n",
            "Batch 334, Meta-loss: 0.898770809173584\n",
            "Batch 335, Meta-loss: 0.7157889008522034\n",
            "Batch 336, Meta-loss: 0.8238442540168762\n",
            "Batch 337, Meta-loss: 0.9475029110908508\n",
            "Batch 338, Meta-loss: 0.7883250117301941\n",
            "Batch 339, Meta-loss: 0.8081302642822266\n",
            "Batch 340, Meta-loss: 0.6591934561729431\n",
            "Batch 341, Meta-loss: 0.8542966842651367\n",
            "Batch 342, Meta-loss: 0.8176479339599609\n",
            "Batch 343, Meta-loss: 0.9687380790710449\n",
            "Batch 344, Meta-loss: 0.8034701347351074\n",
            "Batch 345, Meta-loss: 0.8925265073776245\n",
            "Batch 346, Meta-loss: 0.8372257947921753\n",
            "Batch 347, Meta-loss: 0.8461664915084839\n",
            "Batch 348, Meta-loss: 0.790488600730896\n",
            "Batch 349, Meta-loss: 0.8502167463302612\n",
            "Batch 350, Meta-loss: 0.8062702417373657\n",
            "Batch 351, Meta-loss: 0.8661383390426636\n",
            "Batch 352, Meta-loss: 0.8305319547653198\n",
            "Batch 353, Meta-loss: 0.723441481590271\n",
            "Batch 354, Meta-loss: 0.8055221438407898\n",
            "Batch 355, Meta-loss: 0.6695119142532349\n",
            "Batch 356, Meta-loss: 0.7682471871376038\n",
            "Batch 357, Meta-loss: 0.7792301177978516\n",
            "Batch 358, Meta-loss: 0.8898745775222778\n",
            "Batch 359, Meta-loss: 0.7301032543182373\n",
            "Batch 360, Meta-loss: 0.7971247434616089\n",
            "Batch 361, Meta-loss: 0.8804596662521362\n",
            "Batch 362, Meta-loss: 0.7943000197410583\n",
            "Batch 363, Meta-loss: 0.8448279500007629\n",
            "Batch 364, Meta-loss: 0.8254988789558411\n",
            "Batch 365, Meta-loss: 0.8019960522651672\n",
            "Batch 366, Meta-loss: 0.7586725950241089\n",
            "Batch 367, Meta-loss: 0.7300854325294495\n",
            "Batch 368, Meta-loss: 0.8140267133712769\n",
            "Batch 369, Meta-loss: 0.8574962615966797\n",
            "Batch 370, Meta-loss: 0.8617594838142395\n",
            "Batch 371, Meta-loss: 0.8836191892623901\n",
            "Batch 372, Meta-loss: 0.7091423869132996\n",
            "Batch 373, Meta-loss: 0.7739594578742981\n",
            "Batch 374, Meta-loss: 0.8638141751289368\n",
            "Batch 375, Meta-loss: 0.7457085847854614\n",
            "Epoch 4\n",
            "Batch 1, Meta-loss: 0.9738537073135376\n",
            "Batch 2, Meta-loss: 0.9606479406356812\n",
            "Batch 3, Meta-loss: 0.7075580358505249\n",
            "Batch 4, Meta-loss: 0.7152616381645203\n",
            "Batch 5, Meta-loss: 0.8172343373298645\n",
            "Batch 6, Meta-loss: 0.8826919794082642\n",
            "Batch 7, Meta-loss: 0.7537361979484558\n",
            "Batch 8, Meta-loss: 0.8487998843193054\n",
            "Batch 9, Meta-loss: 0.7811559438705444\n",
            "Batch 10, Meta-loss: 0.8079558610916138\n",
            "Batch 11, Meta-loss: 0.7558212280273438\n",
            "Batch 12, Meta-loss: 0.8532390594482422\n",
            "Batch 13, Meta-loss: 0.6546792387962341\n",
            "Batch 14, Meta-loss: 0.8071826100349426\n",
            "Batch 15, Meta-loss: 0.8965465426445007\n",
            "Batch 16, Meta-loss: 0.7484937906265259\n",
            "Batch 17, Meta-loss: 0.6470004320144653\n",
            "Batch 18, Meta-loss: 0.7604988813400269\n",
            "Batch 19, Meta-loss: 0.857848048210144\n",
            "Batch 20, Meta-loss: 0.7173658609390259\n",
            "Batch 21, Meta-loss: 0.8001508712768555\n",
            "Batch 22, Meta-loss: 0.7999593019485474\n",
            "Batch 23, Meta-loss: 0.7161462903022766\n",
            "Batch 24, Meta-loss: 0.752339780330658\n",
            "Batch 25, Meta-loss: 0.6136991381645203\n",
            "Batch 26, Meta-loss: 0.7774749398231506\n",
            "Batch 27, Meta-loss: 0.6792055368423462\n",
            "Batch 28, Meta-loss: 0.6941719055175781\n",
            "Batch 29, Meta-loss: 0.6563625335693359\n",
            "Batch 30, Meta-loss: 0.826420783996582\n",
            "Batch 31, Meta-loss: 0.8691883087158203\n",
            "Batch 32, Meta-loss: 0.7144122123718262\n",
            "Batch 33, Meta-loss: 0.7043765783309937\n",
            "Batch 34, Meta-loss: 0.8258973360061646\n",
            "Batch 35, Meta-loss: 0.8491007089614868\n",
            "Batch 36, Meta-loss: 0.7067016363143921\n",
            "Batch 37, Meta-loss: 0.7057221531867981\n",
            "Batch 38, Meta-loss: 0.7529209852218628\n",
            "Batch 39, Meta-loss: 0.6789125204086304\n",
            "Batch 40, Meta-loss: 0.7773350477218628\n",
            "Batch 41, Meta-loss: 0.7582913637161255\n",
            "Batch 42, Meta-loss: 0.7350300550460815\n",
            "Batch 43, Meta-loss: 0.756962239742279\n",
            "Batch 44, Meta-loss: 0.7830829620361328\n",
            "Batch 45, Meta-loss: 0.6420177817344666\n",
            "Batch 46, Meta-loss: 0.6922730207443237\n",
            "Batch 47, Meta-loss: 0.7075158953666687\n",
            "Batch 48, Meta-loss: 0.8770031929016113\n",
            "Batch 49, Meta-loss: 0.6767032742500305\n",
            "Batch 50, Meta-loss: 0.6686949729919434\n",
            "Batch 51, Meta-loss: 0.6530121564865112\n",
            "Batch 52, Meta-loss: 0.746382474899292\n",
            "Batch 53, Meta-loss: 0.6977000832557678\n",
            "Batch 54, Meta-loss: 0.7793195843696594\n",
            "Batch 55, Meta-loss: 0.6784370541572571\n",
            "Batch 56, Meta-loss: 0.7635219693183899\n",
            "Batch 57, Meta-loss: 0.7134774327278137\n",
            "Batch 58, Meta-loss: 0.736531138420105\n",
            "Batch 59, Meta-loss: 0.6961239576339722\n",
            "Batch 60, Meta-loss: 0.8160770535469055\n",
            "Batch 61, Meta-loss: 0.8563846349716187\n",
            "Batch 62, Meta-loss: 0.7704802751541138\n",
            "Batch 63, Meta-loss: 0.7798632383346558\n",
            "Batch 64, Meta-loss: 0.7670173645019531\n",
            "Batch 65, Meta-loss: 0.8122214078903198\n",
            "Batch 66, Meta-loss: 0.8056585192680359\n",
            "Batch 67, Meta-loss: 0.8543931245803833\n",
            "Batch 68, Meta-loss: 0.7855950593948364\n",
            "Batch 69, Meta-loss: 0.6789752244949341\n",
            "Batch 70, Meta-loss: 0.920700192451477\n",
            "Batch 71, Meta-loss: 0.8918410539627075\n",
            "Batch 72, Meta-loss: 0.8894997835159302\n",
            "Batch 73, Meta-loss: 0.8836557269096375\n",
            "Batch 74, Meta-loss: 0.665166974067688\n",
            "Batch 75, Meta-loss: 0.738308846950531\n",
            "Batch 76, Meta-loss: 0.8626540899276733\n",
            "Batch 77, Meta-loss: 0.8235088586807251\n",
            "Batch 78, Meta-loss: 0.767035961151123\n",
            "Batch 79, Meta-loss: 0.6343256235122681\n",
            "Batch 80, Meta-loss: 0.8832576870918274\n",
            "Batch 81, Meta-loss: 0.7386952042579651\n",
            "Batch 82, Meta-loss: 0.6762023568153381\n",
            "Batch 83, Meta-loss: 0.7108850479125977\n",
            "Batch 84, Meta-loss: 0.7908327579498291\n",
            "Batch 85, Meta-loss: 0.853927731513977\n",
            "Batch 86, Meta-loss: 0.7420713901519775\n",
            "Batch 87, Meta-loss: 0.6637512445449829\n",
            "Batch 88, Meta-loss: 0.7027713060379028\n",
            "Batch 89, Meta-loss: 0.7114578485488892\n",
            "Batch 90, Meta-loss: 0.7371148467063904\n",
            "Batch 91, Meta-loss: 0.8429558873176575\n",
            "Batch 92, Meta-loss: 0.855891227722168\n",
            "Batch 93, Meta-loss: 0.7676280736923218\n",
            "Batch 94, Meta-loss: 0.7910025119781494\n",
            "Batch 95, Meta-loss: 0.8222783803939819\n",
            "Batch 96, Meta-loss: 0.8561402559280396\n",
            "Batch 97, Meta-loss: 0.6344873905181885\n",
            "Batch 98, Meta-loss: 0.8309398889541626\n",
            "Batch 99, Meta-loss: 0.8407929539680481\n",
            "Batch 100, Meta-loss: 0.7792238593101501\n",
            "Batch 101, Meta-loss: 0.8430637121200562\n",
            "Batch 102, Meta-loss: 0.7552611231803894\n",
            "Batch 103, Meta-loss: 0.6742700338363647\n",
            "Batch 104, Meta-loss: 0.7401712536811829\n",
            "Batch 105, Meta-loss: 0.8280452489852905\n",
            "Batch 106, Meta-loss: 0.9472843408584595\n",
            "Batch 107, Meta-loss: 0.7343111038208008\n",
            "Batch 108, Meta-loss: 0.8603213429450989\n",
            "Batch 109, Meta-loss: 0.7519142627716064\n",
            "Batch 110, Meta-loss: 0.6720244288444519\n",
            "Batch 111, Meta-loss: 0.753881573677063\n",
            "Batch 112, Meta-loss: 0.7482870817184448\n",
            "Batch 113, Meta-loss: 0.7566326856613159\n",
            "Batch 114, Meta-loss: 0.7185584306716919\n",
            "Batch 115, Meta-loss: 0.7306642532348633\n",
            "Batch 116, Meta-loss: 0.7536314129829407\n",
            "Batch 117, Meta-loss: 0.8893296122550964\n",
            "Batch 118, Meta-loss: 0.7739620804786682\n",
            "Batch 119, Meta-loss: 0.692477822303772\n",
            "Batch 120, Meta-loss: 0.7474972605705261\n",
            "Batch 121, Meta-loss: 0.7070938348770142\n",
            "Batch 122, Meta-loss: 0.7696890830993652\n",
            "Batch 123, Meta-loss: 0.7334621548652649\n",
            "Batch 124, Meta-loss: 0.7125045657157898\n",
            "Batch 125, Meta-loss: 0.9565740823745728\n",
            "Batch 126, Meta-loss: 0.7700560688972473\n",
            "Batch 127, Meta-loss: 0.8510152101516724\n",
            "Batch 128, Meta-loss: 0.8974201083183289\n",
            "Batch 129, Meta-loss: 0.8518434762954712\n",
            "Batch 130, Meta-loss: 0.7636825442314148\n",
            "Batch 131, Meta-loss: 0.8614351153373718\n",
            "Batch 132, Meta-loss: 0.7146226763725281\n",
            "Batch 133, Meta-loss: 0.711848258972168\n",
            "Batch 134, Meta-loss: 0.7846537232398987\n",
            "Batch 135, Meta-loss: 0.7567201852798462\n",
            "Batch 136, Meta-loss: 0.7890162467956543\n",
            "Batch 137, Meta-loss: 0.9150153994560242\n",
            "Batch 138, Meta-loss: 0.8345769643783569\n",
            "Batch 139, Meta-loss: 0.7107832431793213\n",
            "Batch 140, Meta-loss: 0.7948782444000244\n",
            "Batch 141, Meta-loss: 0.7468056678771973\n",
            "Batch 142, Meta-loss: 0.7146151661872864\n",
            "Batch 143, Meta-loss: 0.8234955072402954\n",
            "Batch 144, Meta-loss: 0.7466066479682922\n",
            "Batch 145, Meta-loss: 0.7373238801956177\n",
            "Batch 146, Meta-loss: 0.720177173614502\n",
            "Batch 147, Meta-loss: 0.8794687390327454\n",
            "Batch 148, Meta-loss: 0.868608832359314\n",
            "Batch 149, Meta-loss: 0.8100816607475281\n",
            "Batch 150, Meta-loss: 0.8061274290084839\n",
            "Batch 151, Meta-loss: 0.7650655508041382\n",
            "Batch 152, Meta-loss: 0.7260075807571411\n",
            "Batch 153, Meta-loss: 0.8449241518974304\n",
            "Batch 154, Meta-loss: 0.9069092869758606\n",
            "Batch 155, Meta-loss: 0.6977149248123169\n",
            "Batch 156, Meta-loss: 0.7286162376403809\n",
            "Batch 157, Meta-loss: 0.8961410522460938\n",
            "Batch 158, Meta-loss: 0.8199830055236816\n",
            "Batch 159, Meta-loss: 0.8612521290779114\n",
            "Batch 160, Meta-loss: 0.8752330541610718\n",
            "Batch 161, Meta-loss: 0.8552793264389038\n",
            "Batch 162, Meta-loss: 0.8690527081489563\n",
            "Batch 163, Meta-loss: 0.7583476901054382\n",
            "Batch 164, Meta-loss: 0.8592268824577332\n",
            "Batch 165, Meta-loss: 0.891800582408905\n",
            "Batch 166, Meta-loss: 0.8310810327529907\n",
            "Batch 167, Meta-loss: 0.7397979497909546\n",
            "Batch 168, Meta-loss: 0.7145851850509644\n",
            "Batch 169, Meta-loss: 0.7605406641960144\n",
            "Batch 170, Meta-loss: 0.9350509643554688\n",
            "Batch 171, Meta-loss: 0.8066173791885376\n",
            "Batch 172, Meta-loss: 0.937159538269043\n",
            "Batch 173, Meta-loss: 0.8351291418075562\n",
            "Batch 174, Meta-loss: 0.7863301038742065\n",
            "Batch 175, Meta-loss: 0.8317054510116577\n",
            "Batch 176, Meta-loss: 0.8156058192253113\n",
            "Batch 177, Meta-loss: 0.7590106129646301\n",
            "Batch 178, Meta-loss: 0.7857920527458191\n",
            "Batch 179, Meta-loss: 0.7254565954208374\n",
            "Batch 180, Meta-loss: 0.8843616247177124\n",
            "Batch 181, Meta-loss: 0.8433915972709656\n",
            "Batch 182, Meta-loss: 0.8806436657905579\n",
            "Batch 183, Meta-loss: 0.7469218373298645\n",
            "Batch 184, Meta-loss: 0.8584535717964172\n",
            "Batch 185, Meta-loss: 0.9442253112792969\n",
            "Batch 186, Meta-loss: 0.7946200370788574\n",
            "Batch 187, Meta-loss: 0.7942391037940979\n",
            "Batch 188, Meta-loss: 0.80732262134552\n",
            "Batch 189, Meta-loss: 0.7363301515579224\n",
            "Batch 190, Meta-loss: 0.8417165875434875\n",
            "Batch 191, Meta-loss: 0.7209029793739319\n",
            "Batch 192, Meta-loss: 0.835249125957489\n",
            "Batch 193, Meta-loss: 0.8501152992248535\n",
            "Batch 194, Meta-loss: 0.8996185064315796\n",
            "Batch 195, Meta-loss: 0.8519655466079712\n",
            "Batch 196, Meta-loss: 0.7017391324043274\n",
            "Batch 197, Meta-loss: 0.7338947057723999\n",
            "Batch 198, Meta-loss: 0.7344149351119995\n",
            "Batch 199, Meta-loss: 0.798140287399292\n",
            "Batch 200, Meta-loss: 0.8380921483039856\n",
            "Batch 201, Meta-loss: 0.81305992603302\n",
            "Batch 202, Meta-loss: 0.8967084884643555\n",
            "Batch 203, Meta-loss: 0.7968369126319885\n",
            "Batch 204, Meta-loss: 0.7793246507644653\n",
            "Batch 205, Meta-loss: 0.7346483469009399\n",
            "Batch 206, Meta-loss: 0.6971153020858765\n",
            "Batch 207, Meta-loss: 0.7244022488594055\n",
            "Batch 208, Meta-loss: 0.7753521203994751\n",
            "Batch 209, Meta-loss: 0.8750566244125366\n",
            "Batch 210, Meta-loss: 0.9317747354507446\n",
            "Batch 211, Meta-loss: 0.8311346173286438\n",
            "Batch 212, Meta-loss: 0.9400870203971863\n",
            "Batch 213, Meta-loss: 0.7335559725761414\n",
            "Batch 214, Meta-loss: 0.8069364428520203\n",
            "Batch 215, Meta-loss: 0.7360832095146179\n",
            "Batch 216, Meta-loss: 0.7306162118911743\n",
            "Batch 217, Meta-loss: 0.8108524084091187\n",
            "Batch 218, Meta-loss: 0.7212249040603638\n",
            "Batch 219, Meta-loss: 0.8877921104431152\n",
            "Batch 220, Meta-loss: 0.7571703791618347\n",
            "Batch 221, Meta-loss: 0.8293285369873047\n",
            "Batch 222, Meta-loss: 0.6853060126304626\n",
            "Batch 223, Meta-loss: 0.8673197031021118\n",
            "Batch 224, Meta-loss: 0.8657790422439575\n",
            "Batch 225, Meta-loss: 0.7942911386489868\n",
            "Batch 226, Meta-loss: 0.8375400304794312\n",
            "Batch 227, Meta-loss: 0.8910318613052368\n",
            "Batch 228, Meta-loss: 0.719106137752533\n",
            "Batch 229, Meta-loss: 0.8383746147155762\n",
            "Batch 230, Meta-loss: 0.7154077291488647\n",
            "Batch 231, Meta-loss: 0.823004424571991\n",
            "Batch 232, Meta-loss: 0.8685334920883179\n",
            "Batch 233, Meta-loss: 0.7973372340202332\n",
            "Batch 234, Meta-loss: 0.7678124308586121\n",
            "Batch 235, Meta-loss: 0.8260217905044556\n",
            "Batch 236, Meta-loss: 0.7649158239364624\n",
            "Batch 237, Meta-loss: 0.7678648829460144\n",
            "Batch 238, Meta-loss: 0.8034590482711792\n",
            "Batch 239, Meta-loss: 0.9484814405441284\n",
            "Batch 240, Meta-loss: 0.8301395177841187\n",
            "Batch 241, Meta-loss: 0.7369783520698547\n",
            "Batch 242, Meta-loss: 0.7554910778999329\n",
            "Batch 243, Meta-loss: 0.8609145283699036\n",
            "Batch 244, Meta-loss: 0.8767706751823425\n",
            "Batch 245, Meta-loss: 0.8139296770095825\n",
            "Batch 246, Meta-loss: 0.7475336194038391\n",
            "Batch 247, Meta-loss: 0.8377909660339355\n",
            "Batch 248, Meta-loss: 0.7114424705505371\n",
            "Batch 249, Meta-loss: 0.7944573163986206\n",
            "Batch 250, Meta-loss: 0.8585443496704102\n",
            "Batch 251, Meta-loss: 0.8005016446113586\n",
            "Batch 252, Meta-loss: 0.7856594324111938\n",
            "Batch 253, Meta-loss: 0.828094482421875\n",
            "Batch 254, Meta-loss: 0.874881386756897\n",
            "Batch 255, Meta-loss: 0.798676073551178\n",
            "Batch 256, Meta-loss: 0.8330860137939453\n",
            "Batch 257, Meta-loss: 0.8907276391983032\n",
            "Batch 258, Meta-loss: 0.7457868456840515\n",
            "Batch 259, Meta-loss: 0.788769543170929\n",
            "Batch 260, Meta-loss: 0.6359740495681763\n",
            "Batch 261, Meta-loss: 0.8953069448471069\n",
            "Batch 262, Meta-loss: 0.7443594336509705\n",
            "Batch 263, Meta-loss: 0.8935531377792358\n",
            "Batch 264, Meta-loss: 0.7757260799407959\n",
            "Batch 265, Meta-loss: 0.8158991932868958\n",
            "Batch 266, Meta-loss: 0.9504963755607605\n",
            "Batch 267, Meta-loss: 0.8605998754501343\n",
            "Batch 268, Meta-loss: 0.8138328790664673\n",
            "Batch 269, Meta-loss: 0.951068103313446\n",
            "Batch 270, Meta-loss: 0.8021724820137024\n",
            "Batch 271, Meta-loss: 0.8064596056938171\n",
            "Batch 272, Meta-loss: 0.7899671792984009\n",
            "Batch 273, Meta-loss: 0.6699175834655762\n",
            "Batch 274, Meta-loss: 0.6889049410820007\n",
            "Batch 275, Meta-loss: 0.926863968372345\n",
            "Batch 276, Meta-loss: 0.9204915761947632\n",
            "Batch 277, Meta-loss: 0.7904430627822876\n",
            "Batch 278, Meta-loss: 0.783595085144043\n",
            "Batch 279, Meta-loss: 0.8043496012687683\n",
            "Batch 280, Meta-loss: 0.9931160807609558\n",
            "Batch 281, Meta-loss: 0.7767853736877441\n",
            "Batch 282, Meta-loss: 0.8504201769828796\n",
            "Batch 283, Meta-loss: 0.894267737865448\n",
            "Batch 284, Meta-loss: 0.9025297164916992\n",
            "Batch 285, Meta-loss: 0.7529126405715942\n",
            "Batch 286, Meta-loss: 0.8065553903579712\n",
            "Batch 287, Meta-loss: 0.7842215895652771\n",
            "Batch 288, Meta-loss: 0.7688918113708496\n",
            "Batch 289, Meta-loss: 0.8510292768478394\n",
            "Batch 290, Meta-loss: 0.8419386148452759\n",
            "Batch 291, Meta-loss: 0.7798213958740234\n",
            "Batch 292, Meta-loss: 0.7965737581253052\n",
            "Batch 293, Meta-loss: 0.8443970680236816\n",
            "Batch 294, Meta-loss: 0.8015588521957397\n",
            "Batch 295, Meta-loss: 0.8626672625541687\n",
            "Batch 296, Meta-loss: 0.8247056007385254\n",
            "Batch 297, Meta-loss: 0.8264337778091431\n",
            "Batch 298, Meta-loss: 0.8717538714408875\n",
            "Batch 299, Meta-loss: 0.8745070695877075\n",
            "Batch 300, Meta-loss: 0.8992528915405273\n",
            "Batch 301, Meta-loss: 0.6744794845581055\n",
            "Batch 302, Meta-loss: 0.8245264291763306\n",
            "Batch 303, Meta-loss: 0.8712091445922852\n",
            "Batch 304, Meta-loss: 0.7811300158500671\n",
            "Batch 305, Meta-loss: 1.0018365383148193\n",
            "Batch 306, Meta-loss: 0.8141336441040039\n",
            "Batch 307, Meta-loss: 0.7661247253417969\n",
            "Batch 308, Meta-loss: 0.866856575012207\n",
            "Batch 309, Meta-loss: 0.8624206781387329\n",
            "Batch 310, Meta-loss: 0.9294483065605164\n",
            "Batch 311, Meta-loss: 0.8893983960151672\n",
            "Batch 312, Meta-loss: 0.8089971542358398\n",
            "Batch 313, Meta-loss: 0.929150402545929\n",
            "Batch 314, Meta-loss: 0.861994743347168\n",
            "Batch 315, Meta-loss: 0.8182195425033569\n",
            "Batch 316, Meta-loss: 0.7313960790634155\n",
            "Batch 317, Meta-loss: 0.725345253944397\n",
            "Batch 318, Meta-loss: 0.8164166212081909\n",
            "Batch 319, Meta-loss: 0.6461678743362427\n",
            "Batch 320, Meta-loss: 0.8120579719543457\n",
            "Batch 321, Meta-loss: 0.9278718829154968\n",
            "Batch 322, Meta-loss: 0.914827823638916\n",
            "Batch 323, Meta-loss: 0.7714770436286926\n",
            "Batch 324, Meta-loss: 0.6669756174087524\n",
            "Batch 325, Meta-loss: 0.9800357818603516\n",
            "Batch 326, Meta-loss: 0.7064472436904907\n",
            "Batch 327, Meta-loss: 0.9839555025100708\n",
            "Batch 328, Meta-loss: 0.8068072199821472\n",
            "Batch 329, Meta-loss: 0.8693219423294067\n",
            "Batch 330, Meta-loss: 0.7852591276168823\n",
            "Batch 331, Meta-loss: 0.7647220492362976\n",
            "Batch 332, Meta-loss: 0.775584876537323\n",
            "Batch 333, Meta-loss: 0.7612861394882202\n",
            "Batch 334, Meta-loss: 0.7326945066452026\n",
            "Batch 335, Meta-loss: 0.6851787567138672\n",
            "Batch 336, Meta-loss: 0.8470627665519714\n",
            "Batch 337, Meta-loss: 0.7805145382881165\n",
            "Batch 338, Meta-loss: 0.8276861906051636\n",
            "Batch 339, Meta-loss: 0.8061397671699524\n",
            "Batch 340, Meta-loss: 0.861046314239502\n",
            "Batch 341, Meta-loss: 0.869401752948761\n",
            "Batch 342, Meta-loss: 0.7926729917526245\n",
            "Batch 343, Meta-loss: 0.866195797920227\n",
            "Batch 344, Meta-loss: 0.8810887336730957\n",
            "Batch 345, Meta-loss: 0.882564902305603\n",
            "Batch 346, Meta-loss: 0.799362063407898\n",
            "Batch 347, Meta-loss: 0.7964707612991333\n",
            "Batch 348, Meta-loss: 0.8281744122505188\n",
            "Batch 349, Meta-loss: 0.8317784070968628\n",
            "Batch 350, Meta-loss: 0.8764718770980835\n",
            "Batch 351, Meta-loss: 0.7397387623786926\n",
            "Batch 352, Meta-loss: 0.8774732351303101\n",
            "Batch 353, Meta-loss: 0.8262327313423157\n",
            "Batch 354, Meta-loss: 0.8081744313240051\n",
            "Batch 355, Meta-loss: 0.9597004055976868\n",
            "Batch 356, Meta-loss: 0.9670823812484741\n",
            "Batch 357, Meta-loss: 0.7844520807266235\n",
            "Batch 358, Meta-loss: 0.9117350578308105\n",
            "Batch 359, Meta-loss: 0.8331273794174194\n",
            "Batch 360, Meta-loss: 0.7856114506721497\n",
            "Batch 361, Meta-loss: 0.9678347706794739\n",
            "Batch 362, Meta-loss: 0.8185696601867676\n",
            "Batch 363, Meta-loss: 0.8143126368522644\n",
            "Batch 364, Meta-loss: 0.890925407409668\n",
            "Batch 365, Meta-loss: 0.7853042483329773\n",
            "Batch 366, Meta-loss: 0.7954828143119812\n",
            "Batch 367, Meta-loss: 0.9694312810897827\n",
            "Batch 368, Meta-loss: 0.8817342519760132\n",
            "Batch 369, Meta-loss: 0.8485194444656372\n",
            "Batch 370, Meta-loss: 0.8789013028144836\n",
            "Batch 371, Meta-loss: 0.9578565359115601\n",
            "Batch 372, Meta-loss: 0.7975170016288757\n",
            "Batch 373, Meta-loss: 0.7527691125869751\n",
            "Batch 374, Meta-loss: 0.85767662525177\n",
            "Batch 375, Meta-loss: 0.8480518460273743\n",
            "Epoch 5\n",
            "Batch 1, Meta-loss: 0.9182060956954956\n",
            "Batch 2, Meta-loss: 0.9703577160835266\n",
            "Batch 3, Meta-loss: 0.8918941617012024\n",
            "Batch 4, Meta-loss: 0.7164122462272644\n",
            "Batch 5, Meta-loss: 0.8125845193862915\n",
            "Batch 6, Meta-loss: 1.0018037557601929\n",
            "Batch 7, Meta-loss: 0.993321418762207\n",
            "Batch 8, Meta-loss: 0.9453803300857544\n",
            "Batch 9, Meta-loss: 0.7929824590682983\n",
            "Batch 10, Meta-loss: 0.871688723564148\n",
            "Batch 11, Meta-loss: 0.8382281064987183\n",
            "Batch 12, Meta-loss: 0.8426871299743652\n",
            "Batch 13, Meta-loss: 0.8120076060295105\n",
            "Batch 14, Meta-loss: 0.7560597658157349\n",
            "Batch 15, Meta-loss: 0.8555506467819214\n",
            "Batch 16, Meta-loss: 0.6702221632003784\n",
            "Batch 17, Meta-loss: 0.9139751195907593\n",
            "Batch 18, Meta-loss: 0.7403029799461365\n",
            "Batch 19, Meta-loss: 0.8030341267585754\n",
            "Batch 20, Meta-loss: 0.682580828666687\n",
            "Batch 21, Meta-loss: 0.8997544050216675\n",
            "Batch 22, Meta-loss: 0.6541692018508911\n",
            "Batch 23, Meta-loss: 0.87957763671875\n",
            "Batch 24, Meta-loss: 0.7741416692733765\n",
            "Batch 25, Meta-loss: 0.7744634747505188\n",
            "Batch 26, Meta-loss: 0.8142969012260437\n",
            "Batch 27, Meta-loss: 0.7190821766853333\n",
            "Batch 28, Meta-loss: 0.9031558036804199\n",
            "Batch 29, Meta-loss: 0.8954042196273804\n",
            "Batch 30, Meta-loss: 0.7853542566299438\n",
            "Batch 31, Meta-loss: 0.8156868815422058\n",
            "Batch 32, Meta-loss: 0.8848128318786621\n",
            "Batch 33, Meta-loss: 0.7770988941192627\n",
            "Batch 34, Meta-loss: 0.9173067212104797\n",
            "Batch 35, Meta-loss: 0.956566333770752\n",
            "Batch 36, Meta-loss: 0.7807480692863464\n",
            "Batch 37, Meta-loss: 0.7610524892807007\n",
            "Batch 38, Meta-loss: 0.7700039148330688\n",
            "Batch 39, Meta-loss: 0.7302519083023071\n",
            "Batch 40, Meta-loss: 0.8257420659065247\n",
            "Batch 41, Meta-loss: 0.7718705534934998\n",
            "Batch 42, Meta-loss: 0.790546715259552\n",
            "Batch 43, Meta-loss: 0.7625871896743774\n",
            "Batch 44, Meta-loss: 0.756531298160553\n",
            "Batch 45, Meta-loss: 0.8158614039421082\n",
            "Batch 46, Meta-loss: 0.9210596084594727\n",
            "Batch 47, Meta-loss: 0.8193723559379578\n",
            "Batch 48, Meta-loss: 0.8853316307067871\n",
            "Batch 49, Meta-loss: 0.7866199016571045\n",
            "Batch 50, Meta-loss: 0.867993175983429\n",
            "Batch 51, Meta-loss: 0.72866290807724\n",
            "Batch 52, Meta-loss: 0.8142337799072266\n",
            "Batch 53, Meta-loss: 0.9035657644271851\n",
            "Batch 54, Meta-loss: 0.7941471338272095\n",
            "Batch 55, Meta-loss: 0.8072274923324585\n",
            "Batch 56, Meta-loss: 0.7076732516288757\n",
            "Batch 57, Meta-loss: 0.7113203406333923\n",
            "Batch 58, Meta-loss: 0.7601028680801392\n",
            "Batch 59, Meta-loss: 0.9169937968254089\n",
            "Batch 60, Meta-loss: 0.781877875328064\n",
            "Batch 61, Meta-loss: 0.812645435333252\n",
            "Batch 62, Meta-loss: 0.8804655075073242\n",
            "Batch 63, Meta-loss: 0.9190512895584106\n",
            "Batch 64, Meta-loss: 0.740859866142273\n",
            "Batch 65, Meta-loss: 0.7545216083526611\n",
            "Batch 66, Meta-loss: 0.8847540616989136\n",
            "Batch 67, Meta-loss: 0.8634015917778015\n",
            "Batch 68, Meta-loss: 0.8015987277030945\n",
            "Batch 69, Meta-loss: 0.7922995090484619\n",
            "Batch 70, Meta-loss: 0.7850850224494934\n",
            "Batch 71, Meta-loss: 0.8609187006950378\n",
            "Batch 72, Meta-loss: 0.8632024526596069\n",
            "Batch 73, Meta-loss: 0.6766358017921448\n",
            "Batch 74, Meta-loss: 0.7904446125030518\n",
            "Batch 75, Meta-loss: 0.8438105583190918\n",
            "Batch 76, Meta-loss: 0.8056482076644897\n",
            "Batch 77, Meta-loss: 0.7924293279647827\n",
            "Batch 78, Meta-loss: 0.7972952723503113\n",
            "Batch 79, Meta-loss: 0.6613823175430298\n",
            "Batch 80, Meta-loss: 0.8158261179924011\n",
            "Batch 81, Meta-loss: 0.8471037149429321\n",
            "Batch 82, Meta-loss: 0.7786700129508972\n",
            "Batch 83, Meta-loss: 0.7511029839515686\n",
            "Batch 84, Meta-loss: 0.9417624473571777\n",
            "Batch 85, Meta-loss: 1.022772192955017\n",
            "Batch 86, Meta-loss: 0.8329453468322754\n",
            "Batch 87, Meta-loss: 0.8030708432197571\n",
            "Batch 88, Meta-loss: 0.9834079742431641\n",
            "Batch 89, Meta-loss: 0.9995694160461426\n",
            "Batch 90, Meta-loss: 0.8561371564865112\n",
            "Batch 91, Meta-loss: 0.8173569440841675\n",
            "Batch 92, Meta-loss: 0.8338438272476196\n",
            "Batch 93, Meta-loss: 0.9757901430130005\n",
            "Batch 94, Meta-loss: 0.8714315295219421\n",
            "Batch 95, Meta-loss: 0.7329027652740479\n",
            "Batch 96, Meta-loss: 0.7334684133529663\n",
            "Batch 97, Meta-loss: 0.850163459777832\n",
            "Batch 98, Meta-loss: 0.8133907318115234\n",
            "Batch 99, Meta-loss: 0.9371060132980347\n",
            "Batch 100, Meta-loss: 0.7404478192329407\n",
            "Batch 101, Meta-loss: 0.9025095105171204\n",
            "Batch 102, Meta-loss: 0.949427604675293\n",
            "Batch 103, Meta-loss: 0.7127819061279297\n",
            "Batch 104, Meta-loss: 0.9100288152694702\n",
            "Batch 105, Meta-loss: 0.8365961313247681\n",
            "Batch 106, Meta-loss: 0.6881797909736633\n",
            "Batch 107, Meta-loss: 0.7289036512374878\n",
            "Batch 108, Meta-loss: 0.7999931573867798\n",
            "Batch 109, Meta-loss: 1.077121376991272\n",
            "Batch 110, Meta-loss: 0.8871020078659058\n",
            "Batch 111, Meta-loss: 0.7635573744773865\n",
            "Batch 112, Meta-loss: 0.9985764622688293\n",
            "Batch 113, Meta-loss: 0.9894693493843079\n",
            "Batch 114, Meta-loss: 0.7331592440605164\n",
            "Batch 115, Meta-loss: 0.8849555850028992\n",
            "Batch 116, Meta-loss: 0.8090181350708008\n",
            "Batch 117, Meta-loss: 0.8482474088668823\n",
            "Batch 118, Meta-loss: 0.8348196744918823\n",
            "Batch 119, Meta-loss: 0.828771710395813\n",
            "Batch 120, Meta-loss: 0.980737566947937\n",
            "Batch 121, Meta-loss: 0.7938631176948547\n",
            "Batch 122, Meta-loss: 0.8716477155685425\n",
            "Batch 123, Meta-loss: 0.8174513578414917\n",
            "Batch 124, Meta-loss: 0.8840972781181335\n",
            "Batch 125, Meta-loss: 0.7475588917732239\n",
            "Batch 126, Meta-loss: 0.834668755531311\n",
            "Batch 127, Meta-loss: 0.7353029847145081\n",
            "Batch 128, Meta-loss: 0.847700297832489\n",
            "Batch 129, Meta-loss: 0.7378345727920532\n",
            "Batch 130, Meta-loss: 0.9124908447265625\n",
            "Batch 131, Meta-loss: 0.9632024765014648\n",
            "Batch 132, Meta-loss: 0.7328478693962097\n",
            "Batch 133, Meta-loss: 0.8183644413948059\n",
            "Batch 134, Meta-loss: 0.8173984289169312\n",
            "Batch 135, Meta-loss: 0.799740731716156\n",
            "Batch 136, Meta-loss: 0.8668472170829773\n",
            "Batch 137, Meta-loss: 0.8816474080085754\n",
            "Batch 138, Meta-loss: 0.9390804171562195\n",
            "Batch 139, Meta-loss: 0.7062883377075195\n",
            "Batch 140, Meta-loss: 0.8147047162055969\n",
            "Batch 141, Meta-loss: 0.8677128553390503\n",
            "Batch 142, Meta-loss: 0.7388147115707397\n",
            "Batch 143, Meta-loss: 0.8055661916732788\n",
            "Batch 144, Meta-loss: 0.8182865381240845\n",
            "Batch 145, Meta-loss: 0.9150146245956421\n",
            "Batch 146, Meta-loss: 0.8277552723884583\n",
            "Batch 147, Meta-loss: 0.7695950269699097\n",
            "Batch 148, Meta-loss: 0.8725887537002563\n",
            "Batch 149, Meta-loss: 0.9048746228218079\n",
            "Batch 150, Meta-loss: 0.9017788767814636\n",
            "Batch 151, Meta-loss: 0.944710910320282\n",
            "Batch 152, Meta-loss: 0.8655143976211548\n",
            "Batch 153, Meta-loss: 0.7956811189651489\n",
            "Batch 154, Meta-loss: 0.6332039833068848\n",
            "Batch 155, Meta-loss: 0.7459100484848022\n",
            "Batch 156, Meta-loss: 0.9321342706680298\n",
            "Batch 157, Meta-loss: 0.8236492872238159\n",
            "Batch 158, Meta-loss: 0.9930618405342102\n",
            "Batch 159, Meta-loss: 1.0116081237792969\n",
            "Batch 160, Meta-loss: 0.9055114984512329\n",
            "Batch 161, Meta-loss: 0.9075953364372253\n",
            "Batch 162, Meta-loss: 0.7470078468322754\n",
            "Batch 163, Meta-loss: 0.8965800404548645\n",
            "Batch 164, Meta-loss: 0.8388409614562988\n",
            "Batch 165, Meta-loss: 0.7178853154182434\n",
            "Batch 166, Meta-loss: 0.7214662432670593\n",
            "Batch 167, Meta-loss: 0.865814208984375\n",
            "Batch 168, Meta-loss: 0.772708535194397\n",
            "Batch 169, Meta-loss: 0.7615634799003601\n",
            "Batch 170, Meta-loss: 0.79561448097229\n",
            "Batch 171, Meta-loss: 0.8807967305183411\n",
            "Batch 172, Meta-loss: 1.0395876169204712\n",
            "Batch 173, Meta-loss: 0.7902007102966309\n",
            "Batch 174, Meta-loss: 0.8777376413345337\n",
            "Batch 175, Meta-loss: 0.7860185503959656\n",
            "Batch 176, Meta-loss: 0.7768165469169617\n",
            "Batch 177, Meta-loss: 0.8905099034309387\n",
            "Batch 178, Meta-loss: 0.9632158279418945\n",
            "Batch 179, Meta-loss: 0.7867470979690552\n",
            "Batch 180, Meta-loss: 0.8205586671829224\n",
            "Batch 181, Meta-loss: 0.8499369621276855\n",
            "Batch 182, Meta-loss: 0.8297128677368164\n",
            "Batch 183, Meta-loss: 0.7939245104789734\n",
            "Batch 184, Meta-loss: 0.9394442439079285\n",
            "Batch 185, Meta-loss: 0.9183389544487\n",
            "Batch 186, Meta-loss: 0.7870075702667236\n",
            "Batch 187, Meta-loss: 0.9085599184036255\n",
            "Batch 188, Meta-loss: 0.7524668574333191\n",
            "Batch 189, Meta-loss: 0.950329601764679\n",
            "Batch 190, Meta-loss: 0.716486394405365\n",
            "Batch 191, Meta-loss: 0.8542858958244324\n",
            "Batch 192, Meta-loss: 0.9037652015686035\n",
            "Batch 193, Meta-loss: 0.882798969745636\n",
            "Batch 194, Meta-loss: 0.6738664507865906\n",
            "Batch 195, Meta-loss: 0.7639663219451904\n",
            "Batch 196, Meta-loss: 0.8754333257675171\n",
            "Batch 197, Meta-loss: 0.8422024846076965\n",
            "Batch 198, Meta-loss: 0.799152135848999\n",
            "Batch 199, Meta-loss: 0.7346866726875305\n",
            "Batch 200, Meta-loss: 0.763140857219696\n",
            "Batch 201, Meta-loss: 0.8710875511169434\n",
            "Batch 202, Meta-loss: 0.8700214624404907\n",
            "Batch 203, Meta-loss: 0.9507824778556824\n",
            "Batch 204, Meta-loss: 0.716269314289093\n",
            "Batch 205, Meta-loss: 0.9494158625602722\n",
            "Batch 206, Meta-loss: 0.8251951336860657\n",
            "Batch 207, Meta-loss: 0.7472552061080933\n",
            "Batch 208, Meta-loss: 0.7623279690742493\n",
            "Batch 209, Meta-loss: 0.875194251537323\n",
            "Batch 210, Meta-loss: 0.8609426617622375\n",
            "Batch 211, Meta-loss: 0.7767638564109802\n",
            "Batch 212, Meta-loss: 0.8898006677627563\n",
            "Batch 213, Meta-loss: 0.9871042966842651\n",
            "Batch 214, Meta-loss: 0.8058846592903137\n",
            "Batch 215, Meta-loss: 0.9600715637207031\n",
            "Batch 216, Meta-loss: 0.806160569190979\n",
            "Batch 217, Meta-loss: 0.8318091630935669\n",
            "Batch 218, Meta-loss: 0.7536875009536743\n",
            "Batch 219, Meta-loss: 0.7929390668869019\n",
            "Batch 220, Meta-loss: 0.7525027394294739\n",
            "Batch 221, Meta-loss: 0.9301682710647583\n",
            "Batch 222, Meta-loss: 0.8929545283317566\n",
            "Batch 223, Meta-loss: 0.7699176073074341\n",
            "Batch 224, Meta-loss: 0.8260178565979004\n",
            "Batch 225, Meta-loss: 0.8624793887138367\n",
            "Batch 226, Meta-loss: 0.9505605697631836\n",
            "Batch 227, Meta-loss: 0.8323562741279602\n",
            "Batch 228, Meta-loss: 0.870639979839325\n",
            "Batch 229, Meta-loss: 0.8111158609390259\n",
            "Batch 230, Meta-loss: 0.8260034322738647\n",
            "Batch 231, Meta-loss: 1.0241965055465698\n",
            "Batch 232, Meta-loss: 0.7049424052238464\n",
            "Batch 233, Meta-loss: 0.8749986886978149\n",
            "Batch 234, Meta-loss: 0.8263053894042969\n",
            "Batch 235, Meta-loss: 0.7670090198516846\n",
            "Batch 236, Meta-loss: 0.9236840009689331\n",
            "Batch 237, Meta-loss: 0.9176368713378906\n",
            "Batch 238, Meta-loss: 0.7965661287307739\n",
            "Batch 239, Meta-loss: 0.794214129447937\n",
            "Batch 240, Meta-loss: 0.6545403003692627\n",
            "Batch 241, Meta-loss: 0.9122869372367859\n",
            "Batch 242, Meta-loss: 0.8909282684326172\n",
            "Batch 243, Meta-loss: 0.7694400548934937\n",
            "Batch 244, Meta-loss: 0.7769242525100708\n",
            "Batch 245, Meta-loss: 0.8676261901855469\n",
            "Batch 246, Meta-loss: 0.8239952325820923\n",
            "Batch 247, Meta-loss: 0.7190436124801636\n",
            "Batch 248, Meta-loss: 0.9406830072402954\n",
            "Batch 249, Meta-loss: 0.7855488061904907\n",
            "Batch 250, Meta-loss: 0.7830568552017212\n",
            "Batch 251, Meta-loss: 0.7467155456542969\n",
            "Batch 252, Meta-loss: 0.8018293380737305\n",
            "Batch 253, Meta-loss: 0.9623435735702515\n",
            "Batch 254, Meta-loss: 0.9034417271614075\n",
            "Batch 255, Meta-loss: 0.7906176447868347\n",
            "Batch 256, Meta-loss: 0.9568884968757629\n",
            "Batch 257, Meta-loss: 0.8840702772140503\n",
            "Batch 258, Meta-loss: 0.8555797338485718\n",
            "Batch 259, Meta-loss: 0.8524261713027954\n",
            "Batch 260, Meta-loss: 0.7834081053733826\n",
            "Batch 261, Meta-loss: 0.8555227518081665\n",
            "Batch 262, Meta-loss: 0.9502969980239868\n",
            "Batch 263, Meta-loss: 0.7631527185440063\n",
            "Batch 264, Meta-loss: 0.7872341871261597\n",
            "Batch 265, Meta-loss: 0.761863648891449\n",
            "Batch 266, Meta-loss: 0.9332946538925171\n",
            "Batch 267, Meta-loss: 0.7163320779800415\n",
            "Batch 268, Meta-loss: 0.7667438387870789\n",
            "Batch 269, Meta-loss: 0.7952672839164734\n",
            "Batch 270, Meta-loss: 0.8099552392959595\n",
            "Batch 271, Meta-loss: 0.7574246525764465\n",
            "Batch 272, Meta-loss: 0.9614721536636353\n",
            "Batch 273, Meta-loss: 0.8390735387802124\n",
            "Batch 274, Meta-loss: 0.7650781869888306\n",
            "Batch 275, Meta-loss: 0.6911424398422241\n",
            "Batch 276, Meta-loss: 0.910431981086731\n",
            "Batch 277, Meta-loss: 0.8361732363700867\n",
            "Batch 278, Meta-loss: 0.8162518739700317\n",
            "Batch 279, Meta-loss: 0.803083062171936\n",
            "Batch 280, Meta-loss: 0.6930217742919922\n",
            "Batch 281, Meta-loss: 0.8328458070755005\n",
            "Batch 282, Meta-loss: 0.9552156329154968\n",
            "Batch 283, Meta-loss: 0.7513993382453918\n",
            "Batch 284, Meta-loss: 0.8211749196052551\n",
            "Batch 285, Meta-loss: 0.7209656238555908\n",
            "Batch 286, Meta-loss: 0.9184902310371399\n",
            "Batch 287, Meta-loss: 0.7210500836372375\n",
            "Batch 288, Meta-loss: 0.8480873107910156\n",
            "Batch 289, Meta-loss: 1.2071359157562256\n",
            "Batch 290, Meta-loss: 0.9950375556945801\n",
            "Batch 291, Meta-loss: 0.8913904428482056\n",
            "Batch 292, Meta-loss: 0.9251478910446167\n",
            "Batch 293, Meta-loss: 0.9070957899093628\n",
            "Batch 294, Meta-loss: 0.8049231767654419\n",
            "Batch 295, Meta-loss: 0.7859708070755005\n",
            "Batch 296, Meta-loss: 0.7148633599281311\n",
            "Batch 297, Meta-loss: 0.8642874956130981\n",
            "Batch 298, Meta-loss: 0.7745116949081421\n",
            "Batch 299, Meta-loss: 0.7480459213256836\n",
            "Batch 300, Meta-loss: 0.836491584777832\n",
            "Batch 301, Meta-loss: 0.8431175947189331\n",
            "Batch 302, Meta-loss: 0.8295915722846985\n",
            "Batch 303, Meta-loss: 0.8570200800895691\n",
            "Batch 304, Meta-loss: 0.8353897929191589\n",
            "Batch 305, Meta-loss: 0.7646563649177551\n",
            "Batch 306, Meta-loss: 0.7420696020126343\n",
            "Batch 307, Meta-loss: 0.8138551712036133\n",
            "Batch 308, Meta-loss: 0.8153097033500671\n",
            "Batch 309, Meta-loss: 0.8520021438598633\n",
            "Batch 310, Meta-loss: 0.9346143007278442\n",
            "Batch 311, Meta-loss: 0.9548942446708679\n",
            "Batch 312, Meta-loss: 0.7794448733329773\n",
            "Batch 313, Meta-loss: 0.84149569272995\n",
            "Batch 314, Meta-loss: 0.6894267797470093\n",
            "Batch 315, Meta-loss: 0.8969314694404602\n",
            "Batch 316, Meta-loss: 0.8918689489364624\n",
            "Batch 317, Meta-loss: 0.9876381158828735\n",
            "Batch 318, Meta-loss: 0.8306971788406372\n",
            "Batch 319, Meta-loss: 0.7889363765716553\n",
            "Batch 320, Meta-loss: 0.8360332250595093\n",
            "Batch 321, Meta-loss: 0.7450327277183533\n",
            "Batch 322, Meta-loss: 0.8278535604476929\n",
            "Batch 323, Meta-loss: 0.8591995239257812\n",
            "Batch 324, Meta-loss: 0.6985601186752319\n",
            "Batch 325, Meta-loss: 0.8019934892654419\n",
            "Batch 326, Meta-loss: 0.9049410820007324\n",
            "Batch 327, Meta-loss: 0.8271455764770508\n",
            "Batch 328, Meta-loss: 0.9141279458999634\n",
            "Batch 329, Meta-loss: 0.9443143606185913\n",
            "Batch 330, Meta-loss: 0.7614535689353943\n",
            "Batch 331, Meta-loss: 0.7319079637527466\n",
            "Batch 332, Meta-loss: 0.7897887229919434\n",
            "Batch 333, Meta-loss: 0.7310320734977722\n",
            "Batch 334, Meta-loss: 0.7749631404876709\n",
            "Batch 335, Meta-loss: 0.638615071773529\n",
            "Batch 336, Meta-loss: 0.7166082262992859\n",
            "Batch 337, Meta-loss: 0.7315974831581116\n",
            "Batch 338, Meta-loss: 0.9115517735481262\n",
            "Batch 339, Meta-loss: 0.7751471400260925\n",
            "Batch 340, Meta-loss: 0.8463584780693054\n",
            "Batch 341, Meta-loss: 0.8272196650505066\n",
            "Batch 342, Meta-loss: 0.7230318784713745\n",
            "Batch 343, Meta-loss: 0.7250683903694153\n",
            "Batch 344, Meta-loss: 0.7261984348297119\n",
            "Batch 345, Meta-loss: 0.7452256083488464\n",
            "Batch 346, Meta-loss: 0.8322278261184692\n",
            "Batch 347, Meta-loss: 0.8737666010856628\n",
            "Batch 348, Meta-loss: 0.852320671081543\n",
            "Batch 349, Meta-loss: 0.686393141746521\n",
            "Batch 350, Meta-loss: 0.9638704061508179\n",
            "Batch 351, Meta-loss: 0.8867214918136597\n",
            "Batch 352, Meta-loss: 0.7361159324645996\n",
            "Batch 353, Meta-loss: 0.7193847894668579\n",
            "Batch 354, Meta-loss: 0.9084951281547546\n",
            "Batch 355, Meta-loss: 0.8723715543746948\n",
            "Batch 356, Meta-loss: 0.8030003309249878\n",
            "Batch 357, Meta-loss: 0.7815518975257874\n",
            "Batch 358, Meta-loss: 0.7008896470069885\n",
            "Batch 359, Meta-loss: 0.6805794835090637\n",
            "Batch 360, Meta-loss: 0.8301562070846558\n",
            "Batch 361, Meta-loss: 0.8647845387458801\n",
            "Batch 362, Meta-loss: 0.7849324345588684\n",
            "Batch 363, Meta-loss: 0.7185582518577576\n",
            "Batch 364, Meta-loss: 0.9214639663696289\n",
            "Batch 365, Meta-loss: 1.026366114616394\n",
            "Batch 366, Meta-loss: 0.8161047697067261\n",
            "Batch 367, Meta-loss: 0.8207224607467651\n",
            "Batch 368, Meta-loss: 0.8825432062149048\n",
            "Batch 369, Meta-loss: 0.7602565288543701\n",
            "Batch 370, Meta-loss: 0.7345213890075684\n",
            "Batch 371, Meta-loss: 0.6701224446296692\n",
            "Batch 372, Meta-loss: 0.7210997343063354\n",
            "Batch 373, Meta-loss: 0.7677611708641052\n",
            "Batch 374, Meta-loss: 0.7410808205604553\n",
            "Batch 375, Meta-loss: 0.8107320666313171\n",
            "Epoch 6\n",
            "Batch 1, Meta-loss: 0.8387242555618286\n",
            "Batch 2, Meta-loss: 0.7045611143112183\n",
            "Batch 3, Meta-loss: 0.915544867515564\n",
            "Batch 4, Meta-loss: 0.7070500254631042\n",
            "Batch 5, Meta-loss: 0.727510392665863\n",
            "Batch 6, Meta-loss: 0.7583394646644592\n",
            "Batch 7, Meta-loss: 0.7236515879631042\n",
            "Batch 8, Meta-loss: 0.9143466949462891\n",
            "Batch 9, Meta-loss: 0.8662916421890259\n",
            "Batch 10, Meta-loss: 0.8094439506530762\n",
            "Batch 11, Meta-loss: 0.6703389286994934\n",
            "Batch 12, Meta-loss: 0.8020902872085571\n",
            "Batch 13, Meta-loss: 0.8207413554191589\n",
            "Batch 14, Meta-loss: 0.6902378797531128\n",
            "Batch 15, Meta-loss: 0.8308636546134949\n",
            "Batch 16, Meta-loss: 0.7226592302322388\n",
            "Batch 17, Meta-loss: 0.7759120464324951\n",
            "Batch 18, Meta-loss: 0.7738158702850342\n",
            "Batch 19, Meta-loss: 0.6540274620056152\n",
            "Batch 20, Meta-loss: 0.821738064289093\n",
            "Batch 21, Meta-loss: 0.6475549936294556\n",
            "Batch 22, Meta-loss: 0.6964173913002014\n",
            "Batch 23, Meta-loss: 0.7562488913536072\n",
            "Batch 24, Meta-loss: 0.9902944564819336\n",
            "Batch 25, Meta-loss: 0.7725092768669128\n",
            "Batch 26, Meta-loss: 0.9222995638847351\n",
            "Batch 27, Meta-loss: 0.742805004119873\n",
            "Batch 28, Meta-loss: 0.6505537033081055\n",
            "Batch 29, Meta-loss: 0.6680657267570496\n",
            "Batch 30, Meta-loss: 0.8032137155532837\n",
            "Batch 31, Meta-loss: 0.6793376207351685\n",
            "Batch 32, Meta-loss: 0.7477139234542847\n",
            "Batch 33, Meta-loss: 0.669443666934967\n",
            "Batch 34, Meta-loss: 0.812313437461853\n",
            "Batch 35, Meta-loss: 0.9121624231338501\n",
            "Batch 36, Meta-loss: 0.6782282590866089\n",
            "Batch 37, Meta-loss: 0.6998738646507263\n",
            "Batch 38, Meta-loss: 0.729070246219635\n",
            "Batch 39, Meta-loss: 0.8355957865715027\n",
            "Batch 40, Meta-loss: 0.9236652255058289\n",
            "Batch 41, Meta-loss: 0.9786472320556641\n",
            "Batch 42, Meta-loss: 0.6780058741569519\n",
            "Batch 43, Meta-loss: 0.8369289636611938\n",
            "Batch 44, Meta-loss: 0.8337149620056152\n",
            "Batch 45, Meta-loss: 0.8652504086494446\n",
            "Batch 46, Meta-loss: 0.7708302736282349\n",
            "Batch 47, Meta-loss: 0.7486387491226196\n",
            "Batch 48, Meta-loss: 0.6635679006576538\n",
            "Batch 49, Meta-loss: 0.7465561032295227\n",
            "Batch 50, Meta-loss: 0.7836011052131653\n",
            "Batch 51, Meta-loss: 0.8208314776420593\n",
            "Batch 52, Meta-loss: 0.8434323072433472\n",
            "Batch 53, Meta-loss: 0.7516084909439087\n",
            "Batch 54, Meta-loss: 0.8301489949226379\n",
            "Batch 55, Meta-loss: 0.7590616345405579\n",
            "Batch 56, Meta-loss: 1.0816487073898315\n",
            "Batch 57, Meta-loss: 0.7930759191513062\n",
            "Batch 58, Meta-loss: 0.9038330316543579\n",
            "Batch 59, Meta-loss: 0.7698730230331421\n",
            "Batch 60, Meta-loss: 0.7839731574058533\n",
            "Batch 61, Meta-loss: 0.8632339239120483\n",
            "Batch 62, Meta-loss: 0.7088439464569092\n",
            "Batch 63, Meta-loss: 0.9819008111953735\n",
            "Batch 64, Meta-loss: 0.8505896329879761\n",
            "Batch 65, Meta-loss: 0.739066481590271\n",
            "Batch 66, Meta-loss: 0.666892409324646\n",
            "Batch 67, Meta-loss: 0.7876681089401245\n",
            "Batch 68, Meta-loss: 0.7352215051651001\n",
            "Batch 69, Meta-loss: 0.8546655774116516\n",
            "Batch 70, Meta-loss: 0.7547467947006226\n",
            "Batch 71, Meta-loss: 0.8029715418815613\n",
            "Batch 72, Meta-loss: 0.8095055818557739\n",
            "Batch 73, Meta-loss: 0.6487226486206055\n",
            "Batch 74, Meta-loss: 0.8561716079711914\n",
            "Batch 75, Meta-loss: 0.7814732789993286\n",
            "Batch 76, Meta-loss: 0.8391996622085571\n",
            "Batch 77, Meta-loss: 0.8775496482849121\n",
            "Batch 78, Meta-loss: 0.8729804754257202\n",
            "Batch 79, Meta-loss: 0.7558388710021973\n",
            "Batch 80, Meta-loss: 0.912921130657196\n",
            "Batch 81, Meta-loss: 0.8717646598815918\n",
            "Batch 82, Meta-loss: 0.8144866824150085\n",
            "Batch 83, Meta-loss: 0.8045007586479187\n",
            "Batch 84, Meta-loss: 0.6826800107955933\n",
            "Batch 85, Meta-loss: 0.7497714161872864\n",
            "Batch 86, Meta-loss: 0.8048539161682129\n",
            "Batch 87, Meta-loss: 0.8314839601516724\n",
            "Batch 88, Meta-loss: 0.9285567402839661\n",
            "Batch 89, Meta-loss: 0.8254392743110657\n",
            "Batch 90, Meta-loss: 0.7913364171981812\n",
            "Batch 91, Meta-loss: 0.893803596496582\n",
            "Batch 92, Meta-loss: 0.8021296262741089\n",
            "Batch 93, Meta-loss: 0.6973966360092163\n",
            "Batch 94, Meta-loss: 1.0553953647613525\n",
            "Batch 95, Meta-loss: 0.9176732301712036\n",
            "Batch 96, Meta-loss: 0.8701083064079285\n",
            "Batch 97, Meta-loss: 0.820888876914978\n",
            "Batch 98, Meta-loss: 0.8049710392951965\n",
            "Batch 99, Meta-loss: 0.9286463856697083\n",
            "Batch 100, Meta-loss: 0.7861195802688599\n",
            "Batch 101, Meta-loss: 0.7150295972824097\n",
            "Batch 102, Meta-loss: 0.8944058418273926\n",
            "Batch 103, Meta-loss: 0.8875175714492798\n",
            "Batch 104, Meta-loss: 0.7668251991271973\n",
            "Batch 105, Meta-loss: 0.7143993973731995\n",
            "Batch 106, Meta-loss: 0.8100882768630981\n",
            "Batch 107, Meta-loss: 0.7603636384010315\n",
            "Batch 108, Meta-loss: 0.8400666117668152\n",
            "Batch 109, Meta-loss: 0.8481568098068237\n",
            "Batch 110, Meta-loss: 0.8773388862609863\n",
            "Batch 111, Meta-loss: 0.9207288026809692\n",
            "Batch 112, Meta-loss: 0.8334134817123413\n",
            "Batch 113, Meta-loss: 0.6929489970207214\n",
            "Batch 114, Meta-loss: 0.8171364068984985\n",
            "Batch 115, Meta-loss: 0.9888022541999817\n",
            "Batch 116, Meta-loss: 0.7783659100532532\n",
            "Batch 117, Meta-loss: 0.7273603677749634\n",
            "Batch 118, Meta-loss: 1.003599762916565\n",
            "Batch 119, Meta-loss: 0.8100072145462036\n",
            "Batch 120, Meta-loss: 0.6360658407211304\n",
            "Batch 121, Meta-loss: 0.8400555849075317\n",
            "Batch 122, Meta-loss: 0.956830620765686\n",
            "Batch 123, Meta-loss: 0.8187897801399231\n",
            "Batch 124, Meta-loss: 0.8606989979743958\n",
            "Batch 125, Meta-loss: 0.7771186232566833\n",
            "Batch 126, Meta-loss: 0.8298265337944031\n",
            "Batch 127, Meta-loss: 0.7707898020744324\n",
            "Batch 128, Meta-loss: 0.7682294845581055\n",
            "Batch 129, Meta-loss: 0.9818989634513855\n",
            "Batch 130, Meta-loss: 0.892888069152832\n",
            "Batch 131, Meta-loss: 0.8824094533920288\n",
            "Batch 132, Meta-loss: 0.9095061421394348\n",
            "Batch 133, Meta-loss: 0.844862163066864\n",
            "Batch 134, Meta-loss: 0.9072432518005371\n",
            "Batch 135, Meta-loss: 0.6748354434967041\n",
            "Batch 136, Meta-loss: 0.8448899388313293\n",
            "Batch 137, Meta-loss: 0.8444520235061646\n",
            "Batch 138, Meta-loss: 0.8950468897819519\n",
            "Batch 139, Meta-loss: 0.9442469477653503\n",
            "Batch 140, Meta-loss: 0.9813388586044312\n",
            "Batch 141, Meta-loss: 1.0112992525100708\n",
            "Batch 142, Meta-loss: 0.8666999936103821\n",
            "Batch 143, Meta-loss: 0.808703601360321\n",
            "Batch 144, Meta-loss: 0.8056972622871399\n",
            "Batch 145, Meta-loss: 0.8589307069778442\n",
            "Batch 146, Meta-loss: 0.9517602920532227\n",
            "Batch 147, Meta-loss: 0.8560935854911804\n",
            "Batch 148, Meta-loss: 0.881514847278595\n",
            "Batch 149, Meta-loss: 0.8465434908866882\n",
            "Batch 150, Meta-loss: 0.9507702589035034\n",
            "Batch 151, Meta-loss: 0.934556782245636\n",
            "Batch 152, Meta-loss: 0.795549750328064\n",
            "Batch 153, Meta-loss: 0.9357427358627319\n",
            "Batch 154, Meta-loss: 1.0096451044082642\n",
            "Batch 155, Meta-loss: 0.8191300630569458\n",
            "Batch 156, Meta-loss: 0.9639983177185059\n",
            "Batch 157, Meta-loss: 1.0067096948623657\n",
            "Batch 158, Meta-loss: 0.7878965139389038\n",
            "Batch 159, Meta-loss: 0.6856611967086792\n",
            "Batch 160, Meta-loss: 0.7870461940765381\n",
            "Batch 161, Meta-loss: 0.8754236102104187\n",
            "Batch 162, Meta-loss: 0.7033746838569641\n",
            "Batch 163, Meta-loss: 0.7001591324806213\n",
            "Batch 164, Meta-loss: 0.8269037008285522\n",
            "Batch 165, Meta-loss: 0.7274410128593445\n",
            "Batch 166, Meta-loss: 0.9261250495910645\n",
            "Batch 167, Meta-loss: 0.754001259803772\n",
            "Batch 168, Meta-loss: 1.016323208808899\n",
            "Batch 169, Meta-loss: 0.9035899043083191\n",
            "Batch 170, Meta-loss: 0.9551512002944946\n",
            "Batch 171, Meta-loss: 0.83678138256073\n",
            "Batch 172, Meta-loss: 0.8597713708877563\n",
            "Batch 173, Meta-loss: 0.8841762542724609\n",
            "Batch 174, Meta-loss: 0.8929440379142761\n",
            "Batch 175, Meta-loss: 0.9389898180961609\n",
            "Batch 176, Meta-loss: 1.015331745147705\n",
            "Batch 177, Meta-loss: 0.9413015246391296\n",
            "Batch 178, Meta-loss: 0.872352123260498\n",
            "Batch 179, Meta-loss: 0.7711060047149658\n",
            "Batch 180, Meta-loss: 0.8680102229118347\n",
            "Batch 181, Meta-loss: 0.7939791679382324\n",
            "Batch 182, Meta-loss: 0.8344706296920776\n",
            "Batch 183, Meta-loss: 0.7882745862007141\n",
            "Batch 184, Meta-loss: 0.7834333181381226\n",
            "Batch 185, Meta-loss: 0.8824468851089478\n",
            "Batch 186, Meta-loss: 0.8098783493041992\n",
            "Batch 187, Meta-loss: 0.8487628698348999\n",
            "Batch 188, Meta-loss: 0.9149705171585083\n",
            "Batch 189, Meta-loss: 0.7758387923240662\n",
            "Batch 190, Meta-loss: 0.8512305021286011\n",
            "Batch 191, Meta-loss: 0.7831605672836304\n",
            "Batch 192, Meta-loss: 0.9724074602127075\n",
            "Batch 193, Meta-loss: 0.7788797616958618\n",
            "Batch 194, Meta-loss: 0.92535799741745\n",
            "Batch 195, Meta-loss: 0.8673971891403198\n",
            "Batch 196, Meta-loss: 0.9602071642875671\n",
            "Batch 197, Meta-loss: 0.8479264378547668\n",
            "Batch 198, Meta-loss: 0.7619330286979675\n",
            "Batch 199, Meta-loss: 0.7635776996612549\n",
            "Batch 200, Meta-loss: 0.8956734538078308\n",
            "Batch 201, Meta-loss: 0.9062486886978149\n",
            "Batch 202, Meta-loss: 0.8010705709457397\n",
            "Batch 203, Meta-loss: 0.8462076187133789\n",
            "Batch 204, Meta-loss: 0.8885669708251953\n",
            "Batch 205, Meta-loss: 0.8381208181381226\n",
            "Batch 206, Meta-loss: 0.7746008634567261\n",
            "Batch 207, Meta-loss: 0.8717156648635864\n",
            "Batch 208, Meta-loss: 0.9409874677658081\n",
            "Batch 209, Meta-loss: 0.8990193605422974\n",
            "Batch 210, Meta-loss: 0.7509568929672241\n",
            "Batch 211, Meta-loss: 0.9002744555473328\n",
            "Batch 212, Meta-loss: 0.9182791709899902\n",
            "Batch 213, Meta-loss: 0.7951669692993164\n",
            "Batch 214, Meta-loss: 0.739911675453186\n",
            "Batch 215, Meta-loss: 0.8454362154006958\n",
            "Batch 216, Meta-loss: 0.924433708190918\n",
            "Batch 217, Meta-loss: 0.9220918416976929\n",
            "Batch 218, Meta-loss: 0.8198083639144897\n",
            "Batch 219, Meta-loss: 0.821566104888916\n",
            "Batch 220, Meta-loss: 0.9306483268737793\n",
            "Batch 221, Meta-loss: 0.7658181190490723\n",
            "Batch 222, Meta-loss: 0.8636773824691772\n",
            "Batch 223, Meta-loss: 0.770188570022583\n",
            "Batch 224, Meta-loss: 0.8237513303756714\n",
            "Batch 225, Meta-loss: 0.8832061886787415\n",
            "Batch 226, Meta-loss: 0.9314497709274292\n",
            "Batch 227, Meta-loss: 0.7147238850593567\n",
            "Batch 228, Meta-loss: 0.8582308888435364\n",
            "Batch 229, Meta-loss: 0.8861532211303711\n",
            "Batch 230, Meta-loss: 0.8027538061141968\n",
            "Batch 231, Meta-loss: 0.7727388143539429\n",
            "Batch 232, Meta-loss: 0.9293615221977234\n",
            "Batch 233, Meta-loss: 0.8162577748298645\n",
            "Batch 234, Meta-loss: 0.7876406908035278\n",
            "Batch 235, Meta-loss: 0.9119579195976257\n",
            "Batch 236, Meta-loss: 0.8813635110855103\n",
            "Batch 237, Meta-loss: 0.8895506858825684\n",
            "Batch 238, Meta-loss: 0.7819486856460571\n",
            "Batch 239, Meta-loss: 0.9201169013977051\n",
            "Batch 240, Meta-loss: 0.9884766340255737\n",
            "Batch 241, Meta-loss: 0.773556649684906\n",
            "Batch 242, Meta-loss: 0.8479974865913391\n",
            "Batch 243, Meta-loss: 0.8115608096122742\n",
            "Batch 244, Meta-loss: 0.9637996554374695\n",
            "Batch 245, Meta-loss: 0.8722532391548157\n",
            "Batch 246, Meta-loss: 0.7540124654769897\n",
            "Batch 247, Meta-loss: 0.7902252078056335\n",
            "Batch 248, Meta-loss: 0.9627993702888489\n",
            "Batch 249, Meta-loss: 0.9159431457519531\n",
            "Batch 250, Meta-loss: 0.95506751537323\n",
            "Batch 251, Meta-loss: 0.8390712738037109\n",
            "Batch 252, Meta-loss: 0.8105379343032837\n",
            "Batch 253, Meta-loss: 0.8284510374069214\n",
            "Batch 254, Meta-loss: 0.7613102197647095\n",
            "Batch 255, Meta-loss: 0.8511897921562195\n",
            "Batch 256, Meta-loss: 0.9650720357894897\n",
            "Batch 257, Meta-loss: 0.7808934450149536\n",
            "Batch 258, Meta-loss: 0.9542911648750305\n",
            "Batch 259, Meta-loss: 0.8048452138900757\n",
            "Batch 260, Meta-loss: 0.6906570196151733\n",
            "Batch 261, Meta-loss: 0.9343587160110474\n",
            "Batch 262, Meta-loss: 0.8896942138671875\n",
            "Batch 263, Meta-loss: 0.9445608854293823\n",
            "Batch 264, Meta-loss: 0.9826617240905762\n",
            "Batch 265, Meta-loss: 0.8652311563491821\n",
            "Batch 266, Meta-loss: 0.9304399490356445\n",
            "Batch 267, Meta-loss: 0.9033858180046082\n",
            "Batch 268, Meta-loss: 0.8041231036186218\n",
            "Batch 269, Meta-loss: 0.8860036730766296\n",
            "Batch 270, Meta-loss: 0.8313795924186707\n",
            "Batch 271, Meta-loss: 0.802832305431366\n",
            "Batch 272, Meta-loss: 0.9891545176506042\n",
            "Batch 273, Meta-loss: 0.9914295077323914\n",
            "Batch 274, Meta-loss: 0.8767582178115845\n",
            "Batch 275, Meta-loss: 0.7911843061447144\n",
            "Batch 276, Meta-loss: 0.8160538673400879\n",
            "Batch 277, Meta-loss: 0.8780682682991028\n",
            "Batch 278, Meta-loss: 0.9058374166488647\n",
            "Batch 279, Meta-loss: 0.8774182200431824\n",
            "Batch 280, Meta-loss: 0.8971732258796692\n",
            "Batch 281, Meta-loss: 0.820447564125061\n",
            "Batch 282, Meta-loss: 0.7988297343254089\n",
            "Batch 283, Meta-loss: 0.8115045428276062\n",
            "Batch 284, Meta-loss: 0.8826628923416138\n",
            "Batch 285, Meta-loss: 0.78902667760849\n",
            "Batch 286, Meta-loss: 1.0681806802749634\n",
            "Batch 287, Meta-loss: 0.8982033729553223\n",
            "Batch 288, Meta-loss: 0.7460856437683105\n",
            "Batch 289, Meta-loss: 0.7917107343673706\n",
            "Batch 290, Meta-loss: 0.7514524459838867\n",
            "Batch 291, Meta-loss: 0.8551656007766724\n",
            "Batch 292, Meta-loss: 0.9734094738960266\n",
            "Batch 293, Meta-loss: 0.9238296747207642\n",
            "Batch 294, Meta-loss: 0.8805181384086609\n",
            "Batch 295, Meta-loss: 0.8182966113090515\n",
            "Batch 296, Meta-loss: 0.8325244188308716\n",
            "Batch 297, Meta-loss: 0.9076248407363892\n",
            "Batch 298, Meta-loss: 0.9807406663894653\n",
            "Batch 299, Meta-loss: 0.9258473515510559\n",
            "Batch 300, Meta-loss: 0.9531353712081909\n",
            "Batch 301, Meta-loss: 0.8896673321723938\n",
            "Batch 302, Meta-loss: 0.8408656120300293\n",
            "Batch 303, Meta-loss: 0.8693312406539917\n",
            "Batch 304, Meta-loss: 0.8560851216316223\n",
            "Batch 305, Meta-loss: 0.7619340419769287\n",
            "Batch 306, Meta-loss: 0.900146484375\n",
            "Batch 307, Meta-loss: 0.916395366191864\n",
            "Batch 308, Meta-loss: 0.8887189626693726\n",
            "Batch 309, Meta-loss: 0.8688212633132935\n",
            "Batch 310, Meta-loss: 0.9064306020736694\n",
            "Batch 311, Meta-loss: 0.8202068209648132\n",
            "Batch 312, Meta-loss: 0.8788955807685852\n",
            "Batch 313, Meta-loss: 0.7976694107055664\n",
            "Batch 314, Meta-loss: 0.9367367625236511\n",
            "Batch 315, Meta-loss: 0.9473456144332886\n",
            "Batch 316, Meta-loss: 0.9747921824455261\n",
            "Batch 317, Meta-loss: 1.0728330612182617\n",
            "Batch 318, Meta-loss: 0.9121882319450378\n",
            "Batch 319, Meta-loss: 0.7655130624771118\n",
            "Batch 320, Meta-loss: 0.9822118878364563\n",
            "Batch 321, Meta-loss: 0.9730393290519714\n",
            "Batch 322, Meta-loss: 0.8482130169868469\n",
            "Batch 323, Meta-loss: 0.8547781705856323\n",
            "Batch 324, Meta-loss: 0.8916292190551758\n",
            "Batch 325, Meta-loss: 0.9801914095878601\n",
            "Batch 326, Meta-loss: 0.8774713277816772\n",
            "Batch 327, Meta-loss: 0.9624279141426086\n",
            "Batch 328, Meta-loss: 0.950840950012207\n",
            "Batch 329, Meta-loss: 0.8667969703674316\n",
            "Batch 330, Meta-loss: 0.8461998105049133\n",
            "Batch 331, Meta-loss: 1.0061428546905518\n",
            "Batch 332, Meta-loss: 0.8177945017814636\n",
            "Batch 333, Meta-loss: 0.9308306574821472\n",
            "Batch 334, Meta-loss: 0.8309423327445984\n",
            "Batch 335, Meta-loss: 0.9796590805053711\n",
            "Batch 336, Meta-loss: 0.998599648475647\n",
            "Batch 337, Meta-loss: 0.7578257918357849\n",
            "Batch 338, Meta-loss: 0.8264249563217163\n",
            "Batch 339, Meta-loss: 0.949663519859314\n",
            "Batch 340, Meta-loss: 1.048405408859253\n",
            "Batch 341, Meta-loss: 0.8919126391410828\n",
            "Batch 342, Meta-loss: 0.8957862854003906\n",
            "Batch 343, Meta-loss: 0.7684905529022217\n",
            "Batch 344, Meta-loss: 0.9263534545898438\n",
            "Batch 345, Meta-loss: 0.9108702540397644\n",
            "Batch 346, Meta-loss: 1.0911767482757568\n",
            "Batch 347, Meta-loss: 0.777776300907135\n",
            "Batch 348, Meta-loss: 0.8927205801010132\n",
            "Batch 349, Meta-loss: 0.7942000031471252\n",
            "Batch 350, Meta-loss: 0.8320916295051575\n",
            "Batch 351, Meta-loss: 0.9364134073257446\n",
            "Batch 352, Meta-loss: 0.8715444803237915\n",
            "Batch 353, Meta-loss: 0.7985754013061523\n",
            "Batch 354, Meta-loss: 0.8178181648254395\n",
            "Batch 355, Meta-loss: 0.9213132858276367\n",
            "Batch 356, Meta-loss: 0.8645668029785156\n",
            "Batch 357, Meta-loss: 1.0505297183990479\n",
            "Batch 358, Meta-loss: 0.8238002061843872\n",
            "Batch 359, Meta-loss: 0.9237911105155945\n",
            "Batch 360, Meta-loss: 0.86729496717453\n",
            "Batch 361, Meta-loss: 0.9273117780685425\n",
            "Batch 362, Meta-loss: 0.9943893551826477\n",
            "Batch 363, Meta-loss: 0.824249267578125\n",
            "Batch 364, Meta-loss: 0.7869139909744263\n",
            "Batch 365, Meta-loss: 0.7615687251091003\n",
            "Batch 366, Meta-loss: 0.7884044051170349\n",
            "Batch 367, Meta-loss: 1.0003149509429932\n",
            "Batch 368, Meta-loss: 0.9101689457893372\n",
            "Batch 369, Meta-loss: 0.8047691583633423\n",
            "Batch 370, Meta-loss: 0.9068899154663086\n",
            "Batch 371, Meta-loss: 0.9082741737365723\n",
            "Batch 372, Meta-loss: 0.8199227452278137\n",
            "Batch 373, Meta-loss: 1.179396152496338\n",
            "Batch 374, Meta-loss: 0.9591124653816223\n",
            "Batch 375, Meta-loss: 0.819389820098877\n",
            "Epoch 7\n",
            "Batch 1, Meta-loss: 0.9315451383590698\n",
            "Batch 2, Meta-loss: 1.068426489830017\n",
            "Batch 3, Meta-loss: 0.8619556427001953\n",
            "Batch 4, Meta-loss: 0.8923357725143433\n",
            "Batch 5, Meta-loss: 0.982560932636261\n",
            "Batch 6, Meta-loss: 0.9597724676132202\n",
            "Batch 7, Meta-loss: 0.8829352259635925\n",
            "Batch 8, Meta-loss: 0.983572781085968\n",
            "Batch 9, Meta-loss: 0.8831555247306824\n",
            "Batch 10, Meta-loss: 0.7456734776496887\n",
            "Batch 11, Meta-loss: 0.8308228254318237\n",
            "Batch 12, Meta-loss: 0.7336227297782898\n",
            "Batch 13, Meta-loss: 0.926762580871582\n",
            "Batch 14, Meta-loss: 1.0131605863571167\n",
            "Batch 15, Meta-loss: 0.7626012563705444\n",
            "Batch 16, Meta-loss: 0.752156674861908\n",
            "Batch 17, Meta-loss: 0.723648190498352\n",
            "Batch 18, Meta-loss: 0.7357240915298462\n",
            "Batch 19, Meta-loss: 0.7889238595962524\n",
            "Batch 20, Meta-loss: 0.802440345287323\n",
            "Batch 21, Meta-loss: 0.8601571917533875\n",
            "Batch 22, Meta-loss: 0.9244411587715149\n",
            "Batch 23, Meta-loss: 0.7574580907821655\n",
            "Batch 24, Meta-loss: 0.8053447008132935\n",
            "Batch 25, Meta-loss: 0.9335483312606812\n",
            "Batch 26, Meta-loss: 0.8287578821182251\n",
            "Batch 27, Meta-loss: 0.8575910329818726\n",
            "Batch 28, Meta-loss: 0.9315069913864136\n",
            "Batch 29, Meta-loss: 0.8206842541694641\n",
            "Batch 30, Meta-loss: 1.0000813007354736\n",
            "Batch 31, Meta-loss: 0.7689794301986694\n",
            "Batch 32, Meta-loss: 0.9967352151870728\n",
            "Batch 33, Meta-loss: 0.8428676724433899\n",
            "Batch 34, Meta-loss: 0.8620129823684692\n",
            "Batch 35, Meta-loss: 0.9359585046768188\n",
            "Batch 36, Meta-loss: 0.944242000579834\n",
            "Batch 37, Meta-loss: 0.9783485531806946\n",
            "Batch 38, Meta-loss: 0.9451576471328735\n",
            "Batch 39, Meta-loss: 0.8161422610282898\n",
            "Batch 40, Meta-loss: 0.6948509216308594\n",
            "Batch 41, Meta-loss: 0.7958958148956299\n",
            "Batch 42, Meta-loss: 1.0248346328735352\n",
            "Batch 43, Meta-loss: 0.9028814435005188\n",
            "Batch 44, Meta-loss: 0.7908390760421753\n",
            "Batch 45, Meta-loss: 0.7780157923698425\n",
            "Batch 46, Meta-loss: 0.7458934783935547\n",
            "Batch 47, Meta-loss: 0.9411221742630005\n",
            "Batch 48, Meta-loss: 0.8104225397109985\n",
            "Batch 49, Meta-loss: 0.7570436596870422\n",
            "Batch 50, Meta-loss: 0.8660358190536499\n",
            "Batch 51, Meta-loss: 0.8131775856018066\n",
            "Batch 52, Meta-loss: 0.9364086389541626\n",
            "Batch 53, Meta-loss: 0.9616287350654602\n",
            "Batch 54, Meta-loss: 0.6930253505706787\n",
            "Batch 55, Meta-loss: 0.7687321901321411\n",
            "Batch 56, Meta-loss: 0.7947747707366943\n",
            "Batch 57, Meta-loss: 0.690802276134491\n",
            "Batch 58, Meta-loss: 0.9228569269180298\n",
            "Batch 59, Meta-loss: 0.891745924949646\n",
            "Batch 60, Meta-loss: 0.7866619229316711\n",
            "Batch 61, Meta-loss: 0.8955466151237488\n",
            "Batch 62, Meta-loss: 0.8668305277824402\n",
            "Batch 63, Meta-loss: 0.9986827969551086\n",
            "Batch 64, Meta-loss: 0.8506115674972534\n",
            "Batch 65, Meta-loss: 0.8404611349105835\n",
            "Batch 66, Meta-loss: 1.119343876838684\n",
            "Batch 67, Meta-loss: 0.744085967540741\n",
            "Batch 68, Meta-loss: 0.8210502862930298\n",
            "Batch 69, Meta-loss: 0.9109356999397278\n",
            "Batch 70, Meta-loss: 1.1393814086914062\n",
            "Batch 71, Meta-loss: 0.8249284029006958\n",
            "Batch 72, Meta-loss: 0.8378190994262695\n",
            "Batch 73, Meta-loss: 0.8016403317451477\n",
            "Batch 74, Meta-loss: 0.9250055551528931\n",
            "Batch 75, Meta-loss: 0.8617016077041626\n",
            "Batch 76, Meta-loss: 0.9560672640800476\n",
            "Batch 77, Meta-loss: 0.936760425567627\n",
            "Batch 78, Meta-loss: 0.9470522999763489\n",
            "Batch 79, Meta-loss: 0.846074104309082\n",
            "Batch 80, Meta-loss: 0.819801926612854\n",
            "Batch 81, Meta-loss: 0.7140403985977173\n",
            "Batch 82, Meta-loss: 0.7013701796531677\n",
            "Batch 83, Meta-loss: 0.8784109950065613\n",
            "Batch 84, Meta-loss: 0.9136988520622253\n",
            "Batch 85, Meta-loss: 0.867587685585022\n",
            "Batch 86, Meta-loss: 0.7789472937583923\n",
            "Batch 87, Meta-loss: 0.8853546380996704\n",
            "Batch 88, Meta-loss: 0.8112801313400269\n",
            "Batch 89, Meta-loss: 0.8444513082504272\n",
            "Batch 90, Meta-loss: 0.7409177422523499\n",
            "Batch 91, Meta-loss: 0.8721668124198914\n",
            "Batch 92, Meta-loss: 0.9027303457260132\n",
            "Batch 93, Meta-loss: 0.937964141368866\n",
            "Batch 94, Meta-loss: 0.8535927534103394\n",
            "Batch 95, Meta-loss: 0.9216340780258179\n",
            "Batch 96, Meta-loss: 0.751177191734314\n",
            "Batch 97, Meta-loss: 0.9922914505004883\n",
            "Batch 98, Meta-loss: 0.883980393409729\n",
            "Batch 99, Meta-loss: 0.9044524431228638\n",
            "Batch 100, Meta-loss: 0.9512017369270325\n",
            "Batch 101, Meta-loss: 0.6774250268936157\n",
            "Batch 102, Meta-loss: 0.8027241826057434\n",
            "Batch 103, Meta-loss: 0.8227967023849487\n",
            "Batch 104, Meta-loss: 0.9970291256904602\n",
            "Batch 105, Meta-loss: 0.8302799463272095\n",
            "Batch 106, Meta-loss: 0.9086850881576538\n",
            "Batch 107, Meta-loss: 1.0312929153442383\n",
            "Batch 108, Meta-loss: 0.9003025889396667\n",
            "Batch 109, Meta-loss: 0.8419266939163208\n",
            "Batch 110, Meta-loss: 0.9563125371932983\n",
            "Batch 111, Meta-loss: 0.8325636982917786\n",
            "Batch 112, Meta-loss: 0.9187606573104858\n",
            "Batch 113, Meta-loss: 0.8669596910476685\n",
            "Batch 114, Meta-loss: 0.9857834577560425\n",
            "Batch 115, Meta-loss: 0.9203336834907532\n",
            "Batch 116, Meta-loss: 0.9675060510635376\n",
            "Batch 117, Meta-loss: 0.733691394329071\n",
            "Batch 118, Meta-loss: 0.9888818860054016\n",
            "Batch 119, Meta-loss: 0.8086960911750793\n",
            "Batch 120, Meta-loss: 0.9220474362373352\n",
            "Batch 121, Meta-loss: 0.8480752110481262\n",
            "Batch 122, Meta-loss: 0.83930504322052\n",
            "Batch 123, Meta-loss: 0.9652868509292603\n",
            "Batch 124, Meta-loss: 0.7010123133659363\n",
            "Batch 125, Meta-loss: 0.8909408450126648\n",
            "Batch 126, Meta-loss: 0.7497468590736389\n",
            "Batch 127, Meta-loss: 0.844036877155304\n",
            "Batch 128, Meta-loss: 1.0953729152679443\n",
            "Batch 129, Meta-loss: 0.8962787389755249\n",
            "Batch 130, Meta-loss: 0.9443613290786743\n",
            "Batch 131, Meta-loss: 0.8481714129447937\n",
            "Batch 132, Meta-loss: 0.8377004861831665\n",
            "Batch 133, Meta-loss: 1.0079190731048584\n",
            "Batch 134, Meta-loss: 0.9545888900756836\n",
            "Batch 135, Meta-loss: 0.8763504028320312\n",
            "Batch 136, Meta-loss: 0.7714481353759766\n",
            "Batch 137, Meta-loss: 0.8059980273246765\n",
            "Batch 138, Meta-loss: 1.105672001838684\n",
            "Batch 139, Meta-loss: 0.8974577188491821\n",
            "Batch 140, Meta-loss: 1.0458953380584717\n",
            "Batch 141, Meta-loss: 0.9704071879386902\n",
            "Batch 142, Meta-loss: 0.7954930663108826\n",
            "Batch 143, Meta-loss: 0.9454809427261353\n",
            "Batch 144, Meta-loss: 0.9216510057449341\n",
            "Batch 145, Meta-loss: 0.8437772989273071\n",
            "Batch 146, Meta-loss: 0.7817405462265015\n",
            "Batch 147, Meta-loss: 1.0279982089996338\n",
            "Batch 148, Meta-loss: 0.7769298553466797\n",
            "Batch 149, Meta-loss: 0.7520290613174438\n",
            "Batch 150, Meta-loss: 0.9467333555221558\n",
            "Batch 151, Meta-loss: 0.8787256479263306\n",
            "Batch 152, Meta-loss: 0.8009883761405945\n",
            "Batch 153, Meta-loss: 0.790989100933075\n",
            "Batch 154, Meta-loss: 0.79190993309021\n",
            "Batch 155, Meta-loss: 1.0730314254760742\n",
            "Batch 156, Meta-loss: 0.8224050402641296\n",
            "Batch 157, Meta-loss: 0.7471725940704346\n",
            "Batch 158, Meta-loss: 0.8473207354545593\n",
            "Batch 159, Meta-loss: 1.0409609079360962\n",
            "Batch 160, Meta-loss: 0.8873831629753113\n",
            "Batch 161, Meta-loss: 0.8972021341323853\n",
            "Batch 162, Meta-loss: 0.7918267846107483\n",
            "Batch 163, Meta-loss: 1.039289116859436\n",
            "Batch 164, Meta-loss: 0.9608191251754761\n",
            "Batch 165, Meta-loss: 0.9570298194885254\n",
            "Batch 166, Meta-loss: 0.9479732513427734\n",
            "Batch 167, Meta-loss: 0.8524234890937805\n",
            "Batch 168, Meta-loss: 0.8239185214042664\n",
            "Batch 169, Meta-loss: 0.8827682733535767\n",
            "Batch 170, Meta-loss: 1.0564130544662476\n",
            "Batch 171, Meta-loss: 0.9030348062515259\n",
            "Batch 172, Meta-loss: 0.9562530517578125\n",
            "Batch 173, Meta-loss: 0.7652091979980469\n",
            "Batch 174, Meta-loss: 0.8491290211677551\n",
            "Batch 175, Meta-loss: 0.7341535687446594\n",
            "Batch 176, Meta-loss: 0.9411331415176392\n",
            "Batch 177, Meta-loss: 0.9279727935791016\n",
            "Batch 178, Meta-loss: 1.0163992643356323\n",
            "Batch 179, Meta-loss: 1.0980684757232666\n",
            "Batch 180, Meta-loss: 0.8816768527030945\n",
            "Batch 181, Meta-loss: 0.8995113372802734\n",
            "Batch 182, Meta-loss: 0.9414325952529907\n",
            "Batch 183, Meta-loss: 0.843419075012207\n",
            "Batch 184, Meta-loss: 0.8475974798202515\n",
            "Batch 185, Meta-loss: 0.9084662199020386\n",
            "Batch 186, Meta-loss: 0.8576539754867554\n",
            "Batch 187, Meta-loss: 0.8911316990852356\n",
            "Batch 188, Meta-loss: 0.8076552152633667\n",
            "Batch 189, Meta-loss: 0.8299600481987\n",
            "Batch 190, Meta-loss: 0.8084601163864136\n",
            "Batch 191, Meta-loss: 0.828276515007019\n",
            "Batch 192, Meta-loss: 1.0466690063476562\n",
            "Batch 193, Meta-loss: 0.8614179491996765\n",
            "Batch 194, Meta-loss: 0.8699225187301636\n",
            "Batch 195, Meta-loss: 1.0290522575378418\n",
            "Batch 196, Meta-loss: 0.8469775915145874\n",
            "Batch 197, Meta-loss: 0.9444875717163086\n",
            "Batch 198, Meta-loss: 0.8559209704399109\n",
            "Batch 199, Meta-loss: 0.8522100448608398\n",
            "Batch 200, Meta-loss: 0.9356826543807983\n",
            "Batch 201, Meta-loss: 0.8768402338027954\n",
            "Batch 202, Meta-loss: 1.0067317485809326\n",
            "Batch 203, Meta-loss: 0.9069324731826782\n",
            "Batch 204, Meta-loss: 0.9409605860710144\n",
            "Batch 205, Meta-loss: 0.9769406318664551\n",
            "Batch 206, Meta-loss: 0.8475062251091003\n",
            "Batch 207, Meta-loss: 0.8178871870040894\n",
            "Batch 208, Meta-loss: 0.7927460670471191\n",
            "Batch 209, Meta-loss: 0.9585493206977844\n",
            "Batch 210, Meta-loss: 0.9237574338912964\n",
            "Batch 211, Meta-loss: 0.8900240063667297\n",
            "Batch 212, Meta-loss: 0.8971783518791199\n",
            "Batch 213, Meta-loss: 1.043527603149414\n",
            "Batch 214, Meta-loss: 0.7551008462905884\n",
            "Batch 215, Meta-loss: 0.8530004620552063\n",
            "Batch 216, Meta-loss: 0.7619785666465759\n",
            "Batch 217, Meta-loss: 0.86799556016922\n",
            "Batch 218, Meta-loss: 0.7785323858261108\n",
            "Batch 219, Meta-loss: 0.9324883222579956\n",
            "Batch 220, Meta-loss: 0.8089596629142761\n",
            "Batch 221, Meta-loss: 0.8006763458251953\n",
            "Batch 222, Meta-loss: 0.9493781328201294\n",
            "Batch 223, Meta-loss: 0.8954340815544128\n",
            "Batch 224, Meta-loss: 0.7882488369941711\n",
            "Batch 225, Meta-loss: 0.9328073263168335\n",
            "Batch 226, Meta-loss: 1.0060951709747314\n",
            "Batch 227, Meta-loss: 0.9610134959220886\n",
            "Batch 228, Meta-loss: 0.902600884437561\n",
            "Batch 229, Meta-loss: 0.9396610260009766\n",
            "Batch 230, Meta-loss: 0.9005883932113647\n",
            "Batch 231, Meta-loss: 0.9590038061141968\n",
            "Batch 232, Meta-loss: 0.9335776567459106\n",
            "Batch 233, Meta-loss: 1.0576212406158447\n",
            "Batch 234, Meta-loss: 0.9097260236740112\n",
            "Batch 235, Meta-loss: 0.7722148895263672\n",
            "Batch 236, Meta-loss: 0.8930231332778931\n",
            "Batch 237, Meta-loss: 0.8059236407279968\n",
            "Batch 238, Meta-loss: 1.0117136240005493\n",
            "Batch 239, Meta-loss: 0.8456223607063293\n",
            "Batch 240, Meta-loss: 0.7827855944633484\n",
            "Batch 241, Meta-loss: 1.112245798110962\n",
            "Batch 242, Meta-loss: 0.9984523057937622\n",
            "Batch 243, Meta-loss: 0.8298217058181763\n",
            "Batch 244, Meta-loss: 0.9683235883712769\n",
            "Batch 245, Meta-loss: 0.9352867007255554\n",
            "Batch 246, Meta-loss: 1.0444012880325317\n",
            "Batch 247, Meta-loss: 0.8152809143066406\n",
            "Batch 248, Meta-loss: 0.735528826713562\n",
            "Batch 249, Meta-loss: 1.0649206638336182\n",
            "Batch 250, Meta-loss: 0.9881764650344849\n",
            "Batch 251, Meta-loss: 0.7247132658958435\n",
            "Batch 252, Meta-loss: 0.8235586285591125\n",
            "Batch 253, Meta-loss: 0.812781035900116\n",
            "Batch 254, Meta-loss: 0.8467165231704712\n",
            "Batch 255, Meta-loss: 0.8549335598945618\n",
            "Batch 256, Meta-loss: 0.8211948275566101\n",
            "Batch 257, Meta-loss: 0.8083900213241577\n",
            "Batch 258, Meta-loss: 0.8742995262145996\n",
            "Batch 259, Meta-loss: 0.8642572164535522\n",
            "Batch 260, Meta-loss: 0.7905062437057495\n",
            "Batch 261, Meta-loss: 0.9059423208236694\n",
            "Batch 262, Meta-loss: 0.7760065197944641\n",
            "Batch 263, Meta-loss: 0.9132922887802124\n",
            "Batch 264, Meta-loss: 1.0348961353302002\n",
            "Batch 265, Meta-loss: 0.7860274314880371\n",
            "Batch 266, Meta-loss: 0.845608115196228\n",
            "Batch 267, Meta-loss: 0.8320842981338501\n",
            "Batch 268, Meta-loss: 1.034234881401062\n",
            "Batch 269, Meta-loss: 1.058680534362793\n",
            "Batch 270, Meta-loss: 1.089397668838501\n",
            "Batch 271, Meta-loss: 0.8382228016853333\n",
            "Batch 272, Meta-loss: 0.8307069540023804\n",
            "Batch 273, Meta-loss: 0.8973652720451355\n",
            "Batch 274, Meta-loss: 0.8244487643241882\n",
            "Batch 275, Meta-loss: 1.0038249492645264\n",
            "Batch 276, Meta-loss: 0.86265629529953\n",
            "Batch 277, Meta-loss: 0.7995938062667847\n",
            "Batch 278, Meta-loss: 0.8949000239372253\n",
            "Batch 279, Meta-loss: 0.8938804864883423\n",
            "Batch 280, Meta-loss: 0.8374187350273132\n",
            "Batch 281, Meta-loss: 0.8438119888305664\n",
            "Batch 282, Meta-loss: 0.8692672848701477\n",
            "Batch 283, Meta-loss: 0.9979915618896484\n",
            "Batch 284, Meta-loss: 0.7800233364105225\n",
            "Batch 285, Meta-loss: 1.0031919479370117\n",
            "Batch 286, Meta-loss: 0.8980456590652466\n",
            "Batch 287, Meta-loss: 0.9403548240661621\n",
            "Batch 288, Meta-loss: 0.9034951329231262\n",
            "Batch 289, Meta-loss: 0.8025199770927429\n",
            "Batch 290, Meta-loss: 1.005236029624939\n",
            "Batch 291, Meta-loss: 0.8680740594863892\n",
            "Batch 292, Meta-loss: 0.920741081237793\n",
            "Batch 293, Meta-loss: 0.835629940032959\n",
            "Batch 294, Meta-loss: 0.8463155627250671\n",
            "Batch 295, Meta-loss: 1.0236746072769165\n",
            "Batch 296, Meta-loss: 0.7932367920875549\n",
            "Batch 297, Meta-loss: 0.8758845329284668\n",
            "Batch 298, Meta-loss: 0.8032007217407227\n",
            "Batch 299, Meta-loss: 0.8756586313247681\n",
            "Batch 300, Meta-loss: 0.890328586101532\n",
            "Batch 301, Meta-loss: 0.9013420343399048\n",
            "Batch 302, Meta-loss: 0.9499592781066895\n",
            "Batch 303, Meta-loss: 0.8091643452644348\n",
            "Batch 304, Meta-loss: 0.7691876292228699\n",
            "Batch 305, Meta-loss: 0.8547269701957703\n",
            "Batch 306, Meta-loss: 0.8535574078559875\n",
            "Batch 307, Meta-loss: 0.9696691632270813\n",
            "Batch 308, Meta-loss: 0.9176572561264038\n",
            "Batch 309, Meta-loss: 0.909760594367981\n",
            "Batch 310, Meta-loss: 1.182408332824707\n",
            "Batch 311, Meta-loss: 1.0006606578826904\n",
            "Batch 312, Meta-loss: 0.9776175618171692\n",
            "Batch 313, Meta-loss: 1.0105327367782593\n",
            "Batch 314, Meta-loss: 0.8635126948356628\n",
            "Batch 315, Meta-loss: 0.8432566523551941\n",
            "Batch 316, Meta-loss: 1.0050461292266846\n",
            "Batch 317, Meta-loss: 0.923430323600769\n",
            "Batch 318, Meta-loss: 1.0268076658248901\n",
            "Batch 319, Meta-loss: 0.8711749911308289\n",
            "Batch 320, Meta-loss: 0.9490194320678711\n",
            "Batch 321, Meta-loss: 0.971835732460022\n",
            "Batch 322, Meta-loss: 1.0174485445022583\n",
            "Batch 323, Meta-loss: 0.7033683657646179\n",
            "Batch 324, Meta-loss: 0.8712257146835327\n",
            "Batch 325, Meta-loss: 1.0131791830062866\n",
            "Batch 326, Meta-loss: 0.7432757616043091\n",
            "Batch 327, Meta-loss: 1.053626298904419\n",
            "Batch 328, Meta-loss: 0.8896835446357727\n",
            "Batch 329, Meta-loss: 0.9589942693710327\n",
            "Batch 330, Meta-loss: 0.9575480222702026\n",
            "Batch 331, Meta-loss: 0.8959341049194336\n",
            "Batch 332, Meta-loss: 1.1573208570480347\n",
            "Batch 333, Meta-loss: 0.8943050503730774\n",
            "Batch 334, Meta-loss: 0.8755174875259399\n",
            "Batch 335, Meta-loss: 0.8890930414199829\n",
            "Batch 336, Meta-loss: 0.8663979768753052\n",
            "Batch 337, Meta-loss: 0.9162129163742065\n",
            "Batch 338, Meta-loss: 0.8720895051956177\n",
            "Batch 339, Meta-loss: 0.9191035032272339\n",
            "Batch 340, Meta-loss: 0.9858074188232422\n",
            "Batch 341, Meta-loss: 1.1623198986053467\n",
            "Batch 342, Meta-loss: 0.819675624370575\n",
            "Batch 343, Meta-loss: 0.9615403413772583\n",
            "Batch 344, Meta-loss: 1.0891139507293701\n",
            "Batch 345, Meta-loss: 1.1934860944747925\n",
            "Batch 346, Meta-loss: 1.0678598880767822\n",
            "Batch 347, Meta-loss: 0.914779782295227\n",
            "Batch 348, Meta-loss: 1.003788948059082\n",
            "Batch 349, Meta-loss: 0.8534658551216125\n",
            "Batch 350, Meta-loss: 0.9179838299751282\n",
            "Batch 351, Meta-loss: 0.8834269642829895\n",
            "Batch 352, Meta-loss: 1.0375573635101318\n",
            "Batch 353, Meta-loss: 0.7709643840789795\n",
            "Batch 354, Meta-loss: 0.8609105348587036\n",
            "Batch 355, Meta-loss: 0.969037652015686\n",
            "Batch 356, Meta-loss: 1.0386111736297607\n",
            "Batch 357, Meta-loss: 0.8529938459396362\n",
            "Batch 358, Meta-loss: 0.9375497698783875\n",
            "Batch 359, Meta-loss: 0.9468232989311218\n",
            "Batch 360, Meta-loss: 0.839885413646698\n",
            "Batch 361, Meta-loss: 1.0348395109176636\n",
            "Batch 362, Meta-loss: 0.8796356320381165\n",
            "Batch 363, Meta-loss: 1.0585322380065918\n",
            "Batch 364, Meta-loss: 0.890609085559845\n",
            "Batch 365, Meta-loss: 0.8873382806777954\n",
            "Batch 366, Meta-loss: 0.8608789443969727\n",
            "Batch 367, Meta-loss: 0.7115839719772339\n",
            "Batch 368, Meta-loss: 0.8384904861450195\n",
            "Batch 369, Meta-loss: 0.7596114277839661\n",
            "Batch 370, Meta-loss: 0.7458585500717163\n",
            "Batch 371, Meta-loss: 0.9035516977310181\n",
            "Batch 372, Meta-loss: 0.9171382784843445\n",
            "Batch 373, Meta-loss: 0.9124497175216675\n",
            "Batch 374, Meta-loss: 0.8617572784423828\n",
            "Batch 375, Meta-loss: 0.8737090229988098\n",
            "Epoch 8\n",
            "Batch 1, Meta-loss: 0.9144722819328308\n",
            "Batch 2, Meta-loss: 0.8529518842697144\n",
            "Batch 3, Meta-loss: 0.9045828580856323\n",
            "Batch 4, Meta-loss: 1.0814234018325806\n",
            "Batch 5, Meta-loss: 0.9472253918647766\n",
            "Batch 6, Meta-loss: 0.8467914462089539\n",
            "Batch 7, Meta-loss: 0.9024711847305298\n",
            "Batch 8, Meta-loss: 0.968536376953125\n",
            "Batch 9, Meta-loss: 1.0716888904571533\n",
            "Batch 10, Meta-loss: 0.8932905197143555\n",
            "Batch 11, Meta-loss: 0.9535552263259888\n",
            "Batch 12, Meta-loss: 0.865471363067627\n",
            "Batch 13, Meta-loss: 0.8752678632736206\n",
            "Batch 14, Meta-loss: 0.8310141563415527\n",
            "Batch 15, Meta-loss: 0.9029209017753601\n",
            "Batch 16, Meta-loss: 0.8605772256851196\n",
            "Batch 17, Meta-loss: 0.9947955012321472\n",
            "Batch 18, Meta-loss: 0.9615409970283508\n",
            "Batch 19, Meta-loss: 1.204912781715393\n",
            "Batch 20, Meta-loss: 0.9448230862617493\n",
            "Batch 21, Meta-loss: 0.799094557762146\n",
            "Batch 22, Meta-loss: 0.854736328125\n",
            "Batch 23, Meta-loss: 1.0576883554458618\n",
            "Batch 24, Meta-loss: 0.930472195148468\n",
            "Batch 25, Meta-loss: 0.7695284485816956\n",
            "Batch 26, Meta-loss: 1.0006126165390015\n",
            "Batch 27, Meta-loss: 0.6967830657958984\n",
            "Batch 28, Meta-loss: 0.9402614831924438\n",
            "Batch 29, Meta-loss: 0.9162663221359253\n",
            "Batch 30, Meta-loss: 1.0054130554199219\n",
            "Batch 31, Meta-loss: 0.8676406741142273\n",
            "Batch 32, Meta-loss: 0.9203985929489136\n",
            "Batch 33, Meta-loss: 0.7935958504676819\n",
            "Batch 34, Meta-loss: 0.7970585823059082\n",
            "Batch 35, Meta-loss: 1.0023305416107178\n",
            "Batch 36, Meta-loss: 0.9182814359664917\n",
            "Batch 37, Meta-loss: 0.9230167269706726\n",
            "Batch 38, Meta-loss: 0.8959841728210449\n",
            "Batch 39, Meta-loss: 0.9429181218147278\n",
            "Batch 40, Meta-loss: 0.9984582662582397\n",
            "Batch 41, Meta-loss: 0.8385963439941406\n",
            "Batch 42, Meta-loss: 0.8524587750434875\n",
            "Batch 43, Meta-loss: 0.9724953770637512\n",
            "Batch 44, Meta-loss: 0.8237333297729492\n",
            "Batch 45, Meta-loss: 0.8663343191146851\n",
            "Batch 46, Meta-loss: 0.916039764881134\n",
            "Batch 47, Meta-loss: 0.9289840459823608\n",
            "Batch 48, Meta-loss: 1.1379783153533936\n",
            "Batch 49, Meta-loss: 0.9647238850593567\n",
            "Batch 50, Meta-loss: 0.8806565403938293\n",
            "Batch 51, Meta-loss: 0.7289787530899048\n",
            "Batch 52, Meta-loss: 0.8384948968887329\n",
            "Batch 53, Meta-loss: 0.8791449666023254\n",
            "Batch 54, Meta-loss: 1.1157135963439941\n",
            "Batch 55, Meta-loss: 0.8285000920295715\n",
            "Batch 56, Meta-loss: 0.9211940765380859\n",
            "Batch 57, Meta-loss: 0.8391883969306946\n",
            "Batch 58, Meta-loss: 1.065600037574768\n",
            "Batch 59, Meta-loss: 0.9708420634269714\n",
            "Batch 60, Meta-loss: 0.8076295852661133\n",
            "Batch 61, Meta-loss: 1.035262107849121\n",
            "Batch 62, Meta-loss: 0.8770591020584106\n",
            "Batch 63, Meta-loss: 0.7629983425140381\n",
            "Batch 64, Meta-loss: 0.8358739018440247\n",
            "Batch 65, Meta-loss: 0.8294236063957214\n",
            "Batch 66, Meta-loss: 0.9530690312385559\n",
            "Batch 67, Meta-loss: 1.036841869354248\n",
            "Batch 68, Meta-loss: 0.7629543542861938\n",
            "Batch 69, Meta-loss: 0.8695012927055359\n",
            "Batch 70, Meta-loss: 0.9499777555465698\n",
            "Batch 71, Meta-loss: 0.9983910322189331\n",
            "Batch 72, Meta-loss: 0.9692036509513855\n",
            "Batch 73, Meta-loss: 0.970302939414978\n",
            "Batch 74, Meta-loss: 0.9683725237846375\n",
            "Batch 75, Meta-loss: 0.920194149017334\n",
            "Batch 76, Meta-loss: 0.8375704884529114\n",
            "Batch 77, Meta-loss: 1.0230557918548584\n",
            "Batch 78, Meta-loss: 0.8736076354980469\n",
            "Batch 79, Meta-loss: 0.8326929807662964\n",
            "Batch 80, Meta-loss: 0.8261831402778625\n",
            "Batch 81, Meta-loss: 0.9312254786491394\n",
            "Batch 82, Meta-loss: 0.725131094455719\n",
            "Batch 83, Meta-loss: 0.8298103213310242\n",
            "Batch 84, Meta-loss: 0.6782348155975342\n",
            "Batch 85, Meta-loss: 0.8534606695175171\n",
            "Batch 86, Meta-loss: 0.9754348993301392\n",
            "Batch 87, Meta-loss: 0.893101692199707\n",
            "Batch 88, Meta-loss: 0.920366108417511\n",
            "Batch 89, Meta-loss: 1.0146591663360596\n",
            "Batch 90, Meta-loss: 0.8915179967880249\n",
            "Batch 91, Meta-loss: 0.9771361351013184\n",
            "Batch 92, Meta-loss: 0.9702741503715515\n",
            "Batch 93, Meta-loss: 0.9551984071731567\n",
            "Batch 94, Meta-loss: 0.8873359560966492\n",
            "Batch 95, Meta-loss: 0.8626056909561157\n",
            "Batch 96, Meta-loss: 0.9841904640197754\n",
            "Batch 97, Meta-loss: 0.8531621098518372\n",
            "Batch 98, Meta-loss: 0.9117269515991211\n",
            "Batch 99, Meta-loss: 0.8596026301383972\n",
            "Batch 100, Meta-loss: 0.9918929934501648\n",
            "Batch 101, Meta-loss: 1.006000280380249\n",
            "Batch 102, Meta-loss: 0.7856035232543945\n",
            "Batch 103, Meta-loss: 0.8916429281234741\n",
            "Batch 104, Meta-loss: 1.039170503616333\n",
            "Batch 105, Meta-loss: 0.823045551776886\n",
            "Batch 106, Meta-loss: 0.8042513728141785\n",
            "Batch 107, Meta-loss: 0.8141051530838013\n",
            "Batch 108, Meta-loss: 0.834945559501648\n",
            "Batch 109, Meta-loss: 0.8923989534378052\n",
            "Batch 110, Meta-loss: 0.8201645612716675\n",
            "Batch 111, Meta-loss: 0.9796113967895508\n",
            "Batch 112, Meta-loss: 0.8382589221000671\n",
            "Batch 113, Meta-loss: 0.7770489454269409\n",
            "Batch 114, Meta-loss: 0.8597148060798645\n",
            "Batch 115, Meta-loss: 1.0026206970214844\n",
            "Batch 116, Meta-loss: 0.8683284521102905\n",
            "Batch 117, Meta-loss: 1.0637893676757812\n",
            "Batch 118, Meta-loss: 0.8655213117599487\n",
            "Batch 119, Meta-loss: 1.0221222639083862\n",
            "Batch 120, Meta-loss: 0.8504805564880371\n",
            "Batch 121, Meta-loss: 0.7829757928848267\n",
            "Batch 122, Meta-loss: 0.9161855578422546\n",
            "Batch 123, Meta-loss: 1.0402872562408447\n",
            "Batch 124, Meta-loss: 1.0610405206680298\n",
            "Batch 125, Meta-loss: 0.7810465693473816\n",
            "Batch 126, Meta-loss: 0.9899579882621765\n",
            "Batch 127, Meta-loss: 0.812979519367218\n",
            "Batch 128, Meta-loss: 0.8714311718940735\n",
            "Batch 129, Meta-loss: 0.9574925303459167\n",
            "Batch 130, Meta-loss: 0.9499499201774597\n",
            "Batch 131, Meta-loss: 0.8418639898300171\n",
            "Batch 132, Meta-loss: 1.0155999660491943\n",
            "Batch 133, Meta-loss: 1.194739818572998\n",
            "Batch 134, Meta-loss: 0.8165057301521301\n",
            "Batch 135, Meta-loss: 1.0221012830734253\n",
            "Batch 136, Meta-loss: 0.8448281288146973\n",
            "Batch 137, Meta-loss: 0.9830760955810547\n",
            "Batch 138, Meta-loss: 0.9385966062545776\n",
            "Batch 139, Meta-loss: 0.8957146406173706\n",
            "Batch 140, Meta-loss: 0.9610092043876648\n",
            "Batch 141, Meta-loss: 0.8771485090255737\n",
            "Batch 142, Meta-loss: 0.9998839497566223\n",
            "Batch 143, Meta-loss: 0.9635009765625\n",
            "Batch 144, Meta-loss: 0.7478975057601929\n",
            "Batch 145, Meta-loss: 0.8461847305297852\n",
            "Batch 146, Meta-loss: 1.0001862049102783\n",
            "Batch 147, Meta-loss: 0.932894229888916\n",
            "Batch 148, Meta-loss: 1.10590398311615\n",
            "Batch 149, Meta-loss: 1.1313725709915161\n",
            "Batch 150, Meta-loss: 0.9103595614433289\n",
            "Batch 151, Meta-loss: 0.8930250406265259\n",
            "Batch 152, Meta-loss: 0.9700430035591125\n",
            "Batch 153, Meta-loss: 0.965598464012146\n",
            "Batch 154, Meta-loss: 0.9489957094192505\n",
            "Batch 155, Meta-loss: 1.0512921810150146\n",
            "Batch 156, Meta-loss: 0.8268355131149292\n",
            "Batch 157, Meta-loss: 0.8911595344543457\n",
            "Batch 158, Meta-loss: 0.9866788983345032\n",
            "Batch 159, Meta-loss: 0.9304026365280151\n",
            "Batch 160, Meta-loss: 0.8756087422370911\n",
            "Batch 161, Meta-loss: 1.0287139415740967\n",
            "Batch 162, Meta-loss: 0.7825881242752075\n",
            "Batch 163, Meta-loss: 1.068016529083252\n",
            "Batch 164, Meta-loss: 0.8207372426986694\n",
            "Batch 165, Meta-loss: 0.9380887746810913\n",
            "Batch 166, Meta-loss: 0.8505175709724426\n",
            "Batch 167, Meta-loss: 0.957908034324646\n",
            "Batch 168, Meta-loss: 0.7951372861862183\n",
            "Batch 169, Meta-loss: 1.0278178453445435\n",
            "Batch 170, Meta-loss: 0.8696693181991577\n",
            "Batch 171, Meta-loss: 0.9542734026908875\n",
            "Batch 172, Meta-loss: 1.0304725170135498\n",
            "Batch 173, Meta-loss: 0.9794517755508423\n",
            "Batch 174, Meta-loss: 0.8102184534072876\n",
            "Batch 175, Meta-loss: 0.9859574437141418\n",
            "Batch 176, Meta-loss: 1.0186617374420166\n",
            "Batch 177, Meta-loss: 0.8694394826889038\n",
            "Batch 178, Meta-loss: 0.8762515187263489\n",
            "Batch 179, Meta-loss: 0.8138009905815125\n",
            "Batch 180, Meta-loss: 0.9392342567443848\n",
            "Batch 181, Meta-loss: 0.9014301300048828\n",
            "Batch 182, Meta-loss: 0.9414972066879272\n",
            "Batch 183, Meta-loss: 0.9480453729629517\n",
            "Batch 184, Meta-loss: 0.9085624814033508\n",
            "Batch 185, Meta-loss: 0.9230333566665649\n",
            "Batch 186, Meta-loss: 0.8944795727729797\n",
            "Batch 187, Meta-loss: 0.8093289136886597\n",
            "Batch 188, Meta-loss: 0.8354198336601257\n",
            "Batch 189, Meta-loss: 0.7624338865280151\n",
            "Batch 190, Meta-loss: 0.9513602256774902\n",
            "Batch 191, Meta-loss: 1.0045077800750732\n",
            "Batch 192, Meta-loss: 0.8915623426437378\n",
            "Batch 193, Meta-loss: 1.059275507926941\n",
            "Batch 194, Meta-loss: 1.0213642120361328\n",
            "Batch 195, Meta-loss: 0.8731268644332886\n",
            "Batch 196, Meta-loss: 0.778815746307373\n",
            "Batch 197, Meta-loss: 0.9682219624519348\n",
            "Batch 198, Meta-loss: 0.9454991221427917\n",
            "Batch 199, Meta-loss: 0.9490936994552612\n",
            "Batch 200, Meta-loss: 0.8087722063064575\n",
            "Batch 201, Meta-loss: 0.9192672967910767\n",
            "Batch 202, Meta-loss: 1.3273874521255493\n",
            "Batch 203, Meta-loss: 1.0034301280975342\n",
            "Batch 204, Meta-loss: 0.9904259443283081\n",
            "Batch 205, Meta-loss: 1.1736464500427246\n",
            "Batch 206, Meta-loss: 1.0395112037658691\n",
            "Batch 207, Meta-loss: 1.0181362628936768\n",
            "Batch 208, Meta-loss: 0.9740716218948364\n",
            "Batch 209, Meta-loss: 0.9224913716316223\n",
            "Batch 210, Meta-loss: 0.9483326077461243\n",
            "Batch 211, Meta-loss: 0.9139903783798218\n",
            "Batch 212, Meta-loss: 0.9716230630874634\n",
            "Batch 213, Meta-loss: 0.9158235788345337\n",
            "Batch 214, Meta-loss: 0.798982560634613\n",
            "Batch 215, Meta-loss: 1.0133187770843506\n",
            "Batch 216, Meta-loss: 0.9179018139839172\n",
            "Batch 217, Meta-loss: 0.8316091299057007\n",
            "Batch 218, Meta-loss: 0.8235682249069214\n",
            "Batch 219, Meta-loss: 0.8563590049743652\n",
            "Batch 220, Meta-loss: 1.003864049911499\n",
            "Batch 221, Meta-loss: 0.912375807762146\n",
            "Batch 222, Meta-loss: 0.9146846532821655\n",
            "Batch 223, Meta-loss: 0.9708463549613953\n",
            "Batch 224, Meta-loss: 0.8003884553909302\n",
            "Batch 225, Meta-loss: 0.9678620100021362\n",
            "Batch 226, Meta-loss: 0.9555829763412476\n",
            "Batch 227, Meta-loss: 0.8066519498825073\n",
            "Batch 228, Meta-loss: 0.8944135904312134\n",
            "Batch 229, Meta-loss: 0.9083508253097534\n",
            "Batch 230, Meta-loss: 0.9302080869674683\n",
            "Batch 231, Meta-loss: 1.147156000137329\n",
            "Batch 232, Meta-loss: 1.0126616954803467\n",
            "Batch 233, Meta-loss: 0.9518947601318359\n",
            "Batch 234, Meta-loss: 0.9031718969345093\n",
            "Batch 235, Meta-loss: 0.9536358714103699\n",
            "Batch 236, Meta-loss: 0.9158159494400024\n",
            "Batch 237, Meta-loss: 0.8690339922904968\n",
            "Batch 238, Meta-loss: 0.9463838338851929\n",
            "Batch 239, Meta-loss: 0.7594628930091858\n",
            "Batch 240, Meta-loss: 0.9517248868942261\n",
            "Batch 241, Meta-loss: 0.9909919500350952\n",
            "Batch 242, Meta-loss: 1.0348122119903564\n",
            "Batch 243, Meta-loss: 0.9208183288574219\n",
            "Batch 244, Meta-loss: 1.0507985353469849\n",
            "Batch 245, Meta-loss: 0.9288714528083801\n",
            "Batch 246, Meta-loss: 0.9771196246147156\n",
            "Batch 247, Meta-loss: 0.8484700918197632\n",
            "Batch 248, Meta-loss: 0.8475486636161804\n",
            "Batch 249, Meta-loss: 0.9406167268753052\n",
            "Batch 250, Meta-loss: 0.8121261596679688\n",
            "Batch 251, Meta-loss: 1.0041215419769287\n",
            "Batch 252, Meta-loss: 0.9090142250061035\n",
            "Batch 253, Meta-loss: 1.0647788047790527\n",
            "Batch 254, Meta-loss: 1.0556458234786987\n",
            "Batch 255, Meta-loss: 0.8443084955215454\n",
            "Batch 256, Meta-loss: 0.8936762809753418\n",
            "Batch 257, Meta-loss: 0.8935946226119995\n",
            "Batch 258, Meta-loss: 0.8457080125808716\n",
            "Batch 259, Meta-loss: 1.1082271337509155\n",
            "Batch 260, Meta-loss: 0.8156426548957825\n",
            "Batch 261, Meta-loss: 0.9725015759468079\n",
            "Batch 262, Meta-loss: 0.8125367164611816\n",
            "Batch 263, Meta-loss: 0.868269145488739\n",
            "Batch 264, Meta-loss: 0.9124309420585632\n",
            "Batch 265, Meta-loss: 0.9383993148803711\n",
            "Batch 266, Meta-loss: 0.8863584399223328\n",
            "Batch 267, Meta-loss: 0.964819073677063\n",
            "Batch 268, Meta-loss: 0.8736317753791809\n",
            "Batch 269, Meta-loss: 0.9037350416183472\n",
            "Batch 270, Meta-loss: 0.8970836400985718\n",
            "Batch 271, Meta-loss: 0.9568821787834167\n",
            "Batch 272, Meta-loss: 0.9357630014419556\n",
            "Batch 273, Meta-loss: 0.8552570343017578\n",
            "Batch 274, Meta-loss: 0.901084303855896\n",
            "Batch 275, Meta-loss: 0.8543969988822937\n",
            "Batch 276, Meta-loss: 0.9014853239059448\n",
            "Batch 277, Meta-loss: 0.8680000305175781\n",
            "Batch 278, Meta-loss: 0.7865250706672668\n",
            "Batch 279, Meta-loss: 1.00755774974823\n",
            "Batch 280, Meta-loss: 0.8710406422615051\n",
            "Batch 281, Meta-loss: 1.0281598567962646\n",
            "Batch 282, Meta-loss: 0.8519879579544067\n",
            "Batch 283, Meta-loss: 0.9821041822433472\n",
            "Batch 284, Meta-loss: 0.9584159851074219\n",
            "Batch 285, Meta-loss: 0.9737358093261719\n",
            "Batch 286, Meta-loss: 0.8538314700126648\n",
            "Batch 287, Meta-loss: 0.8975545763969421\n",
            "Batch 288, Meta-loss: 0.8486092686653137\n",
            "Batch 289, Meta-loss: 0.8304145932197571\n",
            "Batch 290, Meta-loss: 1.1976161003112793\n",
            "Batch 291, Meta-loss: 0.9812970161437988\n",
            "Batch 292, Meta-loss: 0.9211412668228149\n",
            "Batch 293, Meta-loss: 0.8889438509941101\n",
            "Batch 294, Meta-loss: 1.1102246046066284\n",
            "Batch 295, Meta-loss: 0.9611839056015015\n",
            "Batch 296, Meta-loss: 0.8148534893989563\n",
            "Batch 297, Meta-loss: 1.030338168144226\n",
            "Batch 298, Meta-loss: 0.9916057586669922\n",
            "Batch 299, Meta-loss: 0.827039897441864\n",
            "Batch 300, Meta-loss: 0.9631021618843079\n",
            "Batch 301, Meta-loss: 0.7515155076980591\n",
            "Batch 302, Meta-loss: 1.0313122272491455\n",
            "Batch 303, Meta-loss: 0.77861487865448\n",
            "Batch 304, Meta-loss: 0.9337252378463745\n",
            "Batch 305, Meta-loss: 0.8929669260978699\n",
            "Batch 306, Meta-loss: 1.0180120468139648\n",
            "Batch 307, Meta-loss: 0.9287370443344116\n",
            "Batch 308, Meta-loss: 1.0753953456878662\n",
            "Batch 309, Meta-loss: 0.8750749826431274\n",
            "Batch 310, Meta-loss: 0.815463662147522\n",
            "Batch 311, Meta-loss: 0.9665151834487915\n",
            "Batch 312, Meta-loss: 0.8016394376754761\n",
            "Batch 313, Meta-loss: 0.8681367635726929\n",
            "Batch 314, Meta-loss: 0.7841435670852661\n",
            "Batch 315, Meta-loss: 0.8129474520683289\n",
            "Batch 316, Meta-loss: 1.0024547576904297\n",
            "Batch 317, Meta-loss: 1.0994517803192139\n",
            "Batch 318, Meta-loss: 1.028681993484497\n",
            "Batch 319, Meta-loss: 0.9773823022842407\n",
            "Batch 320, Meta-loss: 0.9402672052383423\n",
            "Batch 321, Meta-loss: 1.0159814357757568\n",
            "Batch 322, Meta-loss: 0.9288283586502075\n",
            "Batch 323, Meta-loss: 0.9434293508529663\n",
            "Batch 324, Meta-loss: 1.0207500457763672\n",
            "Batch 325, Meta-loss: 0.8938560485839844\n",
            "Batch 326, Meta-loss: 1.1712164878845215\n",
            "Batch 327, Meta-loss: 1.0287044048309326\n",
            "Batch 328, Meta-loss: 0.8795069456100464\n",
            "Batch 329, Meta-loss: 0.9985328912734985\n",
            "Batch 330, Meta-loss: 0.7832868695259094\n",
            "Batch 331, Meta-loss: 0.8118487596511841\n",
            "Batch 332, Meta-loss: 0.8614007234573364\n",
            "Batch 333, Meta-loss: 0.8611704111099243\n",
            "Batch 334, Meta-loss: 0.9903386235237122\n",
            "Batch 335, Meta-loss: 1.011810064315796\n",
            "Batch 336, Meta-loss: 0.97569739818573\n",
            "Batch 337, Meta-loss: 0.9867990612983704\n",
            "Batch 338, Meta-loss: 0.908124566078186\n",
            "Batch 339, Meta-loss: 1.0381335020065308\n",
            "Batch 340, Meta-loss: 0.8575231432914734\n",
            "Batch 341, Meta-loss: 1.2052843570709229\n",
            "Batch 342, Meta-loss: 0.8410380482673645\n",
            "Batch 343, Meta-loss: 0.8761776089668274\n",
            "Batch 344, Meta-loss: 0.9981072545051575\n",
            "Batch 345, Meta-loss: 0.9415799379348755\n",
            "Batch 346, Meta-loss: 0.9145158529281616\n",
            "Batch 347, Meta-loss: 0.9438786506652832\n",
            "Batch 348, Meta-loss: 0.9437532424926758\n",
            "Batch 349, Meta-loss: 0.9319941401481628\n",
            "Batch 350, Meta-loss: 0.9363228678703308\n",
            "Batch 351, Meta-loss: 1.0338866710662842\n",
            "Batch 352, Meta-loss: 1.023305892944336\n",
            "Batch 353, Meta-loss: 0.8422231674194336\n",
            "Batch 354, Meta-loss: 0.8987415432929993\n",
            "Batch 355, Meta-loss: 0.8847860097885132\n",
            "Batch 356, Meta-loss: 0.9445969462394714\n",
            "Batch 357, Meta-loss: 0.934644341468811\n",
            "Batch 358, Meta-loss: 0.9273481369018555\n",
            "Batch 359, Meta-loss: 0.9499258995056152\n",
            "Batch 360, Meta-loss: 0.8884652853012085\n",
            "Batch 361, Meta-loss: 1.054113507270813\n",
            "Batch 362, Meta-loss: 0.9674810171127319\n",
            "Batch 363, Meta-loss: 1.0292625427246094\n",
            "Batch 364, Meta-loss: 0.9709385633468628\n",
            "Batch 365, Meta-loss: 0.9202671051025391\n",
            "Batch 366, Meta-loss: 0.9633840322494507\n",
            "Batch 367, Meta-loss: 0.8490093946456909\n",
            "Batch 368, Meta-loss: 1.1681362390518188\n",
            "Batch 369, Meta-loss: 0.9824263453483582\n",
            "Batch 370, Meta-loss: 0.9006025195121765\n",
            "Batch 371, Meta-loss: 1.0907903909683228\n",
            "Batch 372, Meta-loss: 0.7913400530815125\n",
            "Batch 373, Meta-loss: 0.8671029806137085\n",
            "Batch 374, Meta-loss: 0.9099456667900085\n",
            "Batch 375, Meta-loss: 0.9902833104133606\n",
            "Epoch 9\n",
            "Batch 1, Meta-loss: 0.8379586338996887\n",
            "Batch 2, Meta-loss: 1.0028315782546997\n",
            "Batch 3, Meta-loss: 0.8096193075180054\n",
            "Batch 4, Meta-loss: 0.9418525695800781\n",
            "Batch 5, Meta-loss: 0.943780243396759\n",
            "Batch 6, Meta-loss: 0.8848820924758911\n",
            "Batch 7, Meta-loss: 0.9406458139419556\n",
            "Batch 8, Meta-loss: 0.9216644167900085\n",
            "Batch 9, Meta-loss: 0.9993864297866821\n",
            "Batch 10, Meta-loss: 0.9333339929580688\n",
            "Batch 11, Meta-loss: 0.911720871925354\n",
            "Batch 12, Meta-loss: 0.8468502759933472\n",
            "Batch 13, Meta-loss: 0.7542026042938232\n",
            "Batch 14, Meta-loss: 0.9012360572814941\n",
            "Batch 15, Meta-loss: 1.0966167449951172\n",
            "Batch 16, Meta-loss: 0.9889956712722778\n",
            "Batch 17, Meta-loss: 0.860417366027832\n",
            "Batch 18, Meta-loss: 0.7570148706436157\n",
            "Batch 19, Meta-loss: 0.8835768699645996\n",
            "Batch 20, Meta-loss: 0.8046499490737915\n",
            "Batch 21, Meta-loss: 1.0970025062561035\n",
            "Batch 22, Meta-loss: 1.0192539691925049\n",
            "Batch 23, Meta-loss: 0.9767423868179321\n",
            "Batch 24, Meta-loss: 1.0347989797592163\n",
            "Batch 25, Meta-loss: 0.961317241191864\n",
            "Batch 26, Meta-loss: 1.075265645980835\n",
            "Batch 27, Meta-loss: 0.957392692565918\n",
            "Batch 28, Meta-loss: 0.9121307134628296\n",
            "Batch 29, Meta-loss: 0.8198505640029907\n",
            "Batch 30, Meta-loss: 0.8946898579597473\n",
            "Batch 31, Meta-loss: 0.8058797121047974\n",
            "Batch 32, Meta-loss: 0.8209289312362671\n",
            "Batch 33, Meta-loss: 0.7679826021194458\n",
            "Batch 34, Meta-loss: 0.984142005443573\n",
            "Batch 35, Meta-loss: 0.8257762789726257\n",
            "Batch 36, Meta-loss: 1.0070868730545044\n",
            "Batch 37, Meta-loss: 1.0321885347366333\n",
            "Batch 38, Meta-loss: 0.8382512331008911\n",
            "Batch 39, Meta-loss: 0.9791589975357056\n",
            "Batch 40, Meta-loss: 0.8311605453491211\n",
            "Batch 41, Meta-loss: 1.003027081489563\n",
            "Batch 42, Meta-loss: 0.8298300504684448\n",
            "Batch 43, Meta-loss: 1.0165555477142334\n",
            "Batch 44, Meta-loss: 0.9096196889877319\n",
            "Batch 45, Meta-loss: 0.8317329287528992\n",
            "Batch 46, Meta-loss: 0.7909613847732544\n",
            "Batch 47, Meta-loss: 0.8572185635566711\n",
            "Batch 48, Meta-loss: 0.9537822008132935\n",
            "Batch 49, Meta-loss: 0.8010522127151489\n",
            "Batch 50, Meta-loss: 0.7251469492912292\n",
            "Batch 51, Meta-loss: 0.9857351183891296\n",
            "Batch 52, Meta-loss: 0.8991416692733765\n",
            "Batch 53, Meta-loss: 0.8981322050094604\n",
            "Batch 54, Meta-loss: 0.9898784756660461\n",
            "Batch 55, Meta-loss: 1.0076267719268799\n",
            "Batch 56, Meta-loss: 0.8514096140861511\n",
            "Batch 57, Meta-loss: 0.9602290391921997\n",
            "Batch 58, Meta-loss: 0.925158679485321\n",
            "Batch 59, Meta-loss: 0.9406720995903015\n",
            "Batch 60, Meta-loss: 0.8623325228691101\n",
            "Batch 61, Meta-loss: 0.9493662118911743\n",
            "Batch 62, Meta-loss: 0.9447401762008667\n",
            "Batch 63, Meta-loss: 1.0677340030670166\n",
            "Batch 64, Meta-loss: 0.9341030120849609\n",
            "Batch 65, Meta-loss: 0.9015596508979797\n",
            "Batch 66, Meta-loss: 0.9423243403434753\n",
            "Batch 67, Meta-loss: 0.8828511238098145\n",
            "Batch 68, Meta-loss: 0.8193060159683228\n",
            "Batch 69, Meta-loss: 1.0108869075775146\n",
            "Batch 70, Meta-loss: 0.9875398874282837\n",
            "Batch 71, Meta-loss: 0.9748198390007019\n",
            "Batch 72, Meta-loss: 1.0660265684127808\n",
            "Batch 73, Meta-loss: 0.8658294677734375\n",
            "Batch 74, Meta-loss: 0.7250314950942993\n",
            "Batch 75, Meta-loss: 0.9274157285690308\n",
            "Batch 76, Meta-loss: 0.8502248525619507\n",
            "Batch 77, Meta-loss: 0.9614742398262024\n",
            "Batch 78, Meta-loss: 1.0132802724838257\n",
            "Batch 79, Meta-loss: 0.907758891582489\n",
            "Batch 80, Meta-loss: 0.9691517949104309\n",
            "Batch 81, Meta-loss: 0.9246854782104492\n",
            "Batch 82, Meta-loss: 0.8529692888259888\n",
            "Batch 83, Meta-loss: 1.0290213823318481\n",
            "Batch 84, Meta-loss: 0.8754091262817383\n",
            "Batch 85, Meta-loss: 1.1220453977584839\n",
            "Batch 86, Meta-loss: 0.9186835289001465\n",
            "Batch 87, Meta-loss: 1.0210041999816895\n",
            "Batch 88, Meta-loss: 0.9439634084701538\n",
            "Batch 89, Meta-loss: 0.968963623046875\n",
            "Batch 90, Meta-loss: 0.7329136729240417\n",
            "Batch 91, Meta-loss: 1.075711727142334\n",
            "Batch 92, Meta-loss: 0.930729866027832\n",
            "Batch 93, Meta-loss: 1.0408134460449219\n",
            "Batch 94, Meta-loss: 1.1161839962005615\n",
            "Batch 95, Meta-loss: 1.0190092325210571\n",
            "Batch 96, Meta-loss: 0.879682719707489\n",
            "Batch 97, Meta-loss: 0.9504944086074829\n",
            "Batch 98, Meta-loss: 0.9966257810592651\n",
            "Batch 99, Meta-loss: 1.0502161979675293\n",
            "Batch 100, Meta-loss: 0.9144941568374634\n",
            "Batch 101, Meta-loss: 0.9652748107910156\n",
            "Batch 102, Meta-loss: 1.00704824924469\n",
            "Batch 103, Meta-loss: 1.0975193977355957\n",
            "Batch 104, Meta-loss: 0.9344822764396667\n",
            "Batch 105, Meta-loss: 0.9327130317687988\n",
            "Batch 106, Meta-loss: 1.019132375717163\n",
            "Batch 107, Meta-loss: 0.8814799189567566\n",
            "Batch 108, Meta-loss: 0.8162186741828918\n",
            "Batch 109, Meta-loss: 0.8864415884017944\n",
            "Batch 110, Meta-loss: 1.0935213565826416\n",
            "Batch 111, Meta-loss: 0.9948951601982117\n",
            "Batch 112, Meta-loss: 0.8290554881095886\n",
            "Batch 113, Meta-loss: 1.0446149110794067\n",
            "Batch 114, Meta-loss: 0.8202537298202515\n",
            "Batch 115, Meta-loss: 0.935370922088623\n",
            "Batch 116, Meta-loss: 0.8534194827079773\n",
            "Batch 117, Meta-loss: 0.9391862750053406\n",
            "Batch 118, Meta-loss: 0.895405113697052\n",
            "Batch 119, Meta-loss: 0.8759519457817078\n",
            "Batch 120, Meta-loss: 1.1621443033218384\n",
            "Batch 121, Meta-loss: 0.7971101999282837\n",
            "Batch 122, Meta-loss: 0.9000726938247681\n",
            "Batch 123, Meta-loss: 0.944537341594696\n",
            "Batch 124, Meta-loss: 0.9368698000907898\n",
            "Batch 125, Meta-loss: 1.1403319835662842\n",
            "Batch 126, Meta-loss: 0.8789137601852417\n",
            "Batch 127, Meta-loss: 1.1425890922546387\n",
            "Batch 128, Meta-loss: 0.9849012494087219\n",
            "Batch 129, Meta-loss: 0.8369513750076294\n",
            "Batch 130, Meta-loss: 1.1334435939788818\n",
            "Batch 131, Meta-loss: 1.0079220533370972\n",
            "Batch 132, Meta-loss: 0.87925785779953\n",
            "Batch 133, Meta-loss: 0.9302207231521606\n",
            "Batch 134, Meta-loss: 0.9515405893325806\n",
            "Batch 135, Meta-loss: 1.1241910457611084\n",
            "Batch 136, Meta-loss: 0.8859204053878784\n",
            "Batch 137, Meta-loss: 0.9700841903686523\n",
            "Batch 138, Meta-loss: 0.9196783304214478\n",
            "Batch 139, Meta-loss: 1.0115392208099365\n",
            "Batch 140, Meta-loss: 0.9293316006660461\n",
            "Batch 141, Meta-loss: 0.981438159942627\n",
            "Batch 142, Meta-loss: 0.8758757710456848\n",
            "Batch 143, Meta-loss: 1.1046597957611084\n",
            "Batch 144, Meta-loss: 0.9763444662094116\n",
            "Batch 145, Meta-loss: 0.9981158971786499\n",
            "Batch 146, Meta-loss: 0.9062040448188782\n",
            "Batch 147, Meta-loss: 0.936214804649353\n",
            "Batch 148, Meta-loss: 0.9044124484062195\n",
            "Batch 149, Meta-loss: 1.0569756031036377\n",
            "Batch 150, Meta-loss: 0.9073993563652039\n",
            "Batch 151, Meta-loss: 0.8574427366256714\n",
            "Batch 152, Meta-loss: 0.671150267124176\n",
            "Batch 153, Meta-loss: 1.0209368467330933\n",
            "Batch 154, Meta-loss: 1.1128031015396118\n",
            "Batch 155, Meta-loss: 1.047318696975708\n",
            "Batch 156, Meta-loss: 0.906835675239563\n",
            "Batch 157, Meta-loss: 0.953887939453125\n",
            "Batch 158, Meta-loss: 0.8715087175369263\n",
            "Batch 159, Meta-loss: 0.8253200650215149\n",
            "Batch 160, Meta-loss: 0.8873246312141418\n",
            "Batch 161, Meta-loss: 0.9671818017959595\n",
            "Batch 162, Meta-loss: 0.885393500328064\n",
            "Batch 163, Meta-loss: 0.9057329297065735\n",
            "Batch 164, Meta-loss: 1.2604756355285645\n",
            "Batch 165, Meta-loss: 0.902079701423645\n",
            "Batch 166, Meta-loss: 1.078315258026123\n",
            "Batch 167, Meta-loss: 1.065474271774292\n",
            "Batch 168, Meta-loss: 0.9416864514350891\n",
            "Batch 169, Meta-loss: 1.1087478399276733\n",
            "Batch 170, Meta-loss: 1.0229432582855225\n",
            "Batch 171, Meta-loss: 1.0827076435089111\n",
            "Batch 172, Meta-loss: 0.9545770883560181\n",
            "Batch 173, Meta-loss: 0.8057429194450378\n",
            "Batch 174, Meta-loss: 0.9787048101425171\n",
            "Batch 175, Meta-loss: 0.955927848815918\n",
            "Batch 176, Meta-loss: 0.8122972249984741\n",
            "Batch 177, Meta-loss: 0.9254524111747742\n",
            "Batch 178, Meta-loss: 1.2452877759933472\n",
            "Batch 179, Meta-loss: 0.9080642461776733\n",
            "Batch 180, Meta-loss: 1.0761127471923828\n",
            "Batch 181, Meta-loss: 0.9797095060348511\n",
            "Batch 182, Meta-loss: 0.8693631887435913\n",
            "Batch 183, Meta-loss: 0.8765036463737488\n",
            "Batch 184, Meta-loss: 0.9077841639518738\n",
            "Batch 185, Meta-loss: 0.7317483425140381\n",
            "Batch 186, Meta-loss: 1.0632959604263306\n",
            "Batch 187, Meta-loss: 0.7855623364448547\n",
            "Batch 188, Meta-loss: 0.8049706220626831\n",
            "Batch 189, Meta-loss: 0.9982224702835083\n",
            "Batch 190, Meta-loss: 1.1016428470611572\n",
            "Batch 191, Meta-loss: 1.1824123859405518\n",
            "Batch 192, Meta-loss: 1.0998681783676147\n",
            "Batch 193, Meta-loss: 0.8796772956848145\n",
            "Batch 194, Meta-loss: 0.8934210538864136\n",
            "Batch 195, Meta-loss: 0.8721685409545898\n",
            "Batch 196, Meta-loss: 1.0925118923187256\n",
            "Batch 197, Meta-loss: 0.9708162546157837\n",
            "Batch 198, Meta-loss: 1.1977429389953613\n",
            "Batch 199, Meta-loss: 0.9945634603500366\n",
            "Batch 200, Meta-loss: 0.9832690954208374\n",
            "Batch 201, Meta-loss: 0.9090709686279297\n",
            "Batch 202, Meta-loss: 0.8623273968696594\n",
            "Batch 203, Meta-loss: 0.8980921506881714\n",
            "Batch 204, Meta-loss: 1.0561354160308838\n",
            "Batch 205, Meta-loss: 0.9093987345695496\n",
            "Batch 206, Meta-loss: 1.0497162342071533\n",
            "Batch 207, Meta-loss: 0.9301853179931641\n",
            "Batch 208, Meta-loss: 0.8738061785697937\n",
            "Batch 209, Meta-loss: 1.04914391040802\n",
            "Batch 210, Meta-loss: 0.9061158895492554\n",
            "Batch 211, Meta-loss: 0.950670063495636\n",
            "Batch 212, Meta-loss: 0.8660615682601929\n",
            "Batch 213, Meta-loss: 0.8651054501533508\n",
            "Batch 214, Meta-loss: 0.9790244102478027\n",
            "Batch 215, Meta-loss: 0.986375629901886\n",
            "Batch 216, Meta-loss: 1.0264956951141357\n",
            "Batch 217, Meta-loss: 0.8562242388725281\n",
            "Batch 218, Meta-loss: 0.9528304934501648\n",
            "Batch 219, Meta-loss: 0.9107427597045898\n",
            "Batch 220, Meta-loss: 0.8499353528022766\n",
            "Batch 221, Meta-loss: 0.8002331852912903\n",
            "Batch 222, Meta-loss: 0.979641318321228\n",
            "Batch 223, Meta-loss: 1.1731457710266113\n",
            "Batch 224, Meta-loss: 1.1845338344573975\n",
            "Batch 225, Meta-loss: 0.9375540614128113\n",
            "Batch 226, Meta-loss: 0.7533637285232544\n",
            "Batch 227, Meta-loss: 0.7756752371788025\n",
            "Batch 228, Meta-loss: 1.0324287414550781\n",
            "Batch 229, Meta-loss: 1.2778775691986084\n",
            "Batch 230, Meta-loss: 1.0715320110321045\n",
            "Batch 231, Meta-loss: 0.9291681051254272\n",
            "Batch 232, Meta-loss: 1.0632336139678955\n",
            "Batch 233, Meta-loss: 0.9275364875793457\n",
            "Batch 234, Meta-loss: 0.8398391008377075\n",
            "Batch 235, Meta-loss: 0.9508908987045288\n",
            "Batch 236, Meta-loss: 0.9925531148910522\n",
            "Batch 237, Meta-loss: 0.9068095088005066\n",
            "Batch 238, Meta-loss: 0.9575146436691284\n",
            "Batch 239, Meta-loss: 0.9926332235336304\n",
            "Batch 240, Meta-loss: 0.9788784980773926\n",
            "Batch 241, Meta-loss: 0.8255541920661926\n",
            "Batch 242, Meta-loss: 1.044891119003296\n",
            "Batch 243, Meta-loss: 0.8842207789421082\n",
            "Batch 244, Meta-loss: 1.075696587562561\n",
            "Batch 245, Meta-loss: 0.9266799688339233\n",
            "Batch 246, Meta-loss: 0.903754711151123\n",
            "Batch 247, Meta-loss: 1.0178062915802002\n",
            "Batch 248, Meta-loss: 0.9230014085769653\n",
            "Batch 249, Meta-loss: 1.0279161930084229\n",
            "Batch 250, Meta-loss: 0.9718776941299438\n",
            "Batch 251, Meta-loss: 1.0561890602111816\n",
            "Batch 252, Meta-loss: 0.9430229067802429\n",
            "Batch 253, Meta-loss: 0.9864710569381714\n",
            "Batch 254, Meta-loss: 1.0232309103012085\n",
            "Batch 255, Meta-loss: 1.0205084085464478\n",
            "Batch 256, Meta-loss: 1.042578101158142\n",
            "Batch 257, Meta-loss: 1.2562923431396484\n",
            "Batch 258, Meta-loss: 0.8593946695327759\n",
            "Batch 259, Meta-loss: 0.9808686971664429\n",
            "Batch 260, Meta-loss: 0.9127496480941772\n",
            "Batch 261, Meta-loss: 0.8625407218933105\n",
            "Batch 262, Meta-loss: 0.8869756460189819\n",
            "Batch 263, Meta-loss: 1.0341659784317017\n",
            "Batch 264, Meta-loss: 0.9986276626586914\n",
            "Batch 265, Meta-loss: 0.9105156064033508\n",
            "Batch 266, Meta-loss: 0.9732319116592407\n",
            "Batch 267, Meta-loss: 0.9395890235900879\n",
            "Batch 268, Meta-loss: 0.8793578147888184\n",
            "Batch 269, Meta-loss: 1.0199717283248901\n",
            "Batch 270, Meta-loss: 0.8418804407119751\n",
            "Batch 271, Meta-loss: 0.9650235176086426\n",
            "Batch 272, Meta-loss: 0.9107518196105957\n",
            "Batch 273, Meta-loss: 0.8858292698860168\n",
            "Batch 274, Meta-loss: 0.959476113319397\n",
            "Batch 275, Meta-loss: 0.8770966529846191\n",
            "Batch 276, Meta-loss: 0.9147993922233582\n",
            "Batch 277, Meta-loss: 1.008996844291687\n",
            "Batch 278, Meta-loss: 1.0660078525543213\n",
            "Batch 279, Meta-loss: 1.2420289516448975\n",
            "Batch 280, Meta-loss: 1.0454145669937134\n",
            "Batch 281, Meta-loss: 0.8469443321228027\n",
            "Batch 282, Meta-loss: 0.9521395564079285\n",
            "Batch 283, Meta-loss: 0.9994856119155884\n",
            "Batch 284, Meta-loss: 1.092005968093872\n",
            "Batch 285, Meta-loss: 1.0427117347717285\n",
            "Batch 286, Meta-loss: 0.9938628077507019\n",
            "Batch 287, Meta-loss: 0.8915454149246216\n",
            "Batch 288, Meta-loss: 0.8698843121528625\n",
            "Batch 289, Meta-loss: 1.1204664707183838\n",
            "Batch 290, Meta-loss: 0.9437410235404968\n",
            "Batch 291, Meta-loss: 0.9501950144767761\n",
            "Batch 292, Meta-loss: 0.8340879678726196\n",
            "Batch 293, Meta-loss: 0.9954853057861328\n",
            "Batch 294, Meta-loss: 1.0262588262557983\n",
            "Batch 295, Meta-loss: 1.126373529434204\n",
            "Batch 296, Meta-loss: 0.9288554191589355\n",
            "Batch 297, Meta-loss: 0.8725790977478027\n",
            "Batch 298, Meta-loss: 0.8740228414535522\n",
            "Batch 299, Meta-loss: 0.8761740922927856\n",
            "Batch 300, Meta-loss: 0.9722256660461426\n",
            "Batch 301, Meta-loss: 0.9786664247512817\n",
            "Batch 302, Meta-loss: 0.921707272529602\n",
            "Batch 303, Meta-loss: 0.802806556224823\n",
            "Batch 304, Meta-loss: 0.9653068780899048\n",
            "Batch 305, Meta-loss: 1.008927822113037\n",
            "Batch 306, Meta-loss: 0.9918659329414368\n",
            "Batch 307, Meta-loss: 0.9547834396362305\n",
            "Batch 308, Meta-loss: 1.0977528095245361\n",
            "Batch 309, Meta-loss: 0.9801853895187378\n",
            "Batch 310, Meta-loss: 0.9175004959106445\n",
            "Batch 311, Meta-loss: 0.9034876823425293\n",
            "Batch 312, Meta-loss: 0.917675793170929\n",
            "Batch 313, Meta-loss: 1.0254987478256226\n",
            "Batch 314, Meta-loss: 0.9538957476615906\n",
            "Batch 315, Meta-loss: 1.0419831275939941\n",
            "Batch 316, Meta-loss: 1.2283860445022583\n",
            "Batch 317, Meta-loss: 0.9440696835517883\n",
            "Batch 318, Meta-loss: 1.2516334056854248\n",
            "Batch 319, Meta-loss: 0.9509425163269043\n",
            "Batch 320, Meta-loss: 1.0895798206329346\n",
            "Batch 321, Meta-loss: 1.1342490911483765\n",
            "Batch 322, Meta-loss: 1.012662649154663\n",
            "Batch 323, Meta-loss: 1.0884861946105957\n",
            "Batch 324, Meta-loss: 1.0492801666259766\n",
            "Batch 325, Meta-loss: 0.9843379259109497\n",
            "Batch 326, Meta-loss: 1.0107142925262451\n",
            "Batch 327, Meta-loss: 1.002557396888733\n",
            "Batch 328, Meta-loss: 1.0907690525054932\n",
            "Batch 329, Meta-loss: 0.9755339622497559\n",
            "Batch 330, Meta-loss: 0.9550334811210632\n",
            "Batch 331, Meta-loss: 1.1113427877426147\n",
            "Batch 332, Meta-loss: 1.0224721431732178\n",
            "Batch 333, Meta-loss: 0.9488237500190735\n",
            "Batch 334, Meta-loss: 0.9055226445198059\n",
            "Batch 335, Meta-loss: 1.1198499202728271\n",
            "Batch 336, Meta-loss: 0.9782134890556335\n",
            "Batch 337, Meta-loss: 1.1758801937103271\n",
            "Batch 338, Meta-loss: 0.9420580863952637\n",
            "Batch 339, Meta-loss: 0.9178153276443481\n",
            "Batch 340, Meta-loss: 0.8673739433288574\n",
            "Batch 341, Meta-loss: 1.0147840976715088\n",
            "Batch 342, Meta-loss: 1.0622047185897827\n",
            "Batch 343, Meta-loss: 1.1883299350738525\n",
            "Batch 344, Meta-loss: 1.0387275218963623\n",
            "Batch 345, Meta-loss: 0.867290198802948\n",
            "Batch 346, Meta-loss: 0.7832760810852051\n",
            "Batch 347, Meta-loss: 1.003626823425293\n",
            "Batch 348, Meta-loss: 0.9277547597885132\n",
            "Batch 349, Meta-loss: 0.9664667248725891\n",
            "Batch 350, Meta-loss: 1.0579068660736084\n",
            "Batch 351, Meta-loss: 1.2661586999893188\n",
            "Batch 352, Meta-loss: 1.039671540260315\n",
            "Batch 353, Meta-loss: 0.8804725408554077\n",
            "Batch 354, Meta-loss: 1.0975744724273682\n",
            "Batch 355, Meta-loss: 1.052050232887268\n",
            "Batch 356, Meta-loss: 1.0262296199798584\n",
            "Batch 357, Meta-loss: 1.0206820964813232\n",
            "Batch 358, Meta-loss: 0.9756828546524048\n",
            "Batch 359, Meta-loss: 0.9689266085624695\n",
            "Batch 360, Meta-loss: 0.796101450920105\n",
            "Batch 361, Meta-loss: 0.9641292691230774\n",
            "Batch 362, Meta-loss: 0.9266489148139954\n",
            "Batch 363, Meta-loss: 0.9025119543075562\n",
            "Batch 364, Meta-loss: 1.064613938331604\n",
            "Batch 365, Meta-loss: 0.8638033866882324\n",
            "Batch 366, Meta-loss: 0.9702657461166382\n",
            "Batch 367, Meta-loss: 1.0042121410369873\n",
            "Batch 368, Meta-loss: 0.9453662037849426\n",
            "Batch 369, Meta-loss: 0.8786576986312866\n",
            "Batch 370, Meta-loss: 1.1148097515106201\n",
            "Batch 371, Meta-loss: 0.9771977663040161\n",
            "Batch 372, Meta-loss: 0.9122808575630188\n",
            "Batch 373, Meta-loss: 0.9495137929916382\n",
            "Batch 374, Meta-loss: 1.0190807580947876\n",
            "Batch 375, Meta-loss: 0.8867400288581848\n",
            "Epoch 10\n",
            "Batch 1, Meta-loss: 1.0084073543548584\n",
            "Batch 2, Meta-loss: 0.9175609350204468\n",
            "Batch 3, Meta-loss: 0.8927208185195923\n",
            "Batch 4, Meta-loss: 0.9019144773483276\n",
            "Batch 5, Meta-loss: 1.0042612552642822\n",
            "Batch 6, Meta-loss: 0.9381917119026184\n",
            "Batch 7, Meta-loss: 0.9457570910453796\n",
            "Batch 8, Meta-loss: 1.085354208946228\n",
            "Batch 9, Meta-loss: 0.9814133644104004\n",
            "Batch 10, Meta-loss: 0.9550920724868774\n",
            "Batch 11, Meta-loss: 0.9376193881034851\n",
            "Batch 12, Meta-loss: 0.9112628698348999\n",
            "Batch 13, Meta-loss: 0.9146418571472168\n",
            "Batch 14, Meta-loss: 1.0297653675079346\n",
            "Batch 15, Meta-loss: 0.9749852418899536\n",
            "Batch 16, Meta-loss: 0.8459773063659668\n",
            "Batch 17, Meta-loss: 1.0278817415237427\n",
            "Batch 18, Meta-loss: 0.9670071601867676\n",
            "Batch 19, Meta-loss: 0.8679926991462708\n",
            "Batch 20, Meta-loss: 0.976535439491272\n",
            "Batch 21, Meta-loss: 0.7989616394042969\n",
            "Batch 22, Meta-loss: 0.8985013961791992\n",
            "Batch 23, Meta-loss: 0.8979805111885071\n",
            "Batch 24, Meta-loss: 0.9429122805595398\n",
            "Batch 25, Meta-loss: 0.9738239049911499\n",
            "Batch 26, Meta-loss: 0.9358530044555664\n",
            "Batch 27, Meta-loss: 0.8310127258300781\n",
            "Batch 28, Meta-loss: 0.9125951528549194\n",
            "Batch 29, Meta-loss: 0.8502447009086609\n",
            "Batch 30, Meta-loss: 1.071928858757019\n",
            "Batch 31, Meta-loss: 0.942543625831604\n",
            "Batch 32, Meta-loss: 0.9147489666938782\n",
            "Batch 33, Meta-loss: 0.8743149042129517\n",
            "Batch 34, Meta-loss: 0.935481071472168\n",
            "Batch 35, Meta-loss: 1.011718988418579\n",
            "Batch 36, Meta-loss: 0.8213005065917969\n",
            "Batch 37, Meta-loss: 0.8759971857070923\n",
            "Batch 38, Meta-loss: 1.1344757080078125\n",
            "Batch 39, Meta-loss: 1.012833833694458\n",
            "Batch 40, Meta-loss: 0.8764786720275879\n",
            "Batch 41, Meta-loss: 0.9041452407836914\n",
            "Batch 42, Meta-loss: 1.054530143737793\n",
            "Batch 43, Meta-loss: 0.8973493576049805\n",
            "Batch 44, Meta-loss: 0.7837976217269897\n",
            "Batch 45, Meta-loss: 0.9575961828231812\n",
            "Batch 46, Meta-loss: 0.792881965637207\n",
            "Batch 47, Meta-loss: 1.0339146852493286\n",
            "Batch 48, Meta-loss: 1.1016148328781128\n",
            "Batch 49, Meta-loss: 0.8951854705810547\n",
            "Batch 50, Meta-loss: 0.9212762713432312\n",
            "Batch 51, Meta-loss: 1.0679218769073486\n",
            "Batch 52, Meta-loss: 0.8129445910453796\n",
            "Batch 53, Meta-loss: 0.9695199728012085\n",
            "Batch 54, Meta-loss: 0.9312114715576172\n",
            "Batch 55, Meta-loss: 1.074367880821228\n",
            "Batch 56, Meta-loss: 0.8893082737922668\n",
            "Batch 57, Meta-loss: 1.0123555660247803\n",
            "Batch 58, Meta-loss: 0.9068541526794434\n",
            "Batch 59, Meta-loss: 0.9358336329460144\n",
            "Batch 60, Meta-loss: 1.0310524702072144\n",
            "Batch 61, Meta-loss: 0.8175829648971558\n",
            "Batch 62, Meta-loss: 0.8484405279159546\n",
            "Batch 63, Meta-loss: 0.8988094329833984\n",
            "Batch 64, Meta-loss: 0.8555831909179688\n",
            "Batch 65, Meta-loss: 0.9640711545944214\n",
            "Batch 66, Meta-loss: 1.0202820301055908\n",
            "Batch 67, Meta-loss: 0.9813107252120972\n",
            "Batch 68, Meta-loss: 0.790855884552002\n",
            "Batch 69, Meta-loss: 0.9451755285263062\n",
            "Batch 70, Meta-loss: 1.0338772535324097\n",
            "Batch 71, Meta-loss: 1.0219557285308838\n",
            "Batch 72, Meta-loss: 0.8797882199287415\n",
            "Batch 73, Meta-loss: 0.881714940071106\n",
            "Batch 74, Meta-loss: 0.9396492838859558\n",
            "Batch 75, Meta-loss: 0.8833387494087219\n",
            "Batch 76, Meta-loss: 0.7672334909439087\n",
            "Batch 77, Meta-loss: 0.8449233174324036\n",
            "Batch 78, Meta-loss: 0.9486478567123413\n",
            "Batch 79, Meta-loss: 0.8507087826728821\n",
            "Batch 80, Meta-loss: 1.0397000312805176\n",
            "Batch 81, Meta-loss: 0.9197674989700317\n",
            "Batch 82, Meta-loss: 0.9912969470024109\n",
            "Batch 83, Meta-loss: 0.9122534990310669\n",
            "Batch 84, Meta-loss: 0.7861602902412415\n",
            "Batch 85, Meta-loss: 0.9460532069206238\n",
            "Batch 86, Meta-loss: 0.8343662023544312\n",
            "Batch 87, Meta-loss: 0.8724712133407593\n",
            "Batch 88, Meta-loss: 0.8893647193908691\n",
            "Batch 89, Meta-loss: 0.8796607255935669\n",
            "Batch 90, Meta-loss: 0.9077982902526855\n",
            "Batch 91, Meta-loss: 0.9091526865959167\n",
            "Batch 92, Meta-loss: 1.0433690547943115\n",
            "Batch 93, Meta-loss: 0.8687499761581421\n",
            "Batch 94, Meta-loss: 0.8973037004470825\n",
            "Batch 95, Meta-loss: 0.9724198579788208\n",
            "Batch 96, Meta-loss: 0.7780261635780334\n",
            "Batch 97, Meta-loss: 0.956402599811554\n",
            "Batch 98, Meta-loss: 0.9358326196670532\n",
            "Batch 99, Meta-loss: 0.9045554995536804\n",
            "Batch 100, Meta-loss: 0.8702074289321899\n",
            "Batch 101, Meta-loss: 1.0399123430252075\n",
            "Batch 102, Meta-loss: 0.9366176724433899\n",
            "Batch 103, Meta-loss: 0.8524864912033081\n",
            "Batch 104, Meta-loss: 0.931593120098114\n",
            "Batch 105, Meta-loss: 1.071408987045288\n",
            "Batch 106, Meta-loss: 0.8381745219230652\n",
            "Batch 107, Meta-loss: 0.9945237040519714\n",
            "Batch 108, Meta-loss: 0.8130704760551453\n",
            "Batch 109, Meta-loss: 1.0855233669281006\n",
            "Batch 110, Meta-loss: 0.8987902402877808\n",
            "Batch 111, Meta-loss: 0.7707170248031616\n",
            "Batch 112, Meta-loss: 1.0621347427368164\n",
            "Batch 113, Meta-loss: 0.8937010765075684\n",
            "Batch 114, Meta-loss: 0.7431365251541138\n",
            "Batch 115, Meta-loss: 0.8473167419433594\n",
            "Batch 116, Meta-loss: 0.9167360067367554\n",
            "Batch 117, Meta-loss: 0.9084432721138\n",
            "Batch 118, Meta-loss: 0.8675355911254883\n",
            "Batch 119, Meta-loss: 0.8402628898620605\n",
            "Batch 120, Meta-loss: 1.0670907497406006\n",
            "Batch 121, Meta-loss: 1.220804214477539\n",
            "Batch 122, Meta-loss: 0.9281216859817505\n",
            "Batch 123, Meta-loss: 0.8957139849662781\n",
            "Batch 124, Meta-loss: 0.9146687388420105\n",
            "Batch 125, Meta-loss: 0.911797046661377\n",
            "Batch 126, Meta-loss: 0.7839995622634888\n",
            "Batch 127, Meta-loss: 0.8456395268440247\n",
            "Batch 128, Meta-loss: 0.9941915273666382\n",
            "Batch 129, Meta-loss: 0.7810842394828796\n",
            "Batch 130, Meta-loss: 0.9908428192138672\n",
            "Batch 131, Meta-loss: 0.9269120097160339\n",
            "Batch 132, Meta-loss: 0.8591488003730774\n",
            "Batch 133, Meta-loss: 0.9703605771064758\n",
            "Batch 134, Meta-loss: 0.9088726043701172\n",
            "Batch 135, Meta-loss: 0.793209433555603\n",
            "Batch 136, Meta-loss: 0.9173041582107544\n",
            "Batch 137, Meta-loss: 0.8665242195129395\n",
            "Batch 138, Meta-loss: 0.9647351503372192\n",
            "Batch 139, Meta-loss: 0.9994794130325317\n",
            "Batch 140, Meta-loss: 0.8823083639144897\n",
            "Batch 141, Meta-loss: 0.9371293783187866\n",
            "Batch 142, Meta-loss: 0.9552836418151855\n",
            "Batch 143, Meta-loss: 1.0219154357910156\n",
            "Batch 144, Meta-loss: 0.8639724850654602\n",
            "Batch 145, Meta-loss: 1.02530038356781\n",
            "Batch 146, Meta-loss: 0.8938922882080078\n",
            "Batch 147, Meta-loss: 0.9739484786987305\n",
            "Batch 148, Meta-loss: 0.9833105802536011\n",
            "Batch 149, Meta-loss: 0.878888726234436\n",
            "Batch 150, Meta-loss: 1.008017659187317\n",
            "Batch 151, Meta-loss: 0.8664857149124146\n",
            "Batch 152, Meta-loss: 1.0350291728973389\n",
            "Batch 153, Meta-loss: 0.8458347320556641\n",
            "Batch 154, Meta-loss: 1.0736995935440063\n",
            "Batch 155, Meta-loss: 1.161388874053955\n",
            "Batch 156, Meta-loss: 0.9132463335990906\n",
            "Batch 157, Meta-loss: 1.0012853145599365\n",
            "Batch 158, Meta-loss: 0.9119617342948914\n",
            "Batch 159, Meta-loss: 1.0876296758651733\n",
            "Batch 160, Meta-loss: 0.9516458511352539\n",
            "Batch 161, Meta-loss: 0.9610546231269836\n",
            "Batch 162, Meta-loss: 0.9145466685295105\n",
            "Batch 163, Meta-loss: 0.9783117175102234\n",
            "Batch 164, Meta-loss: 0.9609845876693726\n",
            "Batch 165, Meta-loss: 0.8301776647567749\n",
            "Batch 166, Meta-loss: 0.9825217127799988\n",
            "Batch 167, Meta-loss: 1.0356248617172241\n",
            "Batch 168, Meta-loss: 1.028825044631958\n",
            "Batch 169, Meta-loss: 0.826298713684082\n",
            "Batch 170, Meta-loss: 1.116305947303772\n",
            "Batch 171, Meta-loss: 1.0348694324493408\n",
            "Batch 172, Meta-loss: 1.0854873657226562\n",
            "Batch 173, Meta-loss: 0.8253620266914368\n",
            "Batch 174, Meta-loss: 0.879054069519043\n",
            "Batch 175, Meta-loss: 1.0423749685287476\n",
            "Batch 176, Meta-loss: 1.135257363319397\n",
            "Batch 177, Meta-loss: 0.9444534182548523\n",
            "Batch 178, Meta-loss: 0.8908551335334778\n",
            "Batch 179, Meta-loss: 1.2191144227981567\n",
            "Batch 180, Meta-loss: 0.8614161610603333\n",
            "Batch 181, Meta-loss: 0.9249889254570007\n",
            "Batch 182, Meta-loss: 0.9196909070014954\n",
            "Batch 183, Meta-loss: 0.872256875038147\n",
            "Batch 184, Meta-loss: 0.9523955583572388\n",
            "Batch 185, Meta-loss: 0.9579311609268188\n",
            "Batch 186, Meta-loss: 1.0060101747512817\n",
            "Batch 187, Meta-loss: 1.0035454034805298\n",
            "Batch 188, Meta-loss: 1.0177042484283447\n",
            "Batch 189, Meta-loss: 0.8725723028182983\n",
            "Batch 190, Meta-loss: 1.0360301733016968\n",
            "Batch 191, Meta-loss: 0.9965776205062866\n",
            "Batch 192, Meta-loss: 0.8316763043403625\n",
            "Batch 193, Meta-loss: 1.0441093444824219\n",
            "Batch 194, Meta-loss: 1.009700059890747\n",
            "Batch 195, Meta-loss: 0.9058800935745239\n",
            "Batch 196, Meta-loss: 1.0622494220733643\n",
            "Batch 197, Meta-loss: 0.9583795666694641\n",
            "Batch 198, Meta-loss: 0.877058207988739\n",
            "Batch 199, Meta-loss: 0.9165424108505249\n",
            "Batch 200, Meta-loss: 1.006927251815796\n",
            "Batch 201, Meta-loss: 1.0927820205688477\n",
            "Batch 202, Meta-loss: 0.9774673581123352\n",
            "Batch 203, Meta-loss: 0.9313614964485168\n",
            "Batch 204, Meta-loss: 0.8914148211479187\n",
            "Batch 205, Meta-loss: 0.8885003924369812\n",
            "Batch 206, Meta-loss: 0.9788237810134888\n",
            "Batch 207, Meta-loss: 0.9889379739761353\n",
            "Batch 208, Meta-loss: 0.9016237258911133\n",
            "Batch 209, Meta-loss: 0.9677349925041199\n",
            "Batch 210, Meta-loss: 1.0004832744598389\n",
            "Batch 211, Meta-loss: 1.112554669380188\n",
            "Batch 212, Meta-loss: 0.877801239490509\n",
            "Batch 213, Meta-loss: 1.0222232341766357\n",
            "Batch 214, Meta-loss: 0.9344202280044556\n",
            "Batch 215, Meta-loss: 0.8987018465995789\n",
            "Batch 216, Meta-loss: 0.9078162908554077\n",
            "Batch 217, Meta-loss: 0.8005754351615906\n",
            "Batch 218, Meta-loss: 0.984998345375061\n",
            "Batch 219, Meta-loss: 0.8195797204971313\n",
            "Batch 220, Meta-loss: 0.9954190254211426\n",
            "Batch 221, Meta-loss: 1.111840844154358\n",
            "Batch 222, Meta-loss: 1.0591208934783936\n",
            "Batch 223, Meta-loss: 0.978816032409668\n",
            "Batch 224, Meta-loss: 0.9364902377128601\n",
            "Batch 225, Meta-loss: 0.8128849864006042\n",
            "Batch 226, Meta-loss: 0.9031851887702942\n",
            "Batch 227, Meta-loss: 0.9776484370231628\n",
            "Batch 228, Meta-loss: 0.9938933253288269\n",
            "Batch 229, Meta-loss: 0.9718685150146484\n",
            "Batch 230, Meta-loss: 0.9339755773544312\n",
            "Batch 231, Meta-loss: 0.9876829981803894\n",
            "Batch 232, Meta-loss: 0.8064082860946655\n",
            "Batch 233, Meta-loss: 1.1002271175384521\n",
            "Batch 234, Meta-loss: 0.8823696374893188\n",
            "Batch 235, Meta-loss: 0.7941233515739441\n",
            "Batch 236, Meta-loss: 1.0512739419937134\n",
            "Batch 237, Meta-loss: 0.9291738271713257\n",
            "Batch 238, Meta-loss: 1.0970197916030884\n",
            "Batch 239, Meta-loss: 0.9650614857673645\n",
            "Batch 240, Meta-loss: 0.9895844459533691\n",
            "Batch 241, Meta-loss: 0.9130527377128601\n",
            "Batch 242, Meta-loss: 1.0654884576797485\n",
            "Batch 243, Meta-loss: 0.9771102070808411\n",
            "Batch 244, Meta-loss: 1.0628783702850342\n",
            "Batch 245, Meta-loss: 0.76814204454422\n",
            "Batch 246, Meta-loss: 1.0235915184020996\n",
            "Batch 247, Meta-loss: 1.091992735862732\n",
            "Batch 248, Meta-loss: 1.0420944690704346\n",
            "Batch 249, Meta-loss: 1.0237934589385986\n",
            "Batch 250, Meta-loss: 1.0838148593902588\n",
            "Batch 251, Meta-loss: 1.0047680139541626\n",
            "Batch 252, Meta-loss: 0.9445940852165222\n",
            "Batch 253, Meta-loss: 0.9760093688964844\n",
            "Batch 254, Meta-loss: 0.8626753091812134\n",
            "Batch 255, Meta-loss: 1.1784754991531372\n",
            "Batch 256, Meta-loss: 0.8642354011535645\n",
            "Batch 257, Meta-loss: 0.9408709406852722\n",
            "Batch 258, Meta-loss: 1.2415162324905396\n",
            "Batch 259, Meta-loss: 0.9186362028121948\n",
            "Batch 260, Meta-loss: 1.0790431499481201\n",
            "Batch 261, Meta-loss: 0.8369169235229492\n",
            "Batch 262, Meta-loss: 0.9404572248458862\n",
            "Batch 263, Meta-loss: 1.0173299312591553\n",
            "Batch 264, Meta-loss: 1.0146348476409912\n",
            "Batch 265, Meta-loss: 0.9016583561897278\n",
            "Batch 266, Meta-loss: 1.0209903717041016\n",
            "Batch 267, Meta-loss: 0.9653242230415344\n",
            "Batch 268, Meta-loss: 0.9010828137397766\n",
            "Batch 269, Meta-loss: 0.8750983476638794\n",
            "Batch 270, Meta-loss: 0.979948878288269\n",
            "Batch 271, Meta-loss: 0.9898898005485535\n",
            "Batch 272, Meta-loss: 1.0288984775543213\n",
            "Batch 273, Meta-loss: 1.0536079406738281\n",
            "Batch 274, Meta-loss: 1.1222174167633057\n",
            "Batch 275, Meta-loss: 1.1440675258636475\n",
            "Batch 276, Meta-loss: 0.8344009518623352\n",
            "Batch 277, Meta-loss: 1.017450213432312\n",
            "Batch 278, Meta-loss: 0.8868883848190308\n",
            "Batch 279, Meta-loss: 0.9517477750778198\n",
            "Batch 280, Meta-loss: 0.9374216794967651\n",
            "Batch 281, Meta-loss: 0.922002911567688\n",
            "Batch 282, Meta-loss: 1.0043779611587524\n",
            "Batch 283, Meta-loss: 1.2511494159698486\n",
            "Batch 284, Meta-loss: 1.0666463375091553\n",
            "Batch 285, Meta-loss: 1.032372236251831\n",
            "Batch 286, Meta-loss: 1.0050524473190308\n",
            "Batch 287, Meta-loss: 1.068252682685852\n",
            "Batch 288, Meta-loss: 1.042555809020996\n",
            "Batch 289, Meta-loss: 0.9142720103263855\n",
            "Batch 290, Meta-loss: 0.9992048144340515\n",
            "Batch 291, Meta-loss: 1.1063905954360962\n",
            "Batch 292, Meta-loss: 0.9637376070022583\n",
            "Batch 293, Meta-loss: 0.9698169827461243\n",
            "Batch 294, Meta-loss: 0.9404991269111633\n",
            "Batch 295, Meta-loss: 0.9466437101364136\n",
            "Batch 296, Meta-loss: 1.0615158081054688\n",
            "Batch 297, Meta-loss: 1.0729904174804688\n",
            "Batch 298, Meta-loss: 1.0245351791381836\n",
            "Batch 299, Meta-loss: 0.892143726348877\n",
            "Batch 300, Meta-loss: 1.0257028341293335\n",
            "Batch 301, Meta-loss: 0.989538311958313\n",
            "Batch 302, Meta-loss: 0.9969340562820435\n",
            "Batch 303, Meta-loss: 1.086982011795044\n",
            "Batch 304, Meta-loss: 1.0843502283096313\n",
            "Batch 305, Meta-loss: 0.834762454032898\n",
            "Batch 306, Meta-loss: 0.7570290565490723\n",
            "Batch 307, Meta-loss: 1.1105196475982666\n",
            "Batch 308, Meta-loss: 0.9913930892944336\n",
            "Batch 309, Meta-loss: 1.0848948955535889\n",
            "Batch 310, Meta-loss: 1.0712034702301025\n",
            "Batch 311, Meta-loss: 0.9475455284118652\n",
            "Batch 312, Meta-loss: 0.9700056314468384\n",
            "Batch 313, Meta-loss: 0.9984878301620483\n",
            "Batch 314, Meta-loss: 1.0873758792877197\n",
            "Batch 315, Meta-loss: 1.1169401407241821\n",
            "Batch 316, Meta-loss: 0.8741698265075684\n",
            "Batch 317, Meta-loss: 1.1685928106307983\n",
            "Batch 318, Meta-loss: 1.0238771438598633\n",
            "Batch 319, Meta-loss: 1.0662026405334473\n",
            "Batch 320, Meta-loss: 0.9627681970596313\n",
            "Batch 321, Meta-loss: 0.9899754524230957\n",
            "Batch 322, Meta-loss: 0.8160662651062012\n",
            "Batch 323, Meta-loss: 1.1782193183898926\n",
            "Batch 324, Meta-loss: 1.2825520038604736\n",
            "Batch 325, Meta-loss: 0.9366122484207153\n",
            "Batch 326, Meta-loss: 0.8427831530570984\n",
            "Batch 327, Meta-loss: 0.862055778503418\n",
            "Batch 328, Meta-loss: 1.0797593593597412\n",
            "Batch 329, Meta-loss: 1.042814016342163\n",
            "Batch 330, Meta-loss: 1.0692310333251953\n",
            "Batch 331, Meta-loss: 0.9757667779922485\n",
            "Batch 332, Meta-loss: 0.9738848805427551\n",
            "Batch 333, Meta-loss: 1.0224764347076416\n",
            "Batch 334, Meta-loss: 1.0019079446792603\n",
            "Batch 335, Meta-loss: 0.9533621668815613\n",
            "Batch 336, Meta-loss: 1.0768542289733887\n",
            "Batch 337, Meta-loss: 0.9782475233078003\n",
            "Batch 338, Meta-loss: 1.1605770587921143\n",
            "Batch 339, Meta-loss: 1.1143722534179688\n",
            "Batch 340, Meta-loss: 1.0719521045684814\n",
            "Batch 341, Meta-loss: 0.8351043462753296\n",
            "Batch 342, Meta-loss: 1.1468513011932373\n",
            "Batch 343, Meta-loss: 0.9568524360656738\n",
            "Batch 344, Meta-loss: 0.8268799781799316\n",
            "Batch 345, Meta-loss: 0.9124584197998047\n",
            "Batch 346, Meta-loss: 0.947510838508606\n",
            "Batch 347, Meta-loss: 1.0198298692703247\n",
            "Batch 348, Meta-loss: 1.0462957620620728\n",
            "Batch 349, Meta-loss: 0.878799319267273\n",
            "Batch 350, Meta-loss: 0.9637809991836548\n",
            "Batch 351, Meta-loss: 0.9771736264228821\n",
            "Batch 352, Meta-loss: 0.8555817604064941\n",
            "Batch 353, Meta-loss: 1.1102991104125977\n",
            "Batch 354, Meta-loss: 1.0082330703735352\n",
            "Batch 355, Meta-loss: 0.9081996083259583\n",
            "Batch 356, Meta-loss: 0.9338102340698242\n",
            "Batch 357, Meta-loss: 1.0761290788650513\n",
            "Batch 358, Meta-loss: 1.1097943782806396\n",
            "Batch 359, Meta-loss: 0.9060710072517395\n",
            "Batch 360, Meta-loss: 0.9267292022705078\n",
            "Batch 361, Meta-loss: 1.1485249996185303\n",
            "Batch 362, Meta-loss: 1.0234495401382446\n",
            "Batch 363, Meta-loss: 0.9847313761711121\n",
            "Batch 364, Meta-loss: 1.0106945037841797\n",
            "Batch 365, Meta-loss: 0.8200206756591797\n",
            "Batch 366, Meta-loss: 1.0535894632339478\n",
            "Batch 367, Meta-loss: 1.107429027557373\n",
            "Batch 368, Meta-loss: 0.911708652973175\n",
            "Batch 369, Meta-loss: 0.8338476419448853\n",
            "Batch 370, Meta-loss: 1.0406453609466553\n",
            "Batch 371, Meta-loss: 1.0736967325210571\n",
            "Batch 372, Meta-loss: 0.9003279805183411\n",
            "Batch 373, Meta-loss: 1.1907927989959717\n",
            "Batch 374, Meta-loss: 1.0547943115234375\n",
            "Batch 375, Meta-loss: 0.8777643442153931\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JO38OPK15nR",
        "outputId": "1fe85a39-d109-4e11-b23a-bc5fb910884d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "import random\n",
        "\n",
        "# Initialize Pygame\n",
        "try:\n",
        "    pygame.init()\n",
        "except pygame.error as msg:\n",
        "    print(\"Unable to initialize Pygame:\", msg)\n",
        "    exit()"
      ],
      "metadata": {
        "id": "-SzEmoE85z1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "import pygame\n",
        "\n",
        "# Now you can use Pygame without a physical video display"
      ],
      "metadata": {
        "id": "Lo4XMXr6Cubp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "\n",
        "# Initialize Pygame\n",
        "pygame.init()\n",
        "\n",
        "# Set up the display\n",
        "WINDOW_WIDTH = 800\n",
        "WINDOW_HEIGHT = 600\n",
        "game_display = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n",
        "pygame.display.set_caption('Galactic Conquest')\n",
        "\n",
        "# Define game variables\n",
        "player_x = WINDOW_WIDTH / 2\n",
        "player_y = WINDOW_HEIGHT / 2\n",
        "player_speed = 5\n",
        "\n",
        "enemy_x = 100\n",
        "enemy_y = 100\n",
        "enemy_speed = 3\n",
        "\n",
        "bullet_x = 0\n",
        "bullet_y = 0\n",
        "bullet_speed = 10\n",
        "bullet_state = 'ready'\n",
        "\n",
        "# Define game functions\n",
        "def move_player(dx, dy):\n",
        "    global player_x, player_y\n",
        "    player_x += dx\n",
        "    player_y += dy\n",
        "\n",
        "def fire_bullet(x, y):\n",
        "    global bullet_state\n",
        "    bullet_state = 'fire'\n",
        "    game_display.blit(bullet_image, (x + 16, y + 10))\n",
        "\n",
        "def is_collision(enemy_x, enemy_y, bullet_x, bullet_y):\n",
        "    distance = ((enemy_x - bullet_x)**2 + (enemy_y - bullet_y)**2)**0.5\n",
        "    return distance < 27\n",
        "\n",
        "# Load game resources\n",
        "try:\n",
        "    player_image = pygame.image.load('player.png')\n",
        "    enemy_image = pygame.image.load('enemy.png')\n",
        "    bullet_image = pygame.image.load('bullet.png')\n",
        "    bullet_sound = pygame.mixer.Sound('bullet.wav')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Resource file not found. Please check the file paths.\")\n",
        "else:\n",
        "    # Start game loop\n",
        "    game_exit = False\n",
        "    while not game_exit:\n",
        "        # Event handling\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                game_exit = True\n",
        "            elif event.type == pygame.KEYDOWN:\n",
        "                if event.key == pygame.K_LEFT:\n",
        "                    move_player(-player_speed, 0)\n",
        "                elif event.key == pygame.K_RIGHT:\n",
        "                    move_player(player_speed, 0)\n",
        "                elif event.key == pygame.K_UP:\n",
        "                    move_player(0, -player_speed)\n",
        "                elif event.key == pygame.K_DOWN:\n",
        "                    move_player(0, player_speed)\n",
        "                elif event.key == pygame.K_SPACE:\n",
        "                    if bullet_state == 'ready':\n",
        "                        bullet_sound.play()\n",
        "                        bullet_x = player_x\n",
        "                        bullet_y = player_y\n",
        "                        fire_bullet(bullet_x, bullet_y)\n",
        "\n",
        "        # Update game state\n",
        "        if is_collision(enemy_x, enemy_y, bullet_x, bullet_y):\n",
        "            print(\"Enemy hit!\")\n",
        "            bullet_state = 'ready'\n",
        "            bullet_x = 0\n",
        "            bullet_y = 0\n",
        "            enemy_x = 100\n",
        "            enemy_y = 100\n",
        "\n",
        "        if bullet_state == 'fire':\n",
        "            fire_bullet(bullet_x, bullet_y)\n",
        "            bullet_y -= bullet_speed\n",
        "            if bullet_y < 0:\n",
        "                bullet_state = 'ready'\n",
        "                bullet_x = 0\n",
        "                bullet_y = 0\n",
        "\n",
        "        # Draw game elements\n",
        "        game_display.fill((255, 255, 255))\n",
        "        game_display.blit(player_image, (player_x, player_y))\n",
        "        game_display.blit(enemy_image, (enemy_x, enemy_y))\n",
        "        pygame.display.update()\n",
        "\n",
        "# Clean up Pygame\n",
        "pygame.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rxzVFibIL8C",
        "outputId": "b28ec227-0447-4f3d-822f-4b77d4b5d2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Resource file not found. Please check the file paths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/ChatGPT/NLP-QA/main/data/sentiment_data.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Print the first few rows to check if the dataset is loaded correctly\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "rYZD03dGcsRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZllNYutJcsVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgXWyBQwcsau"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}